
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Comprehensive revision notes and solved papers for Mid Semester 1 exams">
      
      
        <meta name="author" content="Shivam Kumar">
      
      
      
        <link rel="prev" href="../module3-classification-evaluation/">
      
      
        <link rel="next" href="../module5-decision-trees/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>Module 4 - Unsupervised Learning - Mid Semester 1 Exam Notes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-4-unsupervised-learning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Mid Semester 1 Exam Notes" class="md-header__button md-logo" aria-label="Mid Semester 1 Exam Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Mid Semester 1 Exam Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Module 4 - Unsupervised Learning
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/shivam2003-dev/mid_sem1_exam_notes" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    mid_sem1_exam_notes
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
  Machine Learning

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../dnn/" class="md-tabs__link">
          
  
  
  Deep Neural Networks

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Mid Semester 1 Exam Notes" class="md-nav__button md-logo" aria-label="Mid Semester 1 Exam Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Mid Semester 1 Exam Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/shivam2003-dev/mid_sem1_exam_notes" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    mid_sem1_exam_notes
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Machine Learning
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Machine Learning
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ML Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cheatsheet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cheat Sheet
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../module1-introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 1 - Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../module2-supervised-learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 2 - Supervised Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../module3-classification-evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 3 - Classification & Evaluation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Module 4 - Unsupervised Learning
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 4 - Unsupervised Learning
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        What is Clustering?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#applications-of-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Applications of Clustering
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Concepts
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k-means-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        K-Means Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="K-Means Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algorithm-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithm Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithm-steps-detailed" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithm Steps (Detailed)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-formulation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mathematical Formulation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distance-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Distance Metrics
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Distance Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#euclidean-distance-most-common" class="md-nav__link">
    <span class="md-ellipsis">
      
        Euclidean Distance (Most Common)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manhattan-distance-l1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Manhattan Distance (L1)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cosine Similarity
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#worked-example-k-means-step-by-step" class="md-nav__link">
    <span class="md-ellipsis">
      
        Worked Example: K-Means Step by Step
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#choosing-k-the-elbow-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        Choosing K: The Elbow Method
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-methods-for-choosing-k" class="md-nav__link">
    <span class="md-ellipsis">
      
        Other Methods for Choosing K
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-means-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      
        K-Means++ Initialization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advantages-and-disadvantages" class="md-nav__link">
    <span class="md-ellipsis">
      
        Advantages and Disadvantages
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hierarchical-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hierarchical Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Hierarchical Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#types-of-hierarchical-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Types of Hierarchical Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Types of Hierarchical Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-agglomerative-bottom-up-most-common" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Agglomerative (Bottom-Up) - Most Common
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-divisive-top-down" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Divisive (Top-Down)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agglomerative-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Agglomerative Algorithm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkage-criteria" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linkage Criteria
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linkage Criteria">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-single-linkage-minimum" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Single Linkage (Minimum)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-complete-linkage-maximum" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Complete Linkage (Maximum)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-average-linkage-upgma" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Average Linkage (UPGMA)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-centroid-linkage" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Centroid Linkage
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-wards-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Ward's Method
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dendrogram" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dendrogram
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#worked-example-hierarchical-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Worked Example: Hierarchical Clustering
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparison-k-means-vs-hierarchical" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comparison: K-Means vs Hierarchical
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dimensionality-reduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dimensionality Reduction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dimensionality Reduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-reduce-dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Reduce Dimensions?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Methods Overview
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#principal-component-analysis-pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        Principal Component Analysis (PCA)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Principal Component Analysis (PCA)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mathematical Foundation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mathematical Foundation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-by-step-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step-by-Step Algorithm
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variance-explained" class="md-nav__link">
    <span class="md-ellipsis">
      
        Variance Explained
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#choosing-number-of-components" class="md-nav__link">
    <span class="md-ellipsis">
      
        Choosing Number of Components
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#worked-example-pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        Worked Example: PCA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#properties-of-pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        Properties of PCA
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#association-rule-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Association Rule Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Association Rule Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-concepts_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Concepts
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#itemset" class="md-nav__link">
    <span class="md-ellipsis">
      
        Itemset
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Support
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Confidence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lift" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lift
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apriori-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Apriori Algorithm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#worked-example-apriori" class="md-nav__link">
    <span class="md-ellipsis">
      
        Worked Example: Apriori
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-formulas-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Formulas Summary
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Formulas Summary">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-means" class="md-nav__link">
    <span class="md-ellipsis">
      
        K-Means
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#association-rules" class="md-nav__link">
    <span class="md-ellipsis">
      
        Association Rules
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-exam-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Exam Questions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#important-points-to-remember" class="md-nav__link">
    <span class="md-ellipsis">
      
        Important Points to Remember
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../module5-decision-trees/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 5 - Decision Trees
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_8" >
        
          
          <label class="md-nav__link" for="__nav_2_8" id="__nav_2_8_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Previous Year Papers
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Previous Year Papers
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/2024-regular-solved/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2024 Regular Paper - Solved
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/2024-makeup-solved/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2024 Makeup Paper - Solved
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../papers/2025-practice-solved/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2025 Practice Set - Solved
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Deep Neural Networks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Deep Neural Networks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    DNN Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dnn/cheatsheet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cheat Sheet
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dnn/module1-introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 1 - Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dnn/module2-ann-perceptron/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 2 - ANN & Perceptron
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dnn/module3-linear-nn-regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 3 - Linear NN Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dnn/module4-linear-nn-classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 4 - Linear NN Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dnn/module5-dfnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 5 - Deep Feedforward Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dnn/module6-cnn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Module 6 - Convolutional Neural Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_9" >
        
          
          <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Previous Year Papers
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Previous Year Papers
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dnn/papers/2024-midsem-regular-solved/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2024 MidSem Regular - Solved
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        What is Clustering?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#applications-of-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Applications of Clustering
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Concepts
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k-means-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        K-Means Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="K-Means Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algorithm-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithm Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algorithm-steps-detailed" class="md-nav__link">
    <span class="md-ellipsis">
      
        Algorithm Steps (Detailed)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-formulation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mathematical Formulation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distance-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Distance Metrics
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Distance Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#euclidean-distance-most-common" class="md-nav__link">
    <span class="md-ellipsis">
      
        Euclidean Distance (Most Common)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manhattan-distance-l1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Manhattan Distance (L1)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cosine-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cosine Similarity
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#worked-example-k-means-step-by-step" class="md-nav__link">
    <span class="md-ellipsis">
      
        Worked Example: K-Means Step by Step
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#choosing-k-the-elbow-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        Choosing K: The Elbow Method
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#other-methods-for-choosing-k" class="md-nav__link">
    <span class="md-ellipsis">
      
        Other Methods for Choosing K
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-means-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      
        K-Means++ Initialization
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advantages-and-disadvantages" class="md-nav__link">
    <span class="md-ellipsis">
      
        Advantages and Disadvantages
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hierarchical-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hierarchical Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Hierarchical Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#types-of-hierarchical-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Types of Hierarchical Clustering
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Types of Hierarchical Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-agglomerative-bottom-up-most-common" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Agglomerative (Bottom-Up) - Most Common
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-divisive-top-down" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Divisive (Top-Down)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agglomerative-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Agglomerative Algorithm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linkage-criteria" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linkage Criteria
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linkage Criteria">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-single-linkage-minimum" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Single Linkage (Minimum)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-complete-linkage-maximum" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Complete Linkage (Maximum)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-average-linkage-upgma" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Average Linkage (UPGMA)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-centroid-linkage" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Centroid Linkage
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-wards-method" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Ward's Method
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dendrogram" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dendrogram
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#worked-example-hierarchical-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      
        Worked Example: Hierarchical Clustering
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparison-k-means-vs-hierarchical" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comparison: K-Means vs Hierarchical
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dimensionality-reduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Dimensionality Reduction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dimensionality Reduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-reduce-dimensions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Reduce Dimensions?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Methods Overview
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#principal-component-analysis-pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        Principal Component Analysis (PCA)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Principal Component Analysis (PCA)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mathematical Foundation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Mathematical Foundation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-by-step-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Step-by-Step Algorithm
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variance-explained" class="md-nav__link">
    <span class="md-ellipsis">
      
        Variance Explained
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#choosing-number-of-components" class="md-nav__link">
    <span class="md-ellipsis">
      
        Choosing Number of Components
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#worked-example-pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        Worked Example: PCA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#properties-of-pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        Properties of PCA
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#association-rule-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Association Rule Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Association Rule Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-concepts_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Concepts
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#itemset" class="md-nav__link">
    <span class="md-ellipsis">
      
        Itemset
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Support
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#confidence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Confidence
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lift" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lift
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apriori-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      
        Apriori Algorithm
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#worked-example-apriori" class="md-nav__link">
    <span class="md-ellipsis">
      
        Worked Example: Apriori
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-formulas-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Formulas Summary
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Formulas Summary">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-means" class="md-nav__link">
    <span class="md-ellipsis">
      
        K-Means
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pca" class="md-nav__link">
    <span class="md-ellipsis">
      
        PCA
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#association-rules" class="md-nav__link">
    <span class="md-ellipsis">
      
        Association Rules
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-exam-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Exam Questions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#important-points-to-remember" class="md-nav__link">
    <span class="md-ellipsis">
      
        Important Points to Remember
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="module-4-unsupervised-learning">Module 4: Unsupervised Learning</h1>
<h2 id="overview">Overview</h2>
<p>Unsupervised learning finds hidden patterns in data <strong>without labeled outputs</strong>. This module covers clustering algorithms (K-Means, Hierarchical), dimensionality reduction (PCA), and association rules.</p>
<div class="admonition info">
<p class="admonition-title">Key Difference from Supervised Learning</p>
<ul>
<li><strong>Supervised</strong>: "Here's the input and the correct answer, learn the pattern"</li>
<li><strong>Unsupervised</strong>: "Here's the data, find interesting patterns on your own"</li>
</ul>
</div>
<hr />
<h2 id="clustering">Clustering</h2>
<h3 id="what-is-clustering">What is Clustering?</h3>
<p><strong>Clustering</strong> groups similar data points together based on their features. The goal is to find natural groupings in data.</p>
<div class="admonition success">
<p class="admonition-title">Definition</p>
<p>Clustering partitions a dataset into groups (clusters) such that:</p>
<ul>
<li>Points <strong>within</strong> a cluster are similar to each other</li>
<li>Points <strong>across</strong> clusters are dissimilar</li>
</ul>
</div>
<h3 id="applications-of-clustering">Applications of Clustering</h3>
<table>
<thead>
<tr>
<th>Domain</th>
<th>Application</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Marketing</strong></td>
<td>Customer Segmentation</td>
<td>Group customers by behavior for targeted campaigns</td>
</tr>
<tr>
<td><strong>Biology</strong></td>
<td>Gene Expression</td>
<td>Group genes with similar expression patterns</td>
</tr>
<tr>
<td><strong>Image Processing</strong></td>
<td>Image Segmentation</td>
<td>Separate foreground from background</td>
</tr>
<tr>
<td><strong>Security</strong></td>
<td>Anomaly Detection</td>
<td>Identify unusual patterns (fraud, intrusion)</td>
</tr>
<tr>
<td><strong>Social Media</strong></td>
<td>Community Detection</td>
<td>Find groups of related users</td>
</tr>
</tbody>
</table>
<h3 id="key-concepts">Key Concepts</h3>
<table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cluster</strong></td>
<td>Group of similar data points</td>
</tr>
<tr>
<td><strong>Centroid</strong></td>
<td>Center point of a cluster (mean of all points)</td>
</tr>
<tr>
<td><strong>Distance Metric</strong></td>
<td>How we measure similarity between points</td>
</tr>
<tr>
<td><strong>Inertia</strong></td>
<td>Sum of squared distances from points to their centroids</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="k-means-clustering">K-Means Clustering</h2>
<h3 id="algorithm-overview">Algorithm Overview</h3>
<p><strong>K-Means</strong> partitions data into <strong>K clusters</strong> by minimizing the within-cluster variance.</p>
<div class="admonition note">
<p class="admonition-title">Key Idea</p>
<p>Iteratively assign points to nearest centroid, then update centroids to be the mean of assigned points.</p>
</div>
<h3 id="algorithm-steps-detailed">Algorithm Steps (Detailed)</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>K-Means Algorithm:
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>Input: Dataset X, number of clusters K
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>Output: K clusters with centroids
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>1. INITIALIZE: Randomly select K data points as initial centroids
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>   , , ..., 
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>2. REPEAT until convergence:
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>   a. ASSIGNMENT STEP:
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>      For each data point x:
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        - Calculate distance to all K centroids
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        - Assign x to cluster with nearest centroid
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        - c = argmin_k ||x - ||
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>   b. UPDATE STEP:
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>      For each cluster k:
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        - Recalculate centroid as mean of all assigned points
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        -  = (1/|C|)  x for all x in cluster k
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>3. CONVERGENCE: Stop when centroids don&#39;t change (or change &lt; threshold)
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>4. RETURN: Cluster assignments and final centroids
</code></pre></div>
<h3 id="mathematical-formulation">Mathematical Formulation</h3>
<p><strong>Objective Function</strong> (Within-cluster sum of squares - WCSS):</p>
<div class="arithmatex">\[
J = \sum_{i=1}^{m} \sum_{k=1}^{K} w_{ik} ||x^{(i)} - \mu_k||^2
\]</div>
<p>Where:
- <span class="arithmatex">\(m\)</span> = number of data points
- <span class="arithmatex">\(K\)</span> = number of clusters
- <span class="arithmatex">\(w_{ik} = 1\)</span> if point <span class="arithmatex">\(i\)</span> belongs to cluster <span class="arithmatex">\(k\)</span>, else <span class="arithmatex">\(0\)</span>
- <span class="arithmatex">\(\mu_k\)</span> = centroid of cluster <span class="arithmatex">\(k\)</span>
- <span class="arithmatex">\(||x^{(i)} - \mu_k||^2\)</span> = squared Euclidean distance</p>
<p><strong>Goal</strong>: Minimize <span class="arithmatex">\(J\)</span> (minimize total within-cluster variance)</p>
<h3 id="distance-metrics">Distance Metrics</h3>
<h4 id="euclidean-distance-most-common">Euclidean Distance (Most Common)</h4>
<div class="arithmatex">\[
d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2} = ||x - y||_2
\]</div>
<div class="admonition tip">
<p class="admonition-title">When to Use</p>
<p>Best for continuous data where all features have similar scales.</p>
</div>
<h4 id="manhattan-distance-l1">Manhattan Distance (L1)</h4>
<div class="arithmatex">\[
d(x, y) = \sum_{i=1}^{n} |x_i - y_i|
\]</div>
<div class="admonition tip">
<p class="admonition-title">When to Use</p>
<p>Better when dealing with high-dimensional data or when outliers are present.</p>
</div>
<h4 id="cosine-similarity">Cosine Similarity</h4>
<div class="arithmatex">\[
\text{similarity}(x, y) = \frac{x \cdot y}{||x|| \cdot ||y||} = \frac{\sum_{i=1}^{n} x_i y_i}{\sqrt{\sum_{i=1}^{n} x_i^2} \cdot \sqrt{\sum_{i=1}^{n} y_i^2}}
\]</div>
<div class="admonition tip">
<p class="admonition-title">When to Use</p>
<p>Best for text data and high-dimensional sparse data (measures angle, not magnitude).</p>
</div>
<hr />
<h3 id="worked-example-k-means-step-by-step">Worked Example: K-Means Step by Step</h3>
<div class="admonition example">
<p class="admonition-title">Problem</p>
<p>Cluster the following 2D points into K=2 clusters:</p>
<table>
<thead>
<tr>
<th>Point</th>
<th>x</th>
<th>x</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>B</td>
<td>1.5</td>
<td>2</td>
</tr>
<tr>
<td>C</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>D</td>
<td>5</td>
<td>7</td>
</tr>
<tr>
<td>E</td>
<td>3.5</td>
<td>5</td>
</tr>
<tr>
<td>F</td>
<td>4.5</td>
<td>5</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Step 1: Initialize Centroids</strong></p>
<p>Randomly select K=2 points as initial centroids:
- <span class="arithmatex">\(\mu_1 = A = (1, 1)\)</span>
- <span class="arithmatex">\(\mu_2 = D = (5, 7)\)</span></p>
<p><strong>Step 2: First Assignment Step</strong></p>
<p>Calculate distance from each point to both centroids:</p>
<table>
<thead>
<tr>
<th>Point</th>
<th>Distance to </th>
<th>Distance to </th>
<th>Assigned Cluster</th>
</tr>
</thead>
<tbody>
<tr>
<td>A (1,1)</td>
<td>0</td>
<td><span class="arithmatex">\(\sqrt{(5-1)^2+(7-1)^2} = \sqrt{52} = 7.21\)</span></td>
<td><strong>Cluster 1</strong></td>
</tr>
<tr>
<td>B (1.5,2)</td>
<td><span class="arithmatex">\(\sqrt{0.5^2+1^2} = 1.12\)</span></td>
<td><span class="arithmatex">\(\sqrt{3.5^2+5^2} = 6.10\)</span></td>
<td><strong>Cluster 1</strong></td>
</tr>
<tr>
<td>C (3,4)</td>
<td><span class="arithmatex">\(\sqrt{2^2+3^2} = 3.61\)</span></td>
<td><span class="arithmatex">\(\sqrt{2^2+3^2} = 3.61\)</span></td>
<td><strong>Cluster 1</strong> (tie, choose 1)</td>
</tr>
<tr>
<td>D (5,7)</td>
<td><span class="arithmatex">\(\sqrt{4^2+6^2} = 7.21\)</span></td>
<td>0</td>
<td><strong>Cluster 2</strong></td>
</tr>
<tr>
<td>E (3.5,5)</td>
<td><span class="arithmatex">\(\sqrt{2.5^2+4^2} = 4.72\)</span></td>
<td><span class="arithmatex">\(\sqrt{1.5^2+2^2} = 2.50\)</span></td>
<td><strong>Cluster 2</strong></td>
</tr>
<tr>
<td>F (4.5,5)</td>
<td><span class="arithmatex">\(\sqrt{3.5^2+4^2} = 5.32\)</span></td>
<td><span class="arithmatex">\(\sqrt{0.5^2+2^2} = 2.06\)</span></td>
<td><strong>Cluster 2</strong></td>
</tr>
</tbody>
</table>
<p><strong>Cluster 1</strong>: {A, B, C}
<strong>Cluster 2</strong>: {D, E, F}</p>
<p><strong>Step 3: First Update Step</strong></p>
<p>Calculate new centroids:</p>
<div class="arithmatex">\[
\mu_1 = \frac{1}{3}[(1,1) + (1.5,2) + (3,4)] = \left(\frac{5.5}{3}, \frac{7}{3}\right) = (1.83, 2.33)
\]</div>
<div class="arithmatex">\[
\mu_2 = \frac{1}{3}[(5,7) + (3.5,5) + (4.5,5)] = \left(\frac{13}{3}, \frac{17}{3}\right) = (4.33, 5.67)
\]</div>
<p><strong>Step 4: Second Assignment Step</strong></p>
<p>Recalculate distances with new centroids and reassign...</p>
<p>(Continue until centroids don't change)</p>
<p><strong>Final Result</strong>: 
- <strong>Cluster 1</strong>: {A, B, C} - Lower-left points
- <strong>Cluster 2</strong>: {D, E, F} - Upper-right points</p>
<hr />
<h3 id="choosing-k-the-elbow-method">Choosing K: The Elbow Method</h3>
<div class="admonition question">
<p class="admonition-title">How do we choose the optimal number of clusters K?</p>
</div>
<p><strong>Elbow Method</strong>:</p>
<ol>
<li>Run K-Means for K = 1, 2, 3, ..., n</li>
<li>Calculate WCSS (Within-Cluster Sum of Squares) for each K</li>
<li>Plot K vs WCSS</li>
<li>Look for the "elbow" - where WCSS decreases sharply then levels off</li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>WCSS
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>  |
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>  |\
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>  | \
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>  |  \
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>  |   \___________   Elbow at K=3
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>  |        
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>  
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    1  2  3  4  5  K
</code></pre></div>
<div class="admonition tip">
<p class="admonition-title">Exam Tip</p>
<p>The elbow point represents the optimal K - adding more clusters doesn't significantly reduce WCSS.</p>
</div>
<h3 id="other-methods-for-choosing-k">Other Methods for Choosing K</h3>
<table>
<thead>
<tr>
<th>Method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Silhouette Score</strong></td>
<td>Measures how similar points are to their own cluster vs other clusters</td>
</tr>
<tr>
<td><strong>Gap Statistic</strong></td>
<td>Compares WCSS to expected WCSS under null distribution</td>
</tr>
<tr>
<td><strong>Domain Knowledge</strong></td>
<td>Use prior knowledge (e.g., 3 customer types)</td>
</tr>
</tbody>
</table>
<h3 id="k-means-initialization">K-Means++ Initialization</h3>
<div class="admonition warning">
<p class="admonition-title">Problem with Random Initialization</p>
<p>Random initialization can lead to poor local minima and inconsistent results.</p>
</div>
<p><strong>K-Means++ Algorithm</strong>:</p>
<ol>
<li>Choose first centroid randomly from data points</li>
<li>For each remaining centroid:</li>
<li>Calculate distance <span class="arithmatex">\(D(x)\)</span> from each point to nearest existing centroid</li>
<li>Choose next centroid with probability proportional to <span class="arithmatex">\(D(x)^2\)</span></li>
<li>Points far from existing centroids are more likely to be chosen</li>
</ol>
<p><strong>Benefits</strong>:
- More spread out initial centroids
- Faster convergence
- Better final clusters</p>
<h3 id="advantages-and-disadvantages">Advantages and Disadvantages</h3>
<table>
<thead>
<tr>
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr>
<td> Simple and intuitive</td>
<td> Must specify K beforehand</td>
</tr>
<tr>
<td> Fast: O(nKiterations)</td>
<td> Sensitive to initialization</td>
</tr>
<tr>
<td> Scales to large datasets</td>
<td> Assumes spherical clusters</td>
</tr>
<tr>
<td> Guaranteed to converge</td>
<td> Sensitive to outliers</td>
</tr>
<tr>
<td> Works well for compact clusters</td>
<td> Struggles with varying cluster sizes</td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="admonition-title">Common Mistakes</p>
<ol>
<li><strong>Not scaling features</strong>: K-Means uses distance, so features with larger ranges dominate</li>
<li><strong>Wrong K</strong>: Always use elbow method or domain knowledge</li>
<li><strong>Single run</strong>: Always run multiple times with different initializations</li>
</ol>
</div>
<hr />
<h2 id="hierarchical-clustering">Hierarchical Clustering</h2>
<h3 id="overview_1">Overview</h3>
<p><strong>Hierarchical Clustering</strong> creates a tree-like structure (dendrogram) of clusters without pre-specifying the number of clusters.</p>
<h3 id="types-of-hierarchical-clustering">Types of Hierarchical Clustering</h3>
<h4 id="1-agglomerative-bottom-up-most-common">1. Agglomerative (Bottom-Up) - Most Common</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>Start: Each point is its own cluster
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>       
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>Merge closest clusters
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>       
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>Repeat until one cluster remains
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>       
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>Result: Dendrogram (tree structure)
</code></pre></div>
<h4 id="2-divisive-top-down">2. Divisive (Top-Down)</h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>Start: All points in one cluster
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>       
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>Split clusters
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>       
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>Repeat until each point is its own cluster
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>       
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>Result: Dendrogram
</code></pre></div>
<h3 id="agglomerative-algorithm">Agglomerative Algorithm</h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>Agglomerative Clustering:
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>1. INITIALIZE: Create n clusters (one per data point)
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>2. COMPUTE: Distance matrix between all pairs of clusters
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>3. REPEAT until one cluster remains:
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>   a. Find two closest clusters
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>   b. Merge them into one cluster
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>   c. Update distance matrix
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>4. RESULT: Dendrogram showing merge history
</code></pre></div>
<h3 id="linkage-criteria">Linkage Criteria</h3>
<p><strong>How do we measure distance between clusters?</strong></p>
<h4 id="1-single-linkage-minimum">1. Single Linkage (Minimum)</h4>
<div class="arithmatex">\[
d(C_i, C_j) = \min_{x \in C_i, y \in C_j} d(x, y)
\]</div>
<ul>
<li>Distance = minimum distance between any two points</li>
<li><strong>Pros</strong>: Can find elongated clusters</li>
<li><strong>Cons</strong>: Chaining effect (long, stringy clusters)</li>
</ul>
<h4 id="2-complete-linkage-maximum">2. Complete Linkage (Maximum)</h4>
<div class="arithmatex">\[
d(C_i, C_j) = \max_{x \in C_i, y \in C_j} d(x, y)
\]</div>
<ul>
<li>Distance = maximum distance between any two points</li>
<li><strong>Pros</strong>: Produces compact, spherical clusters</li>
<li><strong>Cons</strong>: Sensitive to outliers</li>
</ul>
<h4 id="3-average-linkage-upgma">3. Average Linkage (UPGMA)</h4>
<div class="arithmatex">\[
d(C_i, C_j) = \frac{1}{|C_i| \cdot |C_j|} \sum_{x \in C_i} \sum_{y \in C_j} d(x, y)
\]</div>
<ul>
<li>Distance = average of all pairwise distances</li>
<li><strong>Pros</strong>: Balanced approach, less sensitive to outliers</li>
<li><strong>Cons</strong>: Computationally more expensive</li>
</ul>
<h4 id="4-centroid-linkage">4. Centroid Linkage</h4>
<div class="arithmatex">\[
d(C_i, C_j) = d(\mu_i, \mu_j)
\]</div>
<ul>
<li>Distance = distance between cluster centroids</li>
<li><strong>Pros</strong>: Intuitive</li>
<li><strong>Cons</strong>: Can lead to inversions in dendrogram</li>
</ul>
<h4 id="5-wards-method">5. Ward's Method</h4>
<div class="arithmatex">\[
d(C_i, C_j) = \text{Increase in total within-cluster variance after merging}
\]</div>
<ul>
<li>Minimizes total within-cluster variance</li>
<li><strong>Pros</strong>: Produces compact, similar-sized clusters</li>
<li><strong>Cons</strong>: Assumes spherical clusters</li>
</ul>
<h3 id="dendrogram">Dendrogram</h3>
<div class="admonition success">
<p class="admonition-title">Definition</p>
<p>A <strong>dendrogram</strong> is a tree diagram showing the hierarchical relationship between clusters.</p>
</div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>Height (Distance)
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>    |
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>  6 |     
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>    |                    
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>  4 |              
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>    |                    
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>  2 |            
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    |                  
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>  0 | A   B C         D   E F
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>    
</code></pre></div>
<p><strong>How to Read</strong>:
- <strong>Leaves</strong> (bottom): Individual data points
- <strong>Branches</strong>: Clusters at different levels
- <strong>Height</strong>: Distance at which clusters merge
- <strong>Horizontal cut</strong>: Determines number of clusters</p>
<div class="admonition tip">
<p class="admonition-title">Choosing Number of Clusters</p>
<p>Draw a horizontal line at desired height - number of vertical lines it crosses = number of clusters.</p>
</div>
<h3 id="worked-example-hierarchical-clustering">Worked Example: Hierarchical Clustering</h3>
<div class="admonition example">
<p class="admonition-title">Problem</p>
<p>Cluster points A(0,0), B(1,0), C(4,0), D(5,0) using single linkage.</p>
</div>
<p><strong>Distance Matrix</strong>:</p>
<table>
<thead>
<tr>
<th></th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td>B</td>
<td>1</td>
<td>0</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>C</td>
<td>4</td>
<td>3</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>D</td>
<td>5</td>
<td>4</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p><strong>Step 1</strong>: Minimum distance = 1 (A-B and C-D)
- Merge A and B  {A,B}
- Merge C and D  {C,D}</p>
<p><strong>Step 2</strong>: Update distances (single linkage):
- d({A,B}, {C,D}) = min(d(A,C), d(A,D), d(B,C), d(B,D)) = min(4, 5, 3, 4) = 3</p>
<p><strong>Step 3</strong>: Merge {A,B} and {C,D} at distance 3</p>
<p><strong>Dendrogram</strong>:
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>Height
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>  3 |     
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>    |            
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>  1 |      
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>    |            
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>  0 |   A   B   C   D
</code></pre></div></p>
<h3 id="comparison-k-means-vs-hierarchical">Comparison: K-Means vs Hierarchical</h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>K-Means</th>
<th>Hierarchical</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>K specification</strong></td>
<td>Required upfront</td>
<td>Not required</td>
</tr>
<tr>
<td><strong>Output</strong></td>
<td>Flat clusters</td>
<td>Dendrogram (tree)</td>
</tr>
<tr>
<td><strong>Complexity</strong></td>
<td>O(nKiterations)</td>
<td>O(n) or O(nlog n)</td>
</tr>
<tr>
<td><strong>Scalability</strong></td>
<td>Good for large data</td>
<td>Better for small data</td>
</tr>
<tr>
<td><strong>Cluster shape</strong></td>
<td>Spherical</td>
<td>Any shape (with single linkage)</td>
</tr>
<tr>
<td><strong>Reproducibility</strong></td>
<td>Depends on initialization</td>
<td>Deterministic</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="dimensionality-reduction">Dimensionality Reduction</h2>
<h3 id="why-reduce-dimensions">Why Reduce Dimensions?</h3>
<div class="admonition warning">
<p class="admonition-title">Curse of Dimensionality</p>
<p>As dimensions increase:</p>
<ul>
<li>Data becomes sparse</li>
<li>Distance metrics become less meaningful</li>
<li>Computational cost increases exponentially</li>
<li>More data needed to avoid overfitting</li>
</ul>
</div>
<p><strong>Benefits of Dimensionality Reduction</strong>:</p>
<ol>
<li><strong>Visualization</strong>: Reduce to 2D/3D for plotting</li>
<li><strong>Noise Reduction</strong>: Remove noisy features</li>
<li><strong>Computational Efficiency</strong>: Faster training</li>
<li><strong>Avoid Overfitting</strong>: Fewer features = simpler model</li>
<li><strong>Feature Extraction</strong>: Create meaningful features</li>
</ol>
<h3 id="methods-overview">Methods Overview</h3>
<table>
<thead>
<tr>
<th>Method</th>
<th>Type</th>
<th>Preserves</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>PCA</strong></td>
<td>Linear</td>
<td>Global variance</td>
</tr>
<tr>
<td><strong>t-SNE</strong></td>
<td>Non-linear</td>
<td>Local structure</td>
</tr>
<tr>
<td><strong>LDA</strong></td>
<td>Linear, Supervised</td>
<td>Class separability</td>
</tr>
<tr>
<td><strong>Autoencoders</strong></td>
<td>Non-linear</td>
<td>Learned representation</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="principal-component-analysis-pca">Principal Component Analysis (PCA)</h2>
<h3 id="key-idea">Key Idea</h3>
<div class="admonition success">
<p class="admonition-title">PCA in One Sentence</p>
<p>PCA finds new axes (principal components) that capture the <strong>maximum variance</strong> in the data.</p>
</div>
<p><strong>Intuition</strong>: 
- First PC: Direction of maximum variance
- Second PC: Direction of maximum variance perpendicular to first
- And so on...</p>
<h3 id="mathematical-foundation">Mathematical Foundation</h3>
<h4 id="step-by-step-algorithm">Step-by-Step Algorithm</h4>
<p><strong>Step 1: Standardize the Data</strong></p>
<p>For each feature, compute z-score:</p>
<div class="arithmatex">\[
z_i = \frac{x_i - \mu_i}{\sigma_i}
\]</div>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>Always standardize before PCA! Otherwise, features with larger scales dominate.</p>
</div>
<p><strong>Step 2: Compute Covariance Matrix</strong></p>
<div class="arithmatex">\[
\Sigma = \frac{1}{m-1} X^T X
\]</div>
<p>Where X is the centered data matrix (m samples  n features).</p>
<p>The covariance matrix shows how features vary together:
- Diagonal: Variance of each feature
- Off-diagonal: Covariance between features</p>
<p><strong>Step 3: Eigenvalue Decomposition</strong></p>
<p>Find eigenvalues <span class="arithmatex">\(\lambda_1, \lambda_2, ..., \lambda_n\)</span> and eigenvectors <span class="arithmatex">\(v_1, v_2, ..., v_n\)</span> such that:</p>
<div class="arithmatex">\[
\Sigma v_i = \lambda_i v_i
\]</div>
<p><strong>Properties</strong>:
- Eigenvalues are non-negative (covariance matrix is positive semi-definite)
- Eigenvectors are orthogonal
- Eigenvalue = variance explained by that component</p>
<p><strong>Step 4: Sort and Select</strong></p>
<p>Sort eigenvalues in descending order: <span class="arithmatex">\(\lambda_1 \geq \lambda_2 \geq ... \geq \lambda_n\)</span></p>
<p>Select top k eigenvectors (principal components) that capture desired variance.</p>
<p><strong>Step 5: Project Data</strong></p>
<div class="arithmatex">\[
Y = X \cdot P_k
\]</div>
<p>Where:
- <span class="arithmatex">\(X\)</span> = original data (m  n)
- <span class="arithmatex">\(P_k\)</span> = matrix of top k eigenvectors (n  k)
- <span class="arithmatex">\(Y\)</span> = reduced data (m  k)</p>
<h3 id="variance-explained">Variance Explained</h3>
<p><strong>Proportion of Variance Explained by component i</strong>:</p>
<div class="arithmatex">\[
\text{Variance Explained}_i = \frac{\lambda_i}{\sum_{j=1}^{n} \lambda_j}
\]</div>
<p><strong>Cumulative Variance Explained</strong>:</p>
<div class="arithmatex">\[
\text{Cumulative}_k = \frac{\sum_{i=1}^{k} \lambda_i}{\sum_{j=1}^{n} \lambda_j}
\]</div>
<div class="admonition tip">
<p class="admonition-title">Rule of Thumb</p>
<p>Choose k such that cumulative variance  <strong>95%</strong> (or 90% for more compression).</p>
</div>
<h3 id="choosing-number-of-components">Choosing Number of Components</h3>
<p><strong>Method 1: Scree Plot</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>Eigenvalue
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>    |
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>    |*
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>    | *
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>    |  *
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>    |   *___*___*___*   Elbow
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>    
<a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>      1  2  3  4  5  k
</code></pre></div>
<p>Choose k at the "elbow" where eigenvalues drop sharply.</p>
<p><strong>Method 2: Cumulative Variance Threshold</strong></p>
<table>
<thead>
<tr>
<th>k</th>
<th>Cumulative Variance</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>60%</td>
</tr>
<tr>
<td>2</td>
<td>85%</td>
</tr>
<tr>
<td>3</td>
<td><strong>95%</strong>  Choose this</td>
</tr>
<tr>
<td>4</td>
<td>99%</td>
</tr>
</tbody>
</table>
<p><strong>Method 3: Kaiser Criterion</strong></p>
<p>Keep components with eigenvalue &gt; 1 (for standardized data).</p>
<h3 id="worked-example-pca">Worked Example: PCA</h3>
<div class="admonition example">
<p class="admonition-title">Problem</p>
<p>Perform PCA on the following 2D data and reduce to 1D:</p>
<table>
<thead>
<tr>
<th>Point</th>
<th>x</th>
<th>x</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2.5</td>
<td>2.4</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.7</td>
</tr>
<tr>
<td>3</td>
<td>2.2</td>
<td>2.9</td>
</tr>
<tr>
<td>4</td>
<td>1.9</td>
<td>2.2</td>
</tr>
<tr>
<td>5</td>
<td>3.1</td>
<td>3.0</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Step 1: Calculate means</strong></p>
<div class="arithmatex">\[
\bar{x}_1 = \frac{2.5 + 0.5 + 2.2 + 1.9 + 3.1}{5} = 2.04
\]</div>
<div class="arithmatex">\[
\bar{x}_2 = \frac{2.4 + 0.7 + 2.9 + 2.2 + 3.0}{5} = 2.24
\]</div>
<p><strong>Step 2: Center the data</strong> (subtract means)</p>
<table>
<thead>
<tr>
<th>Point</th>
<th>x - 2.04</th>
<th>x - 2.24</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0.46</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>-1.54</td>
<td>-1.54</td>
</tr>
<tr>
<td>3</td>
<td>0.16</td>
<td>0.66</td>
</tr>
<tr>
<td>4</td>
<td>-0.14</td>
<td>-0.04</td>
</tr>
<tr>
<td>5</td>
<td>1.06</td>
<td>0.76</td>
</tr>
</tbody>
</table>
<p><strong>Step 3: Compute covariance matrix</strong></p>
<div class="arithmatex">\[
\Sigma = \begin{bmatrix} 0.616 &amp; 0.615 \\ 0.615 &amp; 0.716 \end{bmatrix}
\]</div>
<p><strong>Step 4: Find eigenvalues and eigenvectors</strong></p>
<p>Eigenvalues: <span class="arithmatex">\(\lambda_1 = 1.284\)</span>, <span class="arithmatex">\(\lambda_2 = 0.049\)</span></p>
<p>Eigenvectors: <span class="arithmatex">\(v_1 = [0.677, 0.736]\)</span>, <span class="arithmatex">\(v_2 = [-0.736, 0.677]\)</span></p>
<p><strong>Step 5: Variance explained</strong></p>
<ul>
<li>PC1: <span class="arithmatex">\(\frac{1.284}{1.284 + 0.049} = 96.3\%\)</span></li>
<li>PC2: <span class="arithmatex">\(\frac{0.049}{1.333} = 3.7\%\)</span></li>
</ul>
<p><strong>Conclusion</strong>: First PC captures 96.3% of variance - we can reduce to 1D with minimal information loss!</p>
<h3 id="properties-of-pca">Properties of PCA</h3>
<p><strong>Key Properties</strong>:</p>
<ol>
<li><strong>Orthogonality</strong>: Principal components are uncorrelated</li>
<li><strong>Variance Maximization</strong>: Each PC maximizes remaining variance</li>
<li><strong>Linear</strong>: PCA finds linear combinations of original features</li>
<li><strong>Reversible</strong>: Can reconstruct original data (with some loss)</li>
</ol>
<p><strong>Limitations</strong>:</p>
<table>
<thead>
<tr>
<th>Limitation</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Linear only</strong></td>
<td>Cannot capture non-linear relationships</td>
</tr>
<tr>
<td><strong>Variance-based</strong></td>
<td>May not preserve class separability</td>
</tr>
<tr>
<td><strong>Sensitive to scaling</strong></td>
<td>Must standardize first</td>
</tr>
<tr>
<td><strong>Interpretability</strong></td>
<td>PCs are combinations of features</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="association-rule-learning">Association Rule Learning</h2>
<h3 id="introduction">Introduction</h3>
<p><strong>Association Rules</strong> discover interesting relationships between variables in large datasets.</p>
<div class="admonition example">
<p class="admonition-title">Classic Example: Market Basket Analysis</p>
<p>"Customers who buy <strong>bread</strong> and <strong>butter</strong> also buy <strong>milk</strong>"</p>
<p>Rule: {Bread, Butter}  {Milk}</p>
</div>
<h3 id="key-concepts_1">Key Concepts</h3>
<h4 id="itemset">Itemset</h4>
<p>An <strong>itemset</strong> is a collection of items.
- {Bread} - 1-itemset
- {Bread, Butter} - 2-itemset
- {Bread, Butter, Milk} - 3-itemset</p>
<h4 id="support">Support</h4>
<p><strong>Support</strong> measures how frequently an itemset appears in the dataset.</p>
<div class="arithmatex">\[
\text{Support}(A) = \frac{\text{Number of transactions containing A}}{\text{Total number of transactions}}
\]</div>
<div class="admonition example">
<p class="admonition-title">Support Example</p>
<p>If 100 transactions and 30 contain {Bread, Milk}:</p>
<p>Support({Bread, Milk}) = 30/100 = 0.30 = 30%</p>
</div>
<h4 id="confidence">Confidence</h4>
<p><strong>Confidence</strong> measures how often the rule is true.</p>
<div class="arithmatex">\[
\text{Confidence}(A \rightarrow B) = \frac{\text{Support}(A \cup B)}{\text{Support}(A)} = P(B|A)
\]</div>
<div class="admonition example">
<p class="admonition-title">Confidence Example</p>
<ul>
<li>Support({Bread}) = 50%</li>
<li>Support({Bread, Milk}) = 30%</li>
</ul>
<p>Confidence(Bread  Milk) = 30%/50% = 60%</p>
<p>"60% of customers who buy bread also buy milk"</p>
</div>
<h4 id="lift">Lift</h4>
<p><strong>Lift</strong> measures how much more likely B is when A occurs, compared to B occurring independently.</p>
<div class="arithmatex">\[
\text{Lift}(A \rightarrow B) = \frac{\text{Confidence}(A \rightarrow B)}{\text{Support}(B)} = \frac{P(B|A)}{P(B)}
\]</div>
<p><strong>Interpretation</strong>:
- <strong>Lift = 1</strong>: A and B are independent
- <strong>Lift &gt; 1</strong>: Positive correlation (A increases likelihood of B)
- <strong>Lift &lt; 1</strong>: Negative correlation (A decreases likelihood of B)</p>
<div class="admonition example">
<p class="admonition-title">Lift Example</p>
<ul>
<li>Confidence(Bread  Milk) = 60%</li>
<li>Support(Milk) = 40%</li>
</ul>
<p>Lift = 60%/40% = 1.5</p>
<p>"Customers who buy bread are 1.5 more likely to buy milk"</p>
</div>
<h3 id="apriori-algorithm">Apriori Algorithm</h3>
<div class="admonition success">
<p class="admonition-title">Apriori Principle</p>
<p>If an itemset is <strong>infrequent</strong>, all its supersets are also infrequent.</p>
<p>Contrapositive: If an itemset is <strong>frequent</strong>, all its subsets are also frequent.</p>
</div>
<p><strong>Algorithm</strong>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>Apriori Algorithm:
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>Input: Transaction database, minimum support, minimum confidence
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>Output: Association rules
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>1. Find all frequent 1-itemsets (items with support  min_support)
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>2. For k = 2, 3, ... until no more frequent itemsets:
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>   a. Generate candidate k-itemsets from frequent (k-1)-itemsets
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>   b. Prune candidates with infrequent subsets
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>   c. Count support for remaining candidates
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>   d. Keep itemsets with support  min_support
<a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>
<a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>3. Generate rules from frequent itemsets:
<a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>   For each frequent itemset I:
<a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>     For each non-empty subset A of I:
<a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>       Rule: A  (I - A)
<a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>       If confidence  min_confidence:
<a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>         Output rule
</code></pre></div>
<h3 id="worked-example-apriori">Worked Example: Apriori</h3>
<div class="admonition example">
<p class="admonition-title">Problem</p>
<p>Given transactions and min_support = 50%, min_confidence = 60%:</p>
<table>
<thead>
<tr>
<th>TID</th>
<th>Items</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>{Bread, Milk}</td>
</tr>
<tr>
<td>2</td>
<td>{Bread, Butter, Milk}</td>
</tr>
<tr>
<td>3</td>
<td>{Bread, Butter}</td>
</tr>
<tr>
<td>4</td>
<td>{Milk, Eggs}</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Step 1: Count 1-itemsets</strong></p>
<table>
<thead>
<tr>
<th>Item</th>
<th>Count</th>
<th>Support</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bread</td>
<td>3</td>
<td>75% </td>
</tr>
<tr>
<td>Milk</td>
<td>3</td>
<td>75% </td>
</tr>
<tr>
<td>Butter</td>
<td>2</td>
<td>50% </td>
</tr>
<tr>
<td>Eggs</td>
<td>1</td>
<td>25% </td>
</tr>
</tbody>
</table>
<p>Frequent 1-itemsets: {Bread}, {Milk}, {Butter}</p>
<p><strong>Step 2: Generate and count 2-itemsets</strong></p>
<table>
<thead>
<tr>
<th>Itemset</th>
<th>Count</th>
<th>Support</th>
</tr>
</thead>
<tbody>
<tr>
<td>{Bread, Milk}</td>
<td>2</td>
<td>50% </td>
</tr>
<tr>
<td>{Bread, Butter}</td>
<td>2</td>
<td>50% </td>
</tr>
<tr>
<td>{Milk, Butter}</td>
<td>1</td>
<td>25% </td>
</tr>
</tbody>
</table>
<p>Frequent 2-itemsets: {Bread, Milk}, {Bread, Butter}</p>
<p><strong>Step 3: Generate 3-itemsets</strong></p>
<p>Candidate: {Bread, Milk, Butter}
- Subset {Milk, Butter} is infrequent  <strong>Prune</strong></p>
<p>No frequent 3-itemsets.</p>
<p><strong>Step 4: Generate Rules</strong></p>
<p>From {Bread, Milk}:
- Bread  Milk: Confidence = 50%/75% = 67% 
- Milk  Bread: Confidence = 50%/75% = 67% </p>
<p>From {Bread, Butter}:
- Bread  Butter: Confidence = 50%/75% = 67% 
- Butter  Bread: Confidence = 50%/50% = 100% </p>
<p><strong>Final Rules</strong> (confidence  60%):
1. Bread  Milk (67%)
2. Milk  Bread (67%)
3. Bread  Butter (67%)
4. Butter  Bread (100%)</p>
<hr />
<h2 id="key-formulas-summary">Key Formulas Summary</h2>
<h3 id="k-means">K-Means</h3>
<table>
<thead>
<tr>
<th>Formula</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(J = \sum_{i=1}^{m} \sum_{k=1}^{K} w_{ik} \|\|x^{(i)} - \mu_k\|\|^2\)</span></td>
<td>Objective function</td>
</tr>
<tr>
<td><span class="arithmatex">\(\mu_k = \frac{1}{\|C_k\|} \sum_{x \in C_k} x\)</span></td>
<td>Centroid update</td>
</tr>
<tr>
<td><span class="arithmatex">\(d(x, y) = \sqrt{\sum_i (x_i - y_i)^2}\)</span></td>
<td>Euclidean distance</td>
</tr>
</tbody>
</table>
<h3 id="pca">PCA</h3>
<table>
<thead>
<tr>
<th>Formula</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\Sigma = \frac{1}{m-1} X^T X\)</span></td>
<td>Covariance matrix</td>
</tr>
<tr>
<td><span class="arithmatex">\(\Sigma v = \lambda v\)</span></td>
<td>Eigenvalue equation</td>
</tr>
<tr>
<td><span class="arithmatex">\(\frac{\lambda_i}{\sum_j \lambda_j}\)</span></td>
<td>Variance explained</td>
</tr>
<tr>
<td><span class="arithmatex">\(Y = X \cdot P_k\)</span></td>
<td>Projection</td>
</tr>
</tbody>
</table>
<h3 id="association-rules">Association Rules</h3>
<table>
<thead>
<tr>
<th>Formula</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\text{Support}(A) = \frac{\text{Count}(A)}{N}\)</span></td>
<td>Support</td>
</tr>
<tr>
<td><span class="arithmatex">\(\text{Confidence}(A \rightarrow B) = \frac{\text{Support}(A \cup B)}{\text{Support}(A)}\)</span></td>
<td>Confidence</td>
</tr>
<tr>
<td><span class="arithmatex">\(\text{Lift}(A \rightarrow B) = \frac{\text{Confidence}(A \rightarrow B)}{\text{Support}(B)}\)</span></td>
<td>Lift</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="common-exam-questions">Common Exam Questions</h2>
<div class="admonition question">
<p class="admonition-title">Q1: Explain K-Means algorithm with example</p>
<ol>
<li>Initialize K centroids randomly</li>
<li>Assign each point to nearest centroid</li>
<li>Update centroids as mean of assigned points</li>
<li>Repeat until convergence</li>
</ol>
<p>(Include numerical example with distance calculations)</p>
</div>
<div class="admonition question">
<p class="admonition-title">Q2: How to choose optimal K in K-Means?</p>
<p><strong>Elbow Method</strong>: Plot WCSS vs K, choose K at the elbow where decrease slows down.</p>
<p><strong>Silhouette Score</strong>: Measures cluster quality, choose K with highest score.</p>
<p><strong>Domain Knowledge</strong>: Use prior knowledge about expected clusters.</p>
</div>
<div class="admonition question">
<p class="admonition-title">Q3: Explain PCA and its applications</p>
<p>PCA finds principal components (directions of maximum variance) to reduce dimensionality.</p>
<p><strong>Steps</strong>: Standardize  Covariance matrix  Eigendecomposition  Select top k  Project</p>
<p><strong>Applications</strong>: Visualization, noise reduction, feature extraction, preprocessing</p>
</div>
<div class="admonition question">
<p class="admonition-title">Q4: Calculate Support, Confidence, Lift</p>
<p>Given transactions, calculate:
- Support = Count(itemset) / Total transactions
- Confidence = Support(AB) / Support(A)
- Lift = Confidence / Support(B)</p>
</div>
<hr />
<h2 id="important-points-to-remember">Important Points to Remember</h2>
<p> <strong>K-Means</strong>: Partition into K clusters, minimize within-cluster variance</p>
<p> <strong>Elbow Method</strong>: Plot cost vs K, choose at elbow</p>
<p> <strong>K-Means++</strong>: Better initialization, spread out centroids</p>
<p> <strong>Hierarchical</strong>: Creates dendrogram, no need to specify K</p>
<p> <strong>Linkage</strong>: Single (min), Complete (max), Average, Ward's</p>
<p> <strong>PCA</strong>: Find directions of maximum variance, reduce dimensions</p>
<p> <strong>Variance Explained</strong>: Choose k for 95% cumulative variance</p>
<p> <strong>Association Rules</strong>: Support, Confidence, Lift</p>
<p> <strong>Apriori</strong>: Frequent itemset mining using downward closure</p>
<p> <strong>Feature Scaling</strong>: Critical for K-Means and PCA</p>
<hr />
<p><strong>Previous</strong>: <a href="../module3-classification-evaluation/">Module 3 - Classification &amp; Evaluation</a> | <strong>Next</strong>: <a href="../module5-decision-trees/">Module 5 - Decision Trees</a></p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="December 16, 2025 17:08:48 UTC">December 16, 2025</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="December 15, 2025 19:52:44 UTC">December 15, 2025</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.annotate", "content.code.copy"], "search": "../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>