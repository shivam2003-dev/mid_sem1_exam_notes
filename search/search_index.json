{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Mid Semester 1 Exam Notes","text":"<p>Welcome to your comprehensive exam revision resource! This site contains detailed revision notes and step-by-step solutions to previous year papers.</p>"},{"location":"#available-subjects","title":"\ud83d\udcda Available Subjects","text":""},{"location":"#machine-learning","title":"Machine Learning","text":"<p>Complete revision notes covering all modules: - Module 1: Introduction to Machine Learning - Module 2: Supervised Learning (Linear Regression, Logistic Regression) - Module 3: Classification and Evaluation Metrics - Module 4: Unsupervised Learning (Clustering, Dimensionality Reduction) - Module 5: Decision Trees</p>"},{"location":"#deep-neural-networks-dnn","title":"Deep Neural Networks (DNN)","text":"<p>Complete revision notes covering all modules: - Module 1: Introduction to Neural Networks - Module 2: ANN &amp; Perceptron - Module 3: Linear NN Regression - Module 4: Linear NN Classification - Module 5: Deep Feedforward Neural Networks - Module 6: Convolutional Neural Networks (CNN)</p>"},{"location":"#solved-previous-year-papers","title":"\ud83d\udcdd Solved Previous Year Papers","text":"<ul> <li>2024 Regular Paper - Complete step-by-step solutions</li> <li>2024 Makeup Paper - Detailed explanations</li> <li>2025 Practice Set - Comprehensive solutions</li> </ul>"},{"location":"#how-to-use-this-site","title":"\ud83c\udfaf How to Use This Site","text":"<ol> <li>Review Module Notes: Start with the module notes to understand concepts</li> <li>Practice with Solved Papers: Work through previous year papers with detailed solutions</li> <li>Focus on Important Topics: Each module highlights key concepts and formulas</li> <li>Understand Step-by-Step Solutions: Learn problem-solving approaches</li> </ol>"},{"location":"#tips-for-exam-preparation","title":"\ud83d\udca1 Tips for Exam Preparation","text":"<ul> <li>Review all modules systematically</li> <li>Practice problems from previous year papers</li> <li>Focus on understanding concepts rather than memorization</li> <li>Pay special attention to formulas and their applications</li> <li>Review evaluation metrics and their interpretations</li> </ul> <p>Good luck with your exams! \ud83d\ude80</p>"},{"location":"dnn/","title":"Deep Neural Networks (DNN) - Complete Revision Guide","text":"<p>Welcome to the Deep Neural Networks revision guide. This section covers all modules with detailed explanations, formulas, and important concepts.</p>"},{"location":"dnn/#modules-overview","title":"\ud83d\udcd6 Modules Overview","text":"<ol> <li> <p>Module 1: Introduction to Neural Networks</p> <ul> <li>Introduction to Neural Networks</li> <li>Biological vs Artificial Neurons</li> <li>History and Evolution</li> <li>Applications of Neural Networks</li> </ul> </li> <li> <p>Module 2: ANN &amp; Perceptron</p> <ul> <li>Artificial Neural Networks (ANN)</li> <li>Perceptron Model</li> <li>Perceptron Learning Algorithm</li> <li>Limitations of Perceptron</li> </ul> </li> <li> <p>Module 3: Linear NN Regression</p> <ul> <li>Linear Neural Networks for Regression</li> <li>Forward Propagation</li> <li>Backpropagation Algorithm</li> <li>Gradient Computation</li> </ul> </li> <li> <p>Module 4: Linear NN Classification</p> <ul> <li>Linear Neural Networks for Classification</li> <li>Activation Functions (Sigmoid, Tanh, ReLU)</li> <li>Loss Functions for Classification</li> <li>Multi-class Classification</li> </ul> </li> <li> <p>Module 5: Deep Feedforward Neural Networks</p> <ul> <li>Deep Feedforward Networks</li> <li>Multi-layer Perceptron (MLP)</li> <li>Backpropagation in Deep Networks</li> <li>Vanishing/Exploding Gradients</li> <li>Regularization Techniques</li> </ul> </li> <li> <p>Module 6: Convolutional Neural Networks</p> <ul> <li>Introduction to CNNs</li> <li>Convolutional Layers</li> <li>Pooling Layers</li> <li>CNN Architecture</li> <li>Applications</li> </ul> </li> </ol>"},{"location":"dnn/#solved-previous-year-papers","title":"\ud83d\udcda Solved Previous Year Papers","text":"<ul> <li>2024 MidSem Regular Paper - Solved</li> <li>2024 EndSem Regular Paper - Solved</li> <li>2023 MidSem Regular Paper - Solved</li> <li>2023 EndSem Regular Paper - Solved</li> <li>2022 MidSem Makeup Paper - Solved</li> <li>2022 EndSem Regular Paper - Solved</li> </ul>"},{"location":"dnn/#important-topics-for-exam","title":"\ud83c\udfaf Important Topics for Exam","text":""},{"location":"dnn/#must-know-concepts","title":"Must Know Concepts","text":"<ul> <li>Perceptron Learning Algorithm</li> <li>Forward and Backward Propagation</li> <li>Activation Functions (Sigmoid, Tanh, ReLU, Softmax)</li> <li>Loss Functions (MSE, Cross-Entropy)</li> <li>Backpropagation Algorithm</li> <li>Gradient Descent and Variants</li> <li>Vanishing/Exploding Gradient Problem</li> <li>CNN Architecture Components</li> </ul>"},{"location":"dnn/#key-formulas","title":"Key Formulas","text":"<ul> <li>Perceptron Update Rule</li> <li>Forward Propagation Equations</li> <li>Backpropagation Gradient Formulas</li> <li>Activation Function Derivatives</li> <li>Loss Function Derivatives</li> <li>Weight Update Rules</li> </ul> <p>Start with Module 1 and work through systematically!</p>"},{"location":"dnn/cheatsheet/","title":"Deep Neural Networks Cheat Sheet","text":"<p>Quick reference guide for all important formulas, concepts, and algorithms in DNN.</p>"},{"location":"dnn/cheatsheet/#key-formulas","title":"\ud83d\udcd0 Key Formulas","text":""},{"location":"dnn/cheatsheet/#perceptron","title":"Perceptron","text":"<p>Output: $$ y = f(\\mathbf{w}^T \\mathbf{x} + b) $$</p> <p>Weight Update (Binary): $$ w_j := w_j + \\alpha \\cdot (y^{(i)} - \\hat{y}^{(i)}) \\cdot x_j^{(i)} $$</p> <p>Weight Update (Bipolar): $$ \\mathbf{w} := \\mathbf{w} + \\alpha \\cdot y^{(i)} \\cdot \\mathbf{x}^{(i)} \\quad \\text{(if misclassified)} $$</p> <p>Decision Boundary: $$ \\mathbf{w}^T \\mathbf{x} + b = 0 $$</p>"},{"location":"dnn/cheatsheet/#linear-nn-regression","title":"Linear NN Regression","text":"<p>Forward Propagation: $$ \\hat{y} = \\mathbf{w}^T \\mathbf{x} + b $$</p> <p>Loss Function (MSE): $$ J = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y<sup>{(i)})</sup>2 $$</p> <p>Gradients: $$ \\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\cdot x_j^{(i)} $$</p> \\[ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\]"},{"location":"dnn/cheatsheet/#linear-nn-classification","title":"Linear NN Classification","text":"<p>Binary Classification (Sigmoid): $$ \\hat{y} = \\sigma(\\mathbf{w}^T \\mathbf{x} + b) = \\frac{1}{1 + e<sup>{-(\\mathbf{w}</sup>T \\mathbf{x} + b)}} $$</p> <p>Loss (Binary Cross-Entropy): $$ J = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)})] $$</p> <p>Multi-Class (Softmax): $$ \\hat{y}_k = \\frac{e<sup>{z_k}}{\\sum_{j=1}</sup> $$} e^{z_j}</p> <p>Loss (Categorical Cross-Entropy): $$ J = -\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K} y_k^{(i)} \\log(\\hat{y}_k^{(i)}) $$</p>"},{"location":"dnn/cheatsheet/#activation-functions","title":"Activation Functions","text":"<p>Sigmoid: $$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$</p> <p>Sigmoid Derivative: $$ \\frac{d\\sigma}{dz} = \\sigma(z)(1 - \\sigma(z)) $$</p> <p>Tanh: $$ \\tanh(z) = \\frac{e^z - e<sup>{-z}}{e</sup>z + e^{-z}} $$</p> <p>Tanh Derivative: $$ \\frac{d\\tanh}{dz} = 1 - \\tanh^2(z) $$</p> <p>ReLU: $$ \\text{ReLU}(z) = \\max(0, z) $$</p> <p>ReLU Derivative: $$ \\frac{d\\text{ReLU}}{dz} = \\begin{cases} 1 &amp; \\text{if } z &gt; 0 \\ 0 &amp; \\text{if } z \\leq 0 \\end{cases} $$</p> <p>Softmax: $$ \\text{softmax}(z_i) = \\frac{e<sup>{z_i}}{\\sum_{j=1}</sup> $$} e^{z_j}</p>"},{"location":"dnn/cheatsheet/#deep-feedforward-networks","title":"Deep Feedforward Networks","text":"<p>Forward Propagation (Layer \\(l\\)): $$ \\mathbf{z}^{[l]} = \\mathbf{W}^{[l]} \\mathbf{a}^{[l-1]} + \\mathbf{b}^{[l]} $$</p> \\[ \\mathbf{a}^{[l]} = g^{[l]}(\\mathbf{z}^{[l]}) \\] <p>Backpropagation:</p> <p>Output Layer: $$ \\frac{\\partial J}{\\partial \\mathbf{z}^{[L]}} = \\hat{\\mathbf{y}} - \\mathbf{y} $$</p> <p>Hidden Layers: $$ \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} = (\\mathbf{W}<sup>{[l+1]})</sup>T \\frac{\\partial J}{\\partial \\mathbf{z}^{[l+1]}} \\odot g'<sup>{[l]}(\\mathbf{z}</sup>) $$</p> <p>Weights: $$ \\frac{\\partial J}{\\partial \\mathbf{W}^{[l]}} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} (\\mathbf{a}<sup>{[l-1]})</sup>T $$</p> <p>Bias: $$ \\frac{\\partial J}{\\partial \\mathbf{b}^{[l]}} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} $$</p> <p>L2 Regularization: $$ J_{\\text{reg}} = J + \\frac{\\lambda}{2m} \\sum_{l=1}^{L} ||\\mathbf{W}<sup>{[l]}||_F</sup>2 $$</p>"},{"location":"dnn/cheatsheet/#convolutional-neural-networks","title":"Convolutional Neural Networks","text":"<p>Convolution Operation: $$ \\text{Output}(i, j) = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} \\text{Input}(i+m, j+n) \\cdot \\text{Filter}(m, n) + b $$</p> <p>Output Size: $$ \\text{Output} = \\left\\lfloor \\frac{\\text{Input} - \\text{Filter} + 2 \\times \\text{Padding}}{\\text{Stride}} \\right\\rfloor + 1 $$</p> <p>Max Pooling: $$ \\text{Output}(i, j) = \\max_{m,n \\in \\text{window}} \\text{Input}(i+m, j+n) $$</p> <p>Average Pooling: $$ \\text{Output}(i, j) = \\frac{1}{k^2} \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} \\text{Input}(i+m, j+n) $$</p>"},{"location":"dnn/cheatsheet/#quick-reference","title":"\ud83c\udfaf Quick Reference","text":""},{"location":"dnn/cheatsheet/#perceptron-convergence","title":"Perceptron Convergence","text":"<ul> <li>Converges: If data is linearly separable</li> <li>Doesn't Converge: If data is not linearly separable (e.g., XOR)</li> </ul>"},{"location":"dnn/cheatsheet/#activation-function-selection","title":"Activation Function Selection","text":"Layer Type Recommended Activation Hidden Layers ReLU (most common) Binary Output Sigmoid Multi-class Output Softmax Regression Output Linear (identity)"},{"location":"dnn/cheatsheet/#gradient-problems","title":"Gradient Problems","text":"<p>Vanishing Gradient: - Cause: Small activation derivatives (sigmoid, tanh) - Solution: Use ReLU, proper initialization, batch norm</p> <p>Exploding Gradient: - Cause: Large weights, many layers - Solution: Gradient clipping, proper initialization</p>"},{"location":"dnn/cheatsheet/#weight-initialization","title":"Weight Initialization","text":"<p>He Initialization (for ReLU): $$ W_{ij} \\sim \\mathcal{N}\\left(0, \\frac{2}{n^{[l-1]}}\\right) $$</p> <p>Xavier Initialization (for tanh/sigmoid): $$ W_{ij} \\sim \\mathcal{N}\\left(0, \\frac{1}{n^{[l-1]}}\\right) $$</p>"},{"location":"dnn/cheatsheet/#common-mistakes-to-avoid","title":"\u26a0\ufe0f Common Mistakes to Avoid","text":"<ol> <li>Using MSE for classification (use cross-entropy instead)</li> <li>Using sigmoid in hidden layers (use ReLU)</li> <li>Initializing all weights to zero (breaks symmetry)</li> <li>Forgetting bias term in calculations</li> <li>Wrong gradient sign (should be \\(-\\alpha\\) for gradient descent)</li> <li>Not handling ReLU derivative at \\(z=0\\) (define as 0)</li> <li>Confusing convolution with correlation in backpropagation</li> </ol>"},{"location":"dnn/cheatsheet/#exam-tips","title":"\ud83d\udca1 Exam Tips","text":"<ol> <li>Memorize activation derivatives: Especially sigmoid and ReLU</li> <li>Practice backpropagation: Show chain rule step-by-step</li> <li>Know perceptron algorithm: Step-by-step weight updates</li> <li>Understand gradient flow: How gradients propagate backward</li> <li>CNN calculations: Practice convolution and pooling operations</li> <li>Know when to use what: ReLU vs sigmoid, MSE vs cross-entropy</li> </ol> <p>Print this page for quick reference during exam preparation! \ud83d\udcc4</p>"},{"location":"dnn/module1-introduction/","title":"Module 1: Introduction to Neural Networks","text":""},{"location":"dnn/module1-introduction/#overview","title":"Overview","text":"<p>This module introduces the fundamental concepts of neural networks, their biological inspiration, historical evolution, and modern applications.</p>"},{"location":"dnn/module1-introduction/#what-are-neural-networks","title":"What are Neural Networks?","text":"<p>Definition</p> <p>Neural Networks are computational models inspired by biological neural networks in animal brains. They consist of interconnected nodes (artificial neurons) that process information through weighted connections.</p>"},{"location":"dnn/module1-introduction/#the-big-picture","title":"The Big Picture","text":"<pre><code>Traditional Programming:\n    Rules + Data \u2192 Computer \u2192 Output\n\nMachine Learning:\n    Data + Output \u2192 Computer \u2192 Rules\n\nNeural Networks:\n    Data \u2192 Network learns hierarchical representations \u2192 Output\n</code></pre> <p>Key Insight</p> <p>Neural networks automatically learn feature representations from raw data, eliminating the need for manual feature engineering.</p>"},{"location":"dnn/module1-introduction/#biological-vs-artificial-neurons","title":"Biological vs Artificial Neurons","text":""},{"location":"dnn/module1-introduction/#biological-neuron","title":"Biological Neuron","text":"<pre><code>                    Axon Terminal\n                         \u2502\n    Dendrites           \u2502\n        \\    Cell Body  \u2502\n         \\      \u2502      \u2502\n          \\\u2500\u2500\u2500\u2500(\u25cf)\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 To other neurons\n         /      \u2502\n        /    Axon\n    Dendrites\n</code></pre> <p>Components:</p> Part Function Analogy Dendrites Receive signals from other neurons Input wires Cell Body (Soma) Processes incoming signals Processor Axon Transmits output signal Output wire Synapses Connections between neurons Weighted connections <p>Process: 1. Dendrites receive input signals from other neurons 2. Cell body sums the signals 3. If sum exceeds threshold \u2192 neuron \"fires\" (action potential) 4. Signal travels down axon to other neurons</p>"},{"location":"dnn/module1-introduction/#artificial-neuron-perceptron","title":"Artificial Neuron (Perceptron)","text":"<pre><code>    Inputs          Weights         Sum          Activation    Output\n\n    x\u2081 \u2500\u2500\u2500\u2500\u2500\u2500\u2192 \u00d7w\u2081 \u2500\u2500\u2510\n                      \u2502\n    x\u2082 \u2500\u2500\u2500\u2500\u2500\u2500\u2192 \u00d7w\u2082 \u2500\u2500\u253c\u2500\u2500\u2192 [\u03a3 + b] \u2500\u2500\u2192 [f(z)] \u2500\u2500\u2192 y\n                      \u2502\n    x\u2083 \u2500\u2500\u2500\u2500\u2500\u2500\u2192 \u00d7w\u2083 \u2500\u2500\u2518\n</code></pre> <p>Components:</p> Component Symbol Description Inputs \\(x_1, x_2, ..., x_n\\) Features (like dendrites) Weights \\(w_1, w_2, ..., w_n\\) Synapse strength Bias \\(b\\) Threshold adjustment Weighted Sum \\(z = \\sum w_i x_i + b\\) Linear combination Activation \\(f(z)\\) Non-linear transformation Output \\(y = f(z)\\) Final output"},{"location":"dnn/module1-introduction/#mathematical-model","title":"Mathematical Model","text":"\\[ y = f\\left(\\sum_{i=1}^{n} w_i x_i + b\\right) = f(\\mathbf{w}^T \\mathbf{x} + b) \\] <p>Where: - \\(\\mathbf{w} = [w_1, w_2, \\ldots, w_n]^T\\) = weight vector - \\(\\mathbf{x} = [x_1, x_2, \\ldots, x_n]^T\\) = input vector - \\(b\\) = bias term - \\(f\\) = activation function</p> <p>Exam Tip</p> <p>The bias \\(b\\) allows the neuron to shift the activation function, enabling it to fit data that doesn't pass through the origin.</p>"},{"location":"dnn/module1-introduction/#comparison-table","title":"Comparison Table","text":"Aspect Biological Artificial Speed ~100 Hz ~10\u2079 Hz (GPU) Parallelism Massively parallel Parallel (limited) Learning Continuous, adaptive Batch/online training Energy ~20 Watts (brain) ~250+ Watts (GPU) Connections ~10\u00b9\u2074 synapses Millions-billions"},{"location":"dnn/module1-introduction/#history-and-evolution-of-neural-networks","title":"History and Evolution of Neural Networks","text":""},{"location":"dnn/module1-introduction/#timeline","title":"Timeline","text":"<pre><code>1943 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 Present\n\n1943: McCulloch-Pitts Neuron (First mathematical model)\n      \u2502\n1958: Perceptron (Rosenblatt) - First learning algorithm\n      \u2502\n1969: Minsky &amp; Papert - XOR problem, AI Winter begins\n      \u2502\n1986: Backpropagation (Rumelhart, Hinton, Williams)\n      \u2502\n1998: LeNet-5 (LeCun) - First successful CNN\n      \u2502\n2006: Deep Learning Renaissance (Hinton)\n      \u2502\n2012: AlexNet - ImageNet breakthrough\n      \u2502\n2014: GANs (Goodfellow), VGG, GoogLeNet\n      \u2502\n2015: ResNet - Very deep networks\n      \u2502\n2017: Transformers - Attention mechanism\n      \u2502\n2020+: GPT-3, DALL-E, ChatGPT - Large language models\n</code></pre>"},{"location":"dnn/module1-introduction/#key-milestones-explained","title":"Key Milestones Explained","text":""},{"location":"dnn/module1-introduction/#1943-mcculloch-pitts-neuron","title":"1943: McCulloch-Pitts Neuron","text":"<ul> <li>First mathematical model of a neuron</li> <li>Binary threshold function</li> <li>Showed neurons can compute logical functions</li> </ul>"},{"location":"dnn/module1-introduction/#1958-perceptron-frank-rosenblatt","title":"1958: Perceptron (Frank Rosenblatt)","text":"<ul> <li>First learning algorithm for neural networks</li> <li>Could learn simple patterns from data</li> <li>Generated enormous excitement</li> </ul>"},{"location":"dnn/module1-introduction/#1969-the-xor-problem-minsky-papert","title":"1969: The XOR Problem (Minsky &amp; Papert)","text":"<p>The Problem</p> <p>Single-layer perceptrons cannot solve non-linearly separable problems like XOR.</p> \\(x_1\\) \\(x_2\\) XOR 0 0 0 0 1 1 1 0 1 1 1 0 <pre><code>x\u2082\n1 \u2502  \u25cf     \u25cb\n  \u2502     \u2717 (No single line can separate!)\n0 \u2502  \u25cb     \u25cf\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 x\u2081\n    0     1\n</code></pre> <p>Impact: Led to \"AI Winter\" - reduced funding and interest</p>"},{"location":"dnn/module1-introduction/#1986-backpropagation","title":"1986: Backpropagation","text":"<ul> <li>Efficient algorithm to train multi-layer networks</li> <li>Enabled learning non-linear patterns</li> <li>Solved XOR and much more!</li> </ul>"},{"location":"dnn/module1-introduction/#2012-alexnet-imagenet-breakthrough","title":"2012: AlexNet (ImageNet Breakthrough)","text":"<ul> <li>Deep CNN with 8 layers</li> <li>Won ImageNet competition by large margin</li> <li>Used ReLU, dropout, GPU training</li> <li>Sparked modern deep learning revolution</li> </ul>"},{"location":"dnn/module1-introduction/#types-of-neural-networks","title":"Types of Neural Networks","text":""},{"location":"dnn/module1-introduction/#1-feedforward-neural-networks-fnn","title":"1. Feedforward Neural Networks (FNN)","text":"<p>Structure: Information flows in one direction only (input \u2192 output)</p> <pre><code>Input Layer    Hidden Layers    Output Layer\n    \u25cb              \u25cb                \u25cb\n    \u25cb    \u2192\u2192\u2192       \u25cb      \u2192\u2192\u2192       \u25cb\n    \u25cb              \u25cb                \u25cb\n</code></pre> <p>Subtypes: - Single-layer Perceptron: Input \u2192 Output (no hidden layers) - Multi-layer Perceptron (MLP): Input \u2192 Hidden \u2192 Output</p> <p>Applications: Classification, regression, pattern recognition</p>"},{"location":"dnn/module1-introduction/#2-convolutional-neural-networks-cnn","title":"2. Convolutional Neural Networks (CNN)","text":"<p>Structure: Specialized for grid-like data (images)</p> <pre><code>Image \u2192 [Conv] \u2192 [Pool] \u2192 [Conv] \u2192 [Pool] \u2192 [FC] \u2192 Output\n</code></pre> <p>Key Features: - Convolutional layers: Detect local patterns (edges, textures) - Pooling layers: Reduce spatial dimensions - Parameter sharing: Same filter across image</p> <p>Applications: Image recognition, object detection, medical imaging</p>"},{"location":"dnn/module1-introduction/#3-recurrent-neural-networks-rnn","title":"3. Recurrent Neural Networks (RNN)","text":"<p>Structure: Connections form cycles (feedback loops)</p> <pre><code>    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                 \u2502\n    \u2193                 \u2502\n[Input] \u2192 [Hidden] \u2192 [Output]\n              \u2191\n              \u2502\n         (Previous state)\n</code></pre> <p>Variants: - Simple RNN: Basic recurrent structure - LSTM: Long Short-Term Memory (handles long sequences) - GRU: Gated Recurrent Unit (simplified LSTM)</p> <p>Applications: NLP, speech recognition, time series</p>"},{"location":"dnn/module1-introduction/#4-transformers","title":"4. Transformers","text":"<p>Structure: Based on attention mechanism</p> <p>Key Innovation: Self-attention allows looking at all positions simultaneously</p> <p>Applications: GPT, BERT, language models, translation</p>"},{"location":"dnn/module1-introduction/#5-other-architectures","title":"5. Other Architectures","text":"Type Description Use Case Autoencoders Encode-decode structure Compression, denoising GANs Generator vs Discriminator Image generation Graph Neural Networks Process graph data Social networks, molecules"},{"location":"dnn/module1-introduction/#comparison-of-network-types","title":"Comparison of Network Types","text":"Type Input Strength Weakness FNN/MLP Fixed-size vectors Simple, fast No spatial/temporal structure CNN Images, grids Translation invariance Fixed input size RNN Sequences Variable length Vanishing gradients Transformer Sequences Parallelizable, long-range Quadratic complexity"},{"location":"dnn/module1-introduction/#applications-of-neural-networks","title":"Applications of Neural Networks","text":""},{"location":"dnn/module1-introduction/#computer-vision","title":"Computer Vision","text":"Application Description Example Image Classification Assign label to image \"This is a cat\" Object Detection Locate and classify objects Self-driving cars Semantic Segmentation Pixel-level classification Medical imaging Face Recognition Identify individuals Phone unlock Image Generation Create new images DALL-E, Midjourney"},{"location":"dnn/module1-introduction/#natural-language-processing","title":"Natural Language Processing","text":"Application Description Example Machine Translation Translate between languages Google Translate Text Generation Generate coherent text ChatGPT Sentiment Analysis Detect emotion in text Review analysis Named Entity Recognition Identify entities Find names, dates Question Answering Answer questions Virtual assistants"},{"location":"dnn/module1-introduction/#speech-and-audio","title":"Speech and Audio","text":"Application Description Example Speech Recognition Convert speech to text Siri, Alexa Text-to-Speech Generate speech from text Voice assistants Music Generation Create music AI composers"},{"location":"dnn/module1-introduction/#other-domains","title":"Other Domains","text":"Domain Applications Healthcare Disease diagnosis, drug discovery, medical imaging Finance Fraud detection, trading, risk assessment Gaming Game AI, character behavior Robotics Control, navigation, manipulation Science Protein folding (AlphaFold), physics simulations"},{"location":"dnn/module1-introduction/#advantages-of-neural-networks","title":"Advantages of Neural Networks","text":"Advantage Description \u2705 Non-linearity Can model complex, non-linear relationships \u2705 Feature Learning Automatically learns relevant features \u2705 Adaptability Can learn from data without explicit programming \u2705 Generalization Can generalize to unseen data \u2705 Parallel Processing Can process multiple inputs simultaneously \u2705 Universal Approximation Can approximate any continuous function <p>Universal Approximation Theorem</p> <p>A feedforward network with a single hidden layer containing a finite number of neurons can approximate any continuous function on compact subsets of \\(\\mathbb{R}^n\\).</p>"},{"location":"dnn/module1-introduction/#limitations-of-neural-networks","title":"Limitations of Neural Networks","text":"Limitation Description Mitigation \u274c Black Box Difficult to interpret decisions Explainability techniques \u274c Data Hungry Need large amounts of training data Transfer learning, data augmentation \u274c Computationally Expensive Training requires significant resources GPUs, TPUs, efficient architectures \u274c Overfitting May memorize training data Regularization, dropout \u274c Hyperparameter Sensitivity Many parameters to tune AutoML, hyperparameter search \u274c Local Minima May get stuck in suboptimal solutions Better initialization, optimizers"},{"location":"dnn/module1-introduction/#key-concepts-summary","title":"Key Concepts Summary","text":""},{"location":"dnn/module1-introduction/#learning-paradigms","title":"Learning Paradigms","text":"Paradigm Data Goal Example Supervised Labeled (X, y) Predict y from X Image classification Unsupervised Unlabeled (X) Find patterns Clustering Reinforcement Rewards Maximize reward Game playing Self-supervised Unlabeled (create labels) Learn representations GPT pretraining"},{"location":"dnn/module1-introduction/#training-process-overview","title":"Training Process Overview","text":"<pre><code>1. Forward Propagation\n   Input \u2192 Network \u2192 Prediction\n\n2. Loss Calculation\n   Loss = f(Prediction, Target)\n\n3. Backward Propagation\n   Compute gradients: \u2202Loss/\u2202Weights\n\n4. Weight Update\n   Weights = Weights - \u03b1 \u00d7 Gradients\n\n5. Repeat until convergence\n</code></pre>"},{"location":"dnn/module1-introduction/#common-exam-questions","title":"Common Exam Questions","text":"<p>Q1: Compare biological and artificial neurons</p> Aspect Biological Artificial Input Dendrites Input features Processing Cell body Weighted sum + activation Output Axon Single output value Connection strength Synapse Weights Threshold Firing threshold Bias <p>Q2: Why couldn't single-layer perceptrons solve XOR?</p> <p>XOR is not linearly separable - no single straight line can separate the classes. Single-layer perceptrons can only learn linear decision boundaries. Solution: Use multi-layer networks with hidden layers.</p> <p>Q3: What is the Universal Approximation Theorem?</p> <p>A feedforward network with one hidden layer and sufficient neurons can approximate any continuous function to arbitrary accuracy. However, it doesn't guarantee: - The network can be trained efficiently - The network will generalize well - The number of neurons is practical</p> <p>Q4: List different types of neural networks and their applications</p> <ul> <li>FNN/MLP: Classification, regression</li> <li>CNN: Image recognition, computer vision</li> <li>RNN/LSTM: Sequence modeling, NLP, time series</li> <li>Transformers: Language models, translation</li> <li>GANs: Image generation</li> <li>Autoencoders: Compression, denoising</li> </ul>"},{"location":"dnn/module1-introduction/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 Neural Networks: Computational models inspired by biological neurons</p> <p>\u2705 Artificial Neuron: \\(y = f(\\mathbf{w}^T \\mathbf{x} + b)\\) - weighted sum with activation</p> <p>\u2705 History: McCulloch-Pitts (1943) \u2192 Perceptron (1958) \u2192 Backprop (1986) \u2192 Deep Learning (2012+)</p> <p>\u2705 XOR Problem: Single-layer cannot solve; need hidden layers</p> <p>\u2705 Types: Feedforward (MLP), Convolutional (CNN), Recurrent (RNN), Transformers</p> <p>\u2705 Applications: Computer vision, NLP, speech, healthcare, finance</p> <p>\u2705 Advantages: Non-linearity, feature learning, universal approximation</p> <p>\u2705 Limitations: Black box, data hungry, computationally expensive</p> <p>\u2705 Training: Forward prop \u2192 Loss \u2192 Backward prop \u2192 Update weights</p> <p>Next: Module 2 - ANN &amp; Perceptron</p>"},{"location":"dnn/module2-ann-perceptron/","title":"Module 2: ANN &amp; Perceptron","text":""},{"location":"dnn/module2-ann-perceptron/#overview","title":"Overview","text":"<p>This module covers Artificial Neural Networks (ANN) and the fundamental Perceptron model, including its learning algorithm and limitations.</p>"},{"location":"dnn/module2-ann-perceptron/#artificial-neural-networks-ann","title":"Artificial Neural Networks (ANN)","text":""},{"location":"dnn/module2-ann-perceptron/#definition","title":"Definition","text":"<p>Artificial Neural Network (ANN) is a computational model inspired by biological neural networks. It consists of interconnected nodes (neurons) organized in layers.</p>"},{"location":"dnn/module2-ann-perceptron/#basic-structure","title":"Basic Structure","text":"<p>Components: - Input Layer: Receives input data - Hidden Layers: Process information (optional) - Output Layer: Produces final output - Connections: Weighted links between neurons</p> <p>Architecture:</p> <pre><code>Input Layer    Hidden Layer    Output Layer\n    x\u2081 \u2500\u2500\u2500\u2500\u2500\u2500\u2192     h\u2081    \u2500\u2500\u2500\u2500\u2500\u2500\u2192    y\u2081\n    x\u2082 \u2500\u2500\u2500\u2500\u2500\u2500\u2192     h\u2082    \u2500\u2500\u2500\u2500\u2500\u2500\u2192    y\u2082\n    x\u2083 \u2500\u2500\u2500\u2500\u2500\u2500\u2192     h\u2083\n</code></pre>"},{"location":"dnn/module2-ann-perceptron/#perceptron-model","title":"Perceptron Model","text":""},{"location":"dnn/module2-ann-perceptron/#single-perceptron","title":"Single Perceptron","text":"<p>Definition: A single-layer neural network with one output neuron.</p> <p>Mathematical Model:</p> \\[ y = f\\left(\\sum_{i=1}^{n} w_i x_i + b\\right) = f(\\mathbf{w}^T \\mathbf{x} + b) \\] <p>Where: - \\(x_i\\) = input \\(i\\) - \\(w_i\\) = weight for input \\(i\\) - \\(b\\) = bias term - \\(f\\) = activation function - \\(y\\) = output</p>"},{"location":"dnn/module2-ann-perceptron/#activation-function","title":"Activation Function","text":"<p>Step Function (Binary):</p> \\[ f(z) = \\begin{cases} 1 &amp; \\text{if } z \\geq 0 \\\\ 0 &amp; \\text{if } z &lt; 0 \\end{cases} \\] <p>Sign Function (Bipolar):</p> \\[ f(z) = \\begin{cases} +1 &amp; \\text{if } z \\geq 0 \\\\ -1 &amp; \\text{if } z &lt; 0 \\end{cases} \\]"},{"location":"dnn/module2-ann-perceptron/#decision-boundary","title":"Decision Boundary","text":"<p>For a perceptron with step function:</p> \\[ \\mathbf{w}^T \\mathbf{x} + b = 0 \\] <p>This defines a hyperplane that separates classes.</p> <p>For 2D case: $$ w_1 x_1 + w_2 x_2 + b = 0 $$</p> <p>This is a line separating the two classes.</p>"},{"location":"dnn/module2-ann-perceptron/#perceptron-learning-algorithm","title":"Perceptron Learning Algorithm","text":""},{"location":"dnn/module2-ann-perceptron/#algorithm-steps","title":"Algorithm Steps","text":"<p>Given: - Training examples: \\(\\{(\\mathbf{x}^{(1)}, y^{(1)}), (\\mathbf{x}^{(2)}, y^{(2)}), \\ldots, (\\mathbf{x}^{(m)}, y^{(m)})\\}\\) - Learning rate: \\(\\alpha\\) (typically 0.1 or 1.0)</p> <p>Steps:</p> <ol> <li>Initialize: Set weights and bias to small random values (or zeros)</li> <li>\\(\\mathbf{w} = [w_1, w_2, \\ldots, w_n]^T\\)</li> <li> <p>\\(b = 0\\) (or small random value)</p> </li> <li> <p>For each training example \\((\\mathbf{x}^{(i)}, y^{(i)})\\):</p> </li> </ol> <p>a. Compute output:    $$    z^{(i)} = \\mathbf{w}^T \\mathbf{x}^{(i)} + b $$    $$    \\hat{y}^{(i)} = f(z^{(i)}) $$</p> <p>b. Update weights if error:    $$    \\text{If } \\hat{y}^{(i)} \\neq y^{(i)} \\text{ then:} $$    $$    w_j := w_j + \\alpha \\cdot (y^{(i)} - \\hat{y}^{(i)}) \\cdot x_j^{(i)} $$    $$    b := b + \\alpha \\cdot (y^{(i)} - \\hat{y}^{(i)}) $$</p> <ol> <li>Repeat: Until all examples are classified correctly (or max iterations)</li> </ol>"},{"location":"dnn/module2-ann-perceptron/#update-rule-vectorized","title":"Update Rule (Vectorized)","text":"<p>For binary classification (\\(y \\in \\{0, 1\\}\\)):</p> \\[ \\mathbf{w} := \\mathbf{w} + \\alpha \\cdot (y^{(i)} - \\hat{y}^{(i)}) \\cdot \\mathbf{x}^{(i)} \\] \\[ b := b + \\alpha \\cdot (y^{(i)} - \\hat{y}^{(i)}) \\] <p>For bipolar classification (\\(y \\in \\{-1, +1\\}\\)):</p> \\[ \\mathbf{w} := \\mathbf{w} + \\alpha \\cdot y^{(i)} \\cdot \\mathbf{x}^{(i)} \\quad \\text{(if misclassified)} \\] \\[ b := b + \\alpha \\cdot y^{(i)} \\] <p>Key Point</p> <p>The perceptron only updates weights when there's a misclassification. If the prediction is correct, no update occurs.</p> <p>Learning Rate</p> <p>A smaller learning rate (\\(\\alpha = 0.1\\)) provides smoother convergence, while a larger rate (\\(\\alpha = 1.0\\)) may converge faster but could overshoot.</p>"},{"location":"dnn/module2-ann-perceptron/#perceptron-convergence-theorem","title":"Perceptron Convergence Theorem","text":""},{"location":"dnn/module2-ann-perceptron/#statement","title":"Statement","text":"<p>If the training data is linearly separable, the perceptron learning algorithm will converge to a solution in a finite number of steps.</p> <p>Conditions: - Data must be linearly separable - Learning rate \\(\\alpha &gt; 0\\) - Weights initialized to zeros or small values</p> <p>Implications: - Guaranteed to find separating hyperplane if one exists - Number of updates is bounded - Convergence is guaranteed (not just probable)</p> <p>Important</p> <p>The perceptron will NOT converge if the data is not linearly separable. It will keep updating weights indefinitely.</p>"},{"location":"dnn/module2-ann-perceptron/#limitations-of-perceptron","title":"Limitations of Perceptron","text":""},{"location":"dnn/module2-ann-perceptron/#1-linearly-separable-data-only","title":"1. Linearly Separable Data Only","text":"<p>Problem: Perceptron can only learn linearly separable patterns.</p> <p>Example - XOR Problem:</p> \\(x_1\\) \\(x_2\\) \\(x_1\\) XOR \\(x_2\\) 0 0 0 0 1 1 1 0 1 1 1 0 <p>Visualization: <pre><code>x\u2082\n1 |  \u25cf     \u25cb\n  |    \u2717\n0 |  \u25cb     \u25cf\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 x\u2081\n    0    1\n</code></pre></p> <p>No single line can separate the classes!</p> <p>Solution: Need multi-layer networks (MLP)</p>"},{"location":"dnn/module2-ann-perceptron/#2-binary-classification-only","title":"2. Binary Classification Only","text":"<ul> <li>Single perceptron can only classify into 2 classes</li> <li>For multi-class, need multiple perceptrons or softmax</li> </ul>"},{"location":"dnn/module2-ann-perceptron/#3-no-probabilistic-output","title":"3. No Probabilistic Output","text":"<ul> <li>Output is binary (0 or 1)</li> <li>Cannot provide confidence/probability</li> <li>Need sigmoid/softmax for probabilities</li> </ul>"},{"location":"dnn/module2-ann-perceptron/#4-sensitive-to-feature-scaling","title":"4. Sensitive to Feature Scaling","text":"<ul> <li>Features should be normalized</li> <li>Large input values can cause issues</li> </ul>"},{"location":"dnn/module2-ann-perceptron/#multi-layer-perceptron-mlp","title":"Multi-Layer Perceptron (MLP)","text":""},{"location":"dnn/module2-ann-perceptron/#solution-to-xor-problem","title":"Solution to XOR Problem","text":"<p>Architecture: - Input Layer: 2 neurons (\\(x_1\\), \\(x_2\\)) - Hidden Layer: 2 neurons (with non-linear activation) - Output Layer: 1 neuron</p> <p>Key: Hidden layer allows learning non-linear decision boundaries.</p> <p>XOR Solution with MLP:</p> \\[ h_1 = f(w_{11}x_1 + w_{12}x_2 + b_1) \\] \\[ h_2 = f(w_{21}x_1 + w_{22}x_2 + b_2) \\] \\[ y = f(w_1 h_1 + w_2 h_2 + b) \\] <p>With appropriate weights, this can solve XOR!</p>"},{"location":"dnn/module2-ann-perceptron/#perceptron-example","title":"Perceptron Example","text":""},{"location":"dnn/module2-ann-perceptron/#problem","title":"Problem","text":"<p>Classify points as class 1 or class 0:</p> <ul> <li>\\((1, 1)\\) \u2192 Class 1</li> <li>\\((2, 2)\\) \u2192 Class 1</li> <li>\\((0, 0)\\) \u2192 Class 0</li> <li>\\((1, 0)\\) \u2192 Class 0</li> </ul>"},{"location":"dnn/module2-ann-perceptron/#solution","title":"Solution","text":"<p>Initialization: - \\(w_1 = 0\\), \\(w_2 = 0\\), \\(b = 0\\) - \\(\\alpha = 1.0\\) - Activation: Step function</p> <p>Iteration 1: - Input: \\((1, 1)\\), Target: \\(1\\) - \\(z = 0 \\cdot 1 + 0 \\cdot 1 + 0 = 0\\) - \\(\\hat{y} = f(0) = 1\\) \u2713 (Correct, no update)</p> <p>Iteration 2: - Input: \\((2, 2)\\), Target: \\(1\\) - \\(z = 0 \\cdot 2 + 0 \\cdot 2 + 0 = 0\\) - \\(\\hat{y} = 1\\) \u2713 (Correct, no update)</p> <p>Iteration 3: - Input: \\((0, 0)\\), Target: \\(0\\) - \\(z = 0\\), \\(\\hat{y} = 1\\) \u2717 (Wrong!) - Update: \\(w_1 = 0 + 1 \\cdot (0 - 1) \\cdot 0 = 0\\) - Update: \\(w_2 = 0 + 1 \\cdot (0 - 1) \\cdot 0 = 0\\) - Update: \\(b = 0 + 1 \\cdot (0 - 1) = -1\\)</p> <p>After updates: \\(w_1 = 0\\), \\(w_2 = 0\\), \\(b = -1\\)</p> <p>Continue iterations until convergence...</p>"},{"location":"dnn/module2-ann-perceptron/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"dnn/module2-ann-perceptron/#perceptron-output","title":"Perceptron Output","text":"\\[ y = f(\\mathbf{w}^T \\mathbf{x} + b) \\]"},{"location":"dnn/module2-ann-perceptron/#weight-update-binary","title":"Weight Update (Binary)","text":"\\[ w_j := w_j + \\alpha \\cdot (y^{(i)} - \\hat{y}^{(i)}) \\cdot x_j^{(i)} \\] \\[ b := b + \\alpha \\cdot (y^{(i)} - \\hat{y}^{(i)}) \\]"},{"location":"dnn/module2-ann-perceptron/#weight-update-bipolar","title":"Weight Update (Bipolar)","text":"\\[ \\mathbf{w} := \\mathbf{w} + \\alpha \\cdot y^{(i)} \\cdot \\mathbf{x}^{(i)} \\quad \\text{(if misclassified)} \\]"},{"location":"dnn/module2-ann-perceptron/#decision-boundary_1","title":"Decision Boundary","text":"\\[ \\mathbf{w}^T \\mathbf{x} + b = 0 \\]"},{"location":"dnn/module2-ann-perceptron/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 Perceptron: Single-layer neural network for binary classification</p> <p>\u2705 Learning Algorithm: Updates weights only on misclassification</p> <p>\u2705 Convergence: Guaranteed if data is linearly separable</p> <p>\u2705 Limitation: Cannot solve non-linearly separable problems (e.g., XOR)</p> <p>\u2705 Solution: Multi-layer networks (MLP) can solve XOR</p> <p>\u2705 Activation: Step function for binary, sign function for bipolar</p> <p>Previous: Module 1 - Introduction | Next: Module 3 - Linear NN Regression</p>"},{"location":"dnn/module3-linear-nn-regression/","title":"Module 3: Linear Neural Networks for Regression","text":""},{"location":"dnn/module3-linear-nn-regression/#overview","title":"Overview","text":"<p>This module covers linear neural networks used for regression tasks, including forward propagation, backpropagation, and gradient computation.</p>"},{"location":"dnn/module3-linear-nn-regression/#linear-neural-network-for-regression","title":"Linear Neural Network for Regression","text":""},{"location":"dnn/module3-linear-nn-regression/#architecture","title":"Architecture","text":"<p>Structure: - Input Layer: \\(n\\) input features - Output Layer: 1 neuron (continuous output) - No Hidden Layers: Direct mapping from input to output</p> <p>Mathematical Model:</p> \\[ \\hat{y} = \\mathbf{w}^T \\mathbf{x} + b = \\sum_{i=1}^{n} w_i x_i + b \\] <p>Where: - \\(\\mathbf{x} = [x_1, x_2, \\ldots, x_n]^T\\) (input vector) - \\(\\mathbf{w} = [w_1, w_2, \\ldots, w_n]^T\\) (weight vector) - \\(b\\) = bias term - \\(\\hat{y}\\) = predicted output (continuous value)</p>"},{"location":"dnn/module3-linear-nn-regression/#difference-from-perceptron","title":"Difference from Perceptron","text":"<ul> <li>Perceptron: Binary classification, step activation</li> <li>Linear NN Regression: Continuous output, linear activation (identity function)</li> </ul>"},{"location":"dnn/module3-linear-nn-regression/#forward-propagation","title":"Forward Propagation","text":""},{"location":"dnn/module3-linear-nn-regression/#process","title":"Process","text":"<p>Step 1: Compute weighted sum</p> \\[ z = \\mathbf{w}^T \\mathbf{x} + b = \\sum_{i=1}^{n} w_i x_i + b \\] <p>Step 2: Apply activation function (for regression, often identity)</p> \\[ \\hat{y} = f(z) = z \\quad \\text{(Linear/Identity activation)} \\] <p>Vectorized Form (for batch of \\(m\\) examples):</p> \\[ \\mathbf{Z} = \\mathbf{X} \\mathbf{w} + \\mathbf{b} \\] \\[ \\hat{\\mathbf{Y}} = \\mathbf{Z} \\] <p>Where: - \\(\\mathbf{X}\\) = \\(m \\times n\\) input matrix - \\(\\mathbf{w}\\) = \\(n \\times 1\\) weight vector - \\(\\mathbf{b}\\) = \\(m \\times 1\\) bias vector (all elements = \\(b\\)) - \\(\\hat{\\mathbf{Y}}\\) = \\(m \\times 1\\) output vector</p>"},{"location":"dnn/module3-linear-nn-regression/#loss-function","title":"Loss Function","text":""},{"location":"dnn/module3-linear-nn-regression/#mean-squared-error-mse","title":"Mean Squared Error (MSE)","text":"<p>For single example:</p> \\[ L(\\hat{y}, y) = \\frac{1}{2}(\\hat{y} - y)^2 \\] <p>For \\(m\\) training examples:</p> \\[ J(\\mathbf{w}, b) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 \\] \\[ J(\\mathbf{w}, b) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\mathbf{w}^T \\mathbf{x}^{(i)} + b - y^{(i)})^2 \\] <p>Why \\(\\frac{1}{2}\\)?: Makes derivative cleaner (the 2 cancels out)</p> <p>Important</p> <p>The factor \\(\\frac{1}{2}\\) doesn't change the optimal solution, but simplifies gradient calculations.</p>"},{"location":"dnn/module3-linear-nn-regression/#backpropagation-algorithm","title":"Backpropagation Algorithm","text":""},{"location":"dnn/module3-linear-nn-regression/#goal","title":"Goal","text":"<p>Minimize the loss function by computing gradients and updating weights.</p>"},{"location":"dnn/module3-linear-nn-regression/#gradient-computation","title":"Gradient Computation","text":"<p>For weight \\(w_j\\):</p> \\[ \\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\cdot x_j^{(i)} \\] <p>For bias \\(b\\):</p> \\[ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\]"},{"location":"dnn/module3-linear-nn-regression/#derivation","title":"Derivation","text":"<p>Chain Rule Application:</p> \\[ \\frac{\\partial J}{\\partial w_j} = \\frac{\\partial J}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w_j} \\] <p>Step 1: \\(\\frac{\\partial J}{\\partial \\hat{y}} = \\hat{y} - y\\)</p> <p>Step 2: \\(\\frac{\\partial \\hat{y}}{\\partial z} = 1\\) (linear activation)</p> <p>Step 3: \\(\\frac{\\partial z}{\\partial w_j} = x_j\\)</p> <p>Combined:</p> \\[ \\frac{\\partial J}{\\partial w_j} = (\\hat{y} - y) \\cdot 1 \\cdot x_j = (\\hat{y} - y) \\cdot x_j \\] <p>For \\(m\\) examples:</p> \\[ \\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\cdot x_j^{(i)} \\]"},{"location":"dnn/module3-linear-nn-regression/#gradient-descent-update","title":"Gradient Descent Update","text":""},{"location":"dnn/module3-linear-nn-regression/#update-rules","title":"Update Rules","text":"<p>Weight Update:</p> \\[ w_j := w_j - \\alpha \\frac{\\partial J}{\\partial w_j} \\] \\[ w_j := w_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\cdot x_j^{(i)} \\] <p>Bias Update:</p> \\[ b := b - \\alpha \\frac{\\partial J}{\\partial b} \\] \\[ b := b - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\] <p>Vectorized Update:</p> \\[ \\mathbf{w} := \\mathbf{w} - \\alpha \\frac{1}{m} \\mathbf{X}^T (\\hat{\\mathbf{Y}} - \\mathbf{Y}) \\] \\[ b := b - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\] <p>Where: - \\(\\alpha\\) = learning rate - \\(\\mathbf{Y}\\) = target output vector</p>"},{"location":"dnn/module3-linear-nn-regression/#complete-training-algorithm","title":"Complete Training Algorithm","text":""},{"location":"dnn/module3-linear-nn-regression/#steps","title":"Steps","text":"<ol> <li> <p>Initialize: Set weights and bias to small random values (or zeros)</p> </li> <li> <p>Forward Propagation:</p> </li> <li> <p>Compute predictions: \\(\\hat{y}^{(i)} = \\mathbf{w}^T \\mathbf{x}^{(i)} + b\\) for all examples</p> </li> <li> <p>Compute Loss:</p> </li> <li> <p>\\(J = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2\\)</p> </li> <li> <p>Backward Propagation:</p> </li> <li> <p>Compute gradients: \\(\\frac{\\partial J}{\\partial w_j}\\) and \\(\\frac{\\partial J}{\\partial b}\\)</p> </li> <li> <p>Update Parameters:</p> </li> <li>\\(w_j := w_j - \\alpha \\frac{\\partial J}{\\partial w_j}\\)</li> <li> <p>\\(b := b - \\alpha \\frac{\\partial J}{\\partial b}\\)</p> </li> <li> <p>Repeat: Steps 2-5 until convergence</p> </li> </ol>"},{"location":"dnn/module3-linear-nn-regression/#numerical-example","title":"Numerical Example","text":""},{"location":"dnn/module3-linear-nn-regression/#given-data","title":"Given Data","text":"\\(x_1\\) \\(x_2\\) \\(y\\) 1 2 5 2 3 8 3 1 7"},{"location":"dnn/module3-linear-nn-regression/#step-by-step-calculation","title":"Step-by-Step Calculation","text":"<p>Initialization: \\(w_1 = 0.5\\), \\(w_2 = 0.3\\), \\(b = 0.1\\), \\(\\alpha = 0.1\\)</p> <p>Forward Pass (Example 1: \\(x_1=1, x_2=2, y=5\\)):</p> \\[ \\hat{y} = 0.5 \\cdot 1 + 0.3 \\cdot 2 + 0.1 = 0.5 + 0.6 + 0.1 = 1.2 \\] <p>Error: \\(1.2 - 5 = -3.8\\)</p> <p>Gradients: - \\(\\frac{\\partial J}{\\partial w_1} = -3.8 \\cdot 1 = -3.8\\) - \\(\\frac{\\partial J}{\\partial w_2} = -3.8 \\cdot 2 = -7.6\\) - \\(\\frac{\\partial J}{\\partial b} = -3.8\\)</p> <p>Updates: - \\(w_1 := 0.5 - 0.1 \\cdot (-3.8) = 0.5 + 0.38 = 0.88\\) - \\(w_2 := 0.3 - 0.1 \\cdot (-7.6) = 0.3 + 0.76 = 1.06\\) - \\(b := 0.1 - 0.1 \\cdot (-3.8) = 0.1 + 0.38 = 0.48\\)</p> <p>Repeat for all examples, then iterate until convergence.</p>"},{"location":"dnn/module3-linear-nn-regression/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"dnn/module3-linear-nn-regression/#forward-propagation_1","title":"Forward Propagation","text":"\\[ \\hat{y} = \\mathbf{w}^T \\mathbf{x} + b \\]"},{"location":"dnn/module3-linear-nn-regression/#loss-function_1","title":"Loss Function","text":"\\[ J = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 \\]"},{"location":"dnn/module3-linear-nn-regression/#gradients","title":"Gradients","text":"\\[ \\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\cdot x_j^{(i)} \\] \\[ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\]"},{"location":"dnn/module3-linear-nn-regression/#updates","title":"Updates","text":"\\[ w_j := w_j - \\alpha \\frac{\\partial J}{\\partial w_j} \\] \\[ b := b - \\alpha \\frac{\\partial J}{\\partial b} \\]"},{"location":"dnn/module3-linear-nn-regression/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 Linear NN Regression: Direct mapping from input to continuous output</p> <p>\u2705 Forward Propagation: Compute prediction using \\(\\hat{y} = \\mathbf{w}^T \\mathbf{x} + b\\)</p> <p>\u2705 Loss Function: Mean Squared Error (MSE)</p> <p>\u2705 Backpropagation: Compute gradients using chain rule</p> <p>\u2705 Gradient Descent: Update weights to minimize loss</p> <p>\u2705 Learning Rate: Controls step size in weight updates</p> <p>Previous: Module 2 - ANN &amp; Perceptron | Next: Module 4 - Linear NN Classification</p>"},{"location":"dnn/module4-linear-nn-classification/","title":"Module 4: Linear Neural Networks for Classification","text":""},{"location":"dnn/module4-linear-nn-classification/#overview","title":"Overview","text":"<p>This module covers linear neural networks for classification tasks, including activation functions, loss functions, and multi-class classification.</p>"},{"location":"dnn/module4-linear-nn-classification/#linear-neural-network-for-classification","title":"Linear Neural Network for Classification","text":""},{"location":"dnn/module4-linear-nn-classification/#architecture","title":"Architecture","text":"<p>Structure: - Input Layer: \\(n\\) input features - Output Layer:    - Binary: 1 neuron with sigmoid activation   - Multi-class: \\(K\\) neurons with softmax activation</p> <p>Key Difference from Regression: - Uses non-linear activation function (sigmoid/softmax) - Output represents probability of class membership - Uses cross-entropy loss instead of MSE</p>"},{"location":"dnn/module4-linear-nn-classification/#activation-functions","title":"Activation Functions","text":""},{"location":"dnn/module4-linear-nn-classification/#1-sigmoid-function","title":"1. Sigmoid Function","text":"<p>Formula:</p> \\[ \\sigma(z) = \\frac{1}{1 + e^{-z}} = \\frac{e^z}{1 + e^z} \\] <p>Properties: - Range: \\((0, 1)\\) - \\(\\sigma(0) = 0.5\\) - As \\(z \\to +\\infty\\), \\(\\sigma(z) \\to 1\\) - As \\(z \\to -\\infty\\), \\(\\sigma(z) \\to 0\\) - S-shaped curve (sigmoid curve)</p> <p>Derivative:</p> \\[ \\frac{d\\sigma}{dz} = \\sigma(z)(1 - \\sigma(z)) \\] <p>Use: Binary classification output layer</p> <p>Key Point</p> <p>The sigmoid function squashes any real number into the range (0, 1), making it perfect for representing probabilities.</p>"},{"location":"dnn/module4-linear-nn-classification/#2-tanh-function-hyperbolic-tangent","title":"2. Tanh Function (Hyperbolic Tangent)","text":"<p>Formula:</p> \\[ \\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}} = \\frac{2}{1 + e^{-2z}} - 1 \\] <p>Properties: - Range: \\((-1, 1)\\) - \\(\\tanh(0) = 0\\) - As \\(z \\to +\\infty\\), \\(\\tanh(z) \\to 1\\) - As \\(z \\to -\\infty\\), \\(\\tanh(z) \\to -1\\) - Zero-centered (unlike sigmoid)</p> <p>Derivative:</p> \\[ \\frac{d\\tanh}{dz} = 1 - \\tanh^2(z) \\] <p>Use: Hidden layers (better than sigmoid for hidden layers)</p>"},{"location":"dnn/module4-linear-nn-classification/#3-relu-rectified-linear-unit","title":"3. ReLU (Rectified Linear Unit)","text":"<p>Formula:</p> \\[ \\text{ReLU}(z) = \\max(0, z) = \\begin{cases} z &amp; \\text{if } z &gt; 0 \\\\ 0 &amp; \\text{if } z \\leq 0 \\end{cases} \\] <p>Properties: - Range: \\([0, +\\infty)\\) - Non-linear but piecewise linear - Computationally efficient - Solves vanishing gradient problem</p> <p>Derivative:</p> \\[ \\frac{d\\text{ReLU}}{dz} = \\begin{cases} 1 &amp; \\text{if } z &gt; 0 \\\\ 0 &amp; \\text{if } z \\leq 0 \\end{cases} \\] <p>Use: Hidden layers (most common in modern deep learning)</p> <p>Dead ReLU Problem</p> <p>If a ReLU neuron outputs 0 for all inputs, it becomes \"dead\" and never activates. Use Leaky ReLU or initialization techniques to prevent this.</p>"},{"location":"dnn/module4-linear-nn-classification/#4-softmax-function","title":"4. Softmax Function","text":"<p>Formula (for \\(K\\) classes):</p> \\[ \\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} \\] <p>Properties: - Outputs probability distribution: \\(\\sum_{i=1}^{K} \\text{softmax}(z_i) = 1\\) - Each output is in range \\((0, 1)\\) - Largest \\(z_i\\) gets highest probability</p> <p>Use: Multi-class classification output layer</p> <p>Example (3 classes): - \\(z = [2, 1, 0.1]\\) - \\(\\text{softmax}(z) = [0.659, 0.242, 0.099]\\) - Class 1 has highest probability (65.9%)</p>"},{"location":"dnn/module4-linear-nn-classification/#binary-classification","title":"Binary Classification","text":""},{"location":"dnn/module4-linear-nn-classification/#architecture_1","title":"Architecture","text":"<p>Single Output Neuron with sigmoid activation:</p> \\[ \\hat{y} = \\sigma(\\mathbf{w}^T \\mathbf{x} + b) = \\frac{1}{1 + e^{-(\\mathbf{w}^T \\mathbf{x} + b)}} \\] <p>Interpretation: \\(\\hat{y} = P(y = 1 | \\mathbf{x})\\)</p>"},{"location":"dnn/module4-linear-nn-classification/#loss-function-binary-cross-entropy","title":"Loss Function: Binary Cross-Entropy","text":"<p>For single example:</p> \\[ L(\\hat{y}, y) = -[y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y})] \\] <p>For \\(m\\) examples:</p> \\[ J(\\mathbf{w}, b) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)})] \\] <p>Intuition: - If \\(y = 1\\): Loss is large when \\(\\hat{y} \\to 0\\), loss is 0 when \\(\\hat{y} \\to 1\\) - If \\(y = 0\\): Loss is large when \\(\\hat{y} \\to 1\\), loss is 0 when \\(\\hat{y} \\to 0\\)</p>"},{"location":"dnn/module4-linear-nn-classification/#gradient-computation","title":"Gradient Computation","text":"<p>For weight \\(w_j\\):</p> \\[ \\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\cdot x_j^{(i)} \\] <p>For bias \\(b\\):</p> \\[ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\] <p>Derivation (using chain rule):</p> \\[ \\frac{\\partial J}{\\partial w_j} = \\frac{\\partial J}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w_j} \\] <ul> <li>\\(\\frac{\\partial J}{\\partial \\hat{y}} = -\\frac{y}{\\hat{y}} + \\frac{1-y}{1-\\hat{y}} = \\frac{\\hat{y} - y}{\\hat{y}(1-\\hat{y})}\\)</li> <li>\\(\\frac{\\partial \\hat{y}}{\\partial z} = \\hat{y}(1-\\hat{y})\\) (sigmoid derivative)</li> <li>\\(\\frac{\\partial z}{\\partial w_j} = x_j\\)</li> </ul> <p>Combined:</p> \\[ \\frac{\\partial J}{\\partial w_j} = \\frac{\\hat{y} - y}{\\hat{y}(1-\\hat{y})} \\cdot \\hat{y}(1-\\hat{y}) \\cdot x_j = (\\hat{y} - y) \\cdot x_j \\] <p>Important</p> <p>Notice that the gradient for binary cross-entropy with sigmoid has the same form as MSE with linear activation! This is a beautiful property.</p>"},{"location":"dnn/module4-linear-nn-classification/#multi-class-classification","title":"Multi-Class Classification","text":""},{"location":"dnn/module4-linear-nn-classification/#architecture_2","title":"Architecture","text":"<p>\\(K\\) Output Neurons with softmax activation:</p> \\[ \\hat{y}_k = \\text{softmax}(z_k) = \\frac{e^{z_k}}{\\sum_{j=1}^{K} e^{z_j}} \\] <p>Where \\(z_k = \\mathbf{w}_k^T \\mathbf{x} + b_k\\) for class \\(k\\).</p> <p>Output: Probability distribution over \\(K\\) classes</p> \\[ \\hat{\\mathbf{y}} = [\\hat{y}_1, \\hat{y}_2, \\ldots, \\hat{y}_K]^T \\] <p>with \\(\\sum_{k=1}^{K} \\hat{y}_k = 1\\)</p>"},{"location":"dnn/module4-linear-nn-classification/#loss-function-categorical-cross-entropy","title":"Loss Function: Categorical Cross-Entropy","text":"<p>For single example (one-hot encoded target):</p> \\[ L(\\hat{\\mathbf{y}}, \\mathbf{y}) = -\\sum_{k=1}^{K} y_k \\log(\\hat{y}_k) \\] <p>Since only one \\(y_k = 1\\) (true class), this simplifies to:</p> \\[ L(\\hat{\\mathbf{y}}, \\mathbf{y}) = -\\log(\\hat{y}_{\\text{true class}}) \\] <p>For \\(m\\) examples:</p> \\[ J = -\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K} y_k^{(i)} \\log(\\hat{y}_k^{(i)}) \\]"},{"location":"dnn/module4-linear-nn-classification/#gradient-computation_1","title":"Gradient Computation","text":"<p>For weight \\(w_{jk}\\) (weight from input \\(j\\) to output \\(k\\)):</p> \\[ \\frac{\\partial J}{\\partial w_{jk}} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_k^{(i)} - y_k^{(i)}) \\cdot x_j^{(i)} \\] <p>For bias \\(b_k\\):</p> \\[ \\frac{\\partial J}{\\partial b_k} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_k^{(i)} - y_k^{(i)}) \\] <p>Key Insight</p> <p>The gradient for softmax + cross-entropy has the same elegant form: prediction error times input!</p>"},{"location":"dnn/module4-linear-nn-classification/#decision-boundary","title":"Decision Boundary","text":""},{"location":"dnn/module4-linear-nn-classification/#binary-classification_1","title":"Binary Classification","text":"<p>Decision Rule: Predict class 1 if \\(\\hat{y} \\geq 0.5\\), else predict class 0.</p> <p>Since \\(\\hat{y} = \\sigma(\\mathbf{w}^T \\mathbf{x} + b)\\):</p> \\[ \\sigma(\\mathbf{w}^T \\mathbf{x} + b) \\geq 0.5 \\] \\[ \\mathbf{w}^T \\mathbf{x} + b \\geq 0 \\] <p>Decision Boundary: \\(\\mathbf{w}^T \\mathbf{x} + b = 0\\) (linear boundary)</p>"},{"location":"dnn/module4-linear-nn-classification/#multi-class-classification_1","title":"Multi-Class Classification","text":"<p>Decision Rule: Predict class with highest probability</p> \\[ \\text{Predicted Class} = \\arg\\max_k \\hat{y}_k \\] <p>Decision Boundaries: Linear boundaries between classes (for linear NN)</p>"},{"location":"dnn/module4-linear-nn-classification/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"dnn/module4-linear-nn-classification/#binary-classification_2","title":"Binary Classification","text":"<p>Output: $$ \\hat{y} = \\sigma(\\mathbf{w}^T \\mathbf{x} + b) $$</p> <p>Loss: $$ J = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)})] $$</p> <p>Gradient: $$ \\frac{\\partial J}{\\partial w_j} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)}) \\cdot x_j^{(i)} $$</p>"},{"location":"dnn/module4-linear-nn-classification/#multi-class-classification_2","title":"Multi-Class Classification","text":"<p>Output: $$ \\hat{y}_k = \\frac{e<sup>{z_k}}{\\sum_{j=1}</sup> $$} e^{z_j}</p> <p>Loss: $$ J = -\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K} y_k^{(i)} \\log(\\hat{y}_k^{(i)}) $$</p> <p>Gradient: $$ \\frac{\\partial J}{\\partial w_{jk}} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_k^{(i)} - y_k^{(i)}) \\cdot x_j^{(i)} $$</p>"},{"location":"dnn/module4-linear-nn-classification/#activation-function-derivatives","title":"Activation Function Derivatives","text":"<p>Sigmoid: $$ \\frac{d\\sigma}{dz} = \\sigma(z)(1 - \\sigma(z)) $$</p> <p>Tanh: $$ \\frac{d\\tanh}{dz} = 1 - \\tanh^2(z) $$</p> <p>ReLU: $$ \\frac{d\\text{ReLU}}{dz} = \\begin{cases} 1 &amp; \\text{if } z &gt; 0 \\ 0 &amp; \\text{if } z \\leq 0 \\end{cases} $$</p>"},{"location":"dnn/module4-linear-nn-classification/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 Sigmoid: Binary classification output, range (0, 1)</p> <p>\u2705 Softmax: Multi-class classification output, probability distribution</p> <p>\u2705 ReLU: Best for hidden layers, solves vanishing gradient</p> <p>\u2705 Cross-Entropy Loss: Used for classification (not MSE!)</p> <p>\u2705 Gradient Form: Same elegant form \\((\\hat{y} - y) \\cdot x\\) for both binary and multi-class</p> <p>\u2705 Decision Boundary: Linear for linear neural networks</p> <p>Previous: Module 3 - Linear NN Regression | Next: Module 5 - Deep Feedforward Neural Networks</p>"},{"location":"dnn/module5-dfnn/","title":"Module 5: Deep Feedforward Neural Networks (DFNN)","text":""},{"location":"dnn/module5-dfnn/#overview","title":"Overview","text":"<p>This module covers deep feedforward neural networks (multi-layer perceptrons), including forward propagation, backpropagation through multiple layers, and techniques to handle gradient problems.</p>"},{"location":"dnn/module5-dfnn/#deep-feedforward-neural-networks","title":"Deep Feedforward Neural Networks","text":""},{"location":"dnn/module5-dfnn/#definition","title":"Definition","text":"<p>Deep Feedforward Neural Network (DFNN) is a multi-layer neural network where information flows in one direction (forward) from input to output through multiple hidden layers.</p> <p>Also called: - Multi-Layer Perceptron (MLP) - Deep Neural Network (DNN) - Fully Connected Network</p>"},{"location":"dnn/module5-dfnn/#architecture","title":"Architecture","text":"<p>Structure:</p> <pre><code>Input Layer \u2192 Hidden Layer 1 \u2192 Hidden Layer 2 \u2192 ... \u2192 Hidden Layer L \u2192 Output Layer\n    x\u2081            h\u2081\u00b9              h\u2081\u00b2                        h\u2081^L          y\u2081\n    x\u2082            h\u2082\u00b9              h\u2082\u00b2                        h\u2082^L          y\u2082\n    ...           ...               ...                        ...\n    x\u2099            h\u2098\u00b9              h\u2098\u00b2                        h\u2098^L\n</code></pre> <p>Key Components: - Input Layer: \\(n\\) neurons (features) - Hidden Layers: \\(L\\) layers with varying number of neurons - Output Layer: \\(K\\) neurons (for \\(K\\) classes) or 1 neuron (for regression)</p>"},{"location":"dnn/module5-dfnn/#forward-propagation","title":"Forward Propagation","text":""},{"location":"dnn/module5-dfnn/#single-layer-forward-pass","title":"Single Layer Forward Pass","text":"<p>For layer \\(l\\):</p> \\[ \\mathbf{z}^{[l]} = \\mathbf{W}^{[l]} \\mathbf{a}^{[l-1]} + \\mathbf{b}^{[l]} \\] \\[ \\mathbf{a}^{[l]} = g^{[l]}(\\mathbf{z}^{[l]}) \\] <p>Where: - \\(\\mathbf{W}^{[l]}\\) = weight matrix for layer \\(l\\) (size: \\(n^{[l]} \\times n^{[l-1]}\\)) - \\(\\mathbf{a}^{[l-1]}\\) = activations from previous layer - \\(\\mathbf{b}^{[l]}\\) = bias vector for layer \\(l\\) - \\(g^{[l]}\\) = activation function for layer \\(l\\) - \\(\\mathbf{z}^{[l]}\\) = pre-activation (linear combination) - \\(\\mathbf{a}^{[l]}\\) = post-activation (output of layer \\(l\\))</p> <p>Notation: - \\(n^{[l]}\\) = number of neurons in layer \\(l\\) - \\(\\mathbf{a}^{[0]} = \\mathbf{x}\\) (input) - \\(\\mathbf{a}^{[L]} = \\hat{\\mathbf{y}}\\) (output)</p>"},{"location":"dnn/module5-dfnn/#complete-forward-propagation","title":"Complete Forward Propagation","text":"<p>For a network with \\(L\\) layers:</p> <ol> <li> <p>Input: \\(\\mathbf{a}^{[0]} = \\mathbf{x}\\)</p> </li> <li> <p>For each layer \\(l = 1, 2, \\ldots, L\\):    $$    \\mathbf{z}^{[l]} = \\mathbf{W}^{[l]} \\mathbf{a}^{[l-1]} + \\mathbf{b}^{[l]} $$    $$    \\mathbf{a}^{[l]} = g<sup>{[l]}(\\mathbf{z}</sup>) $$</p> </li> <li> <p>Output: \\(\\hat{\\mathbf{y}} = \\mathbf{a}^{[L]}\\)</p> </li> </ol>"},{"location":"dnn/module5-dfnn/#example-3-layer-network","title":"Example: 3-Layer Network","text":"<p>Architecture: Input (2) \u2192 Hidden (3) \u2192 Output (1)</p> <p>Layer 1 (Hidden): $$ \\mathbf{z}^{[1]} = \\mathbf{W}^{[1]} \\mathbf{x} + \\mathbf{b}^{[1]} $$ $$ \\mathbf{a}^{[1]} = \\text{ReLU}(\\mathbf{z}^{[1]}) $$</p> <p>Layer 2 (Output): $$ \\mathbf{z}^{[2]} = \\mathbf{W}^{[2]} \\mathbf{a}^{[1]} + \\mathbf{b}^{[2]} $$ $$ \\hat{y} = \\sigma(\\mathbf{z}^{[2]}) \\quad \\text{(for binary classification)} $$</p>"},{"location":"dnn/module5-dfnn/#backpropagation-algorithm","title":"Backpropagation Algorithm","text":""},{"location":"dnn/module5-dfnn/#goal","title":"Goal","text":"<p>Compute gradients for all layers to update weights using gradient descent.</p>"},{"location":"dnn/module5-dfnn/#chain-rule-for-multiple-layers","title":"Chain Rule for Multiple Layers","text":"<p>Key Insight: Gradients flow backward from output to input.</p>"},{"location":"dnn/module5-dfnn/#backpropagation-steps","title":"Backpropagation Steps","text":"<p>Given: Loss function \\(J\\) and network output \\(\\hat{\\mathbf{y}}\\)</p> <p>Step 1: Compute output layer gradient</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{a}^{[L]}} = \\frac{\\partial J}{\\partial \\hat{\\mathbf{y}}} \\] <p>Step 2: For each layer \\(l = L, L-1, \\ldots, 1\\) (backward):</p> <p>a. Gradient w.r.t. pre-activation: $$ \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} = \\frac{\\partial J}{\\partial \\mathbf{a}^{[l]}} \\odot g'<sup>{[l]}(\\mathbf{z}</sup>) $$</p> <p>Where \\(\\odot\\) is element-wise multiplication.</p> <p>b. Gradient w.r.t. weights: $$ \\frac{\\partial J}{\\partial \\mathbf{W}^{[l]}} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} (\\mathbf{a}<sup>{[l-1]})</sup>T $$</p> <p>c. Gradient w.r.t. bias: $$ \\frac{\\partial J}{\\partial \\mathbf{b}^{[l]}} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} $$</p> <p>d. Gradient w.r.t. previous layer activations: $$ \\frac{\\partial J}{\\partial \\mathbf{a}^{[l-1]}} = (\\mathbf{W}<sup>{[l]})</sup>T \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} $$</p>"},{"location":"dnn/module5-dfnn/#detailed-formulas","title":"Detailed Formulas","text":"<p>For output layer \\(L\\) (binary classification with sigmoid):</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{z}^{[L]}} = \\mathbf{a}^{[L]} - \\mathbf{y} = \\hat{\\mathbf{y}} - \\mathbf{y} \\] <p>For hidden layer \\(l\\):</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} = (\\mathbf{W}^{[l+1]})^T \\frac{\\partial J}{\\partial \\mathbf{z}^{[l+1]}} \\odot g'^{[l]}(\\mathbf{z}^{[l]}) \\] <p>Weight updates:</p> \\[ \\mathbf{W}^{[l]} := \\mathbf{W}^{[l]} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W}^{[l]}} \\] \\[ \\mathbf{b}^{[l]} := \\mathbf{b}^{[l]} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{b}^{[l]}} \\] <p>Key Point</p> <p>Backpropagation uses the chain rule to compute gradients layer by layer, starting from the output and working backward to the input.</p>"},{"location":"dnn/module5-dfnn/#vanishing-gradient-problem","title":"Vanishing Gradient Problem","text":""},{"location":"dnn/module5-dfnn/#problem","title":"Problem","text":"<p>In deep networks, gradients can become extremely small as they propagate backward through many layers.</p> <p>Cause: When activation function derivatives are small (e.g., sigmoid: \\(\\sigma'(z) = \\sigma(z)(1-\\sigma(z)) \\leq 0.25\\)), repeated multiplication makes gradients vanish.</p> <p>Effect: Early layers learn very slowly or not at all.</p>"},{"location":"dnn/module5-dfnn/#example","title":"Example","text":"<p>5-layer network with sigmoid:</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{W}^{[1]}} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[5]}} \\cdot \\sigma'(\\mathbf{z}^{[5]}) \\cdot \\sigma'(\\mathbf{z}^{[4]}) \\cdot \\sigma'(\\mathbf{z}^{[3]}) \\cdot \\sigma'(\\mathbf{z}^{[2]}) \\cdot \\sigma'(\\mathbf{z}^{[1]}) \\] <p>If each \\(\\sigma'(z) \\approx 0.25\\), then:</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{W}^{[1]}} \\approx \\text{(small)} \\times 0.25^4 = \\text{(very small)} \\]"},{"location":"dnn/module5-dfnn/#solutions","title":"Solutions","text":"<ol> <li>Use ReLU: Derivative is 1 (when active), prevents vanishing</li> <li>Residual Connections: Skip connections (ResNet)</li> <li>Batch Normalization: Normalize activations</li> <li>Proper Initialization: Xavier/He initialization</li> <li>Gradient Clipping: Prevent exploding gradients</li> </ol>"},{"location":"dnn/module5-dfnn/#exploding-gradient-problem","title":"Exploding Gradient Problem","text":""},{"location":"dnn/module5-dfnn/#problem_1","title":"Problem","text":"<p>Gradients can become extremely large, causing unstable training.</p> <p>Cause: Large weights or many layers with large derivatives.</p> <p>Effect: Weights update too much, training diverges.</p>"},{"location":"dnn/module5-dfnn/#solutions_1","title":"Solutions","text":"<ol> <li> <p>Gradient Clipping: Limit gradient magnitude    $$    \\text{if } ||\\mathbf{g}|| &gt; \\text{threshold}: \\mathbf{g} = \\mathbf{g} \\cdot \\frac{\\text{threshold}}{||\\mathbf{g}||} $$</p> </li> <li> <p>Weight Initialization: Start with small weights</p> </li> <li>Batch Normalization: Stabilize activations</li> <li>Lower Learning Rate: Smaller steps</li> </ol>"},{"location":"dnn/module5-dfnn/#regularization-techniques","title":"Regularization Techniques","text":""},{"location":"dnn/module5-dfnn/#1-l2-regularization-weight-decay","title":"1. L2 Regularization (Weight Decay)","text":"<p>Modified Loss Function:</p> \\[ J_{\\text{reg}} = J + \\frac{\\lambda}{2m} \\sum_{l=1}^{L} ||\\mathbf{W}^{[l]}||_F^2 \\] <p>Where \\(||\\mathbf{W}^{[l]}||_F^2\\) is Frobenius norm (sum of squares of all elements).</p> <p>Weight Update:</p> \\[ \\mathbf{W}^{[l]} := \\mathbf{W}^{[l]} - \\alpha \\left(\\frac{\\partial J}{\\partial \\mathbf{W}^{[l]}} + \\frac{\\lambda}{m} \\mathbf{W}^{[l]}\\right) \\] <p>Effect: Penalizes large weights, prevents overfitting.</p>"},{"location":"dnn/module5-dfnn/#2-dropout","title":"2. Dropout","text":"<p>During Training: - Randomly set some neurons to 0 with probability \\(p\\) (dropout rate) - Only keep neurons with probability \\((1-p)\\)</p> <p>During Testing: - Use all neurons - Scale activations by \\((1-p)\\)</p> <p>Effect: Prevents co-adaptation, reduces overfitting.</p>"},{"location":"dnn/module5-dfnn/#3-early-stopping","title":"3. Early Stopping","text":"<ul> <li>Monitor validation loss</li> <li>Stop training when validation loss starts increasing</li> <li>Prevents overfitting</li> </ul>"},{"location":"dnn/module5-dfnn/#4-batch-normalization","title":"4. Batch Normalization","text":"<p>Normalize activations:</p> \\[ \\hat{z}^{[l]} = \\frac{z^{[l]} - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\] \\[ \\tilde{z}^{[l]} = \\gamma \\hat{z}^{[l]} + \\beta \\] <p>Benefits: - Faster training - Less sensitive to initialization - Acts as regularization</p>"},{"location":"dnn/module5-dfnn/#weight-initialization","title":"Weight Initialization","text":""},{"location":"dnn/module5-dfnn/#poor-initialization","title":"Poor Initialization","text":"<p>Problem: If all weights are same (e.g., all zeros), all neurons learn same thing (symmetry breaking problem).</p>"},{"location":"dnn/module5-dfnn/#good-initialization-strategies","title":"Good Initialization Strategies","text":"<p>1. Xavier/Glorot Initialization (for tanh/sigmoid):</p> \\[ W_{ij} \\sim \\mathcal{N}\\left(0, \\frac{1}{n^{[l-1]}}\\right) \\] <p>or</p> \\[ W_{ij} \\sim \\mathcal{U}\\left(-\\frac{\\sqrt{6}}{\\sqrt{n^{[l-1]} + n^{[l]}}}, \\frac{\\sqrt{6}}{\\sqrt{n^{[l-1]} + n^{[l]}}}\\right) \\] <p>2. He Initialization (for ReLU):</p> \\[ W_{ij} \\sim \\mathcal{N}\\left(0, \\frac{2}{n^{[l-1]}}\\right) \\] <p>Best Practice</p> <p>Use He initialization for ReLU networks and Xavier initialization for tanh/sigmoid networks.</p>"},{"location":"dnn/module5-dfnn/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"dnn/module5-dfnn/#forward-propagation_1","title":"Forward Propagation","text":"\\[ \\mathbf{z}^{[l]} = \\mathbf{W}^{[l]} \\mathbf{a}^{[l-1]} + \\mathbf{b}^{[l]} \\] \\[ \\mathbf{a}^{[l]} = g^{[l]}(\\mathbf{z}^{[l]}) \\]"},{"location":"dnn/module5-dfnn/#backpropagation","title":"Backpropagation","text":"<p>Output Layer: $$ \\frac{\\partial J}{\\partial \\mathbf{z}^{[L]}} = \\hat{\\mathbf{y}} - \\mathbf{y} $$</p> <p>Hidden Layers: $$ \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} = (\\mathbf{W}<sup>{[l+1]})</sup>T \\frac{\\partial J}{\\partial \\mathbf{z}^{[l+1]}} \\odot g'<sup>{[l]}(\\mathbf{z}</sup>) $$</p> <p>Weights: $$ \\frac{\\partial J}{\\partial \\mathbf{W}^{[l]}} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} (\\mathbf{a}<sup>{[l-1]})</sup>T $$</p> <p>Bias: $$ \\frac{\\partial J}{\\partial \\mathbf{b}^{[l]}} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[l]}} $$</p>"},{"location":"dnn/module5-dfnn/#regularization","title":"Regularization","text":"<p>L2 Regularization: $$ J_{\\text{reg}} = J + \\frac{\\lambda}{2m} \\sum_{l=1}^{L} ||\\mathbf{W}<sup>{[l]}||_F</sup>2 $$</p>"},{"location":"dnn/module5-dfnn/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 DFNN: Multi-layer network with forward and backward propagation</p> <p>\u2705 Forward Pass: Compute activations layer by layer</p> <p>\u2705 Backpropagation: Compute gradients using chain rule, backward through layers</p> <p>\u2705 Vanishing Gradient: Use ReLU, proper initialization, batch norm</p> <p>\u2705 Exploding Gradient: Use gradient clipping, proper initialization</p> <p>\u2705 Regularization: L2, dropout, early stopping, batch normalization</p> <p>\u2705 Initialization: He for ReLU, Xavier for tanh/sigmoid</p> <p>Previous: Module 4 - Linear NN Classification | Next: Module 6 - Convolutional Neural Networks</p>"},{"location":"dnn/module6-cnn/","title":"Module 6: Convolutional Neural Networks (CNN)","text":""},{"location":"dnn/module6-cnn/#overview","title":"Overview","text":"<p>This module covers Convolutional Neural Networks (CNNs), specialized neural networks for processing grid-like data such as images.</p>"},{"location":"dnn/module6-cnn/#introduction-to-cnns","title":"Introduction to CNNs","text":""},{"location":"dnn/module6-cnn/#why-cnns-for-images","title":"Why CNNs for Images?","text":"<p>Problems with Fully Connected Networks: - Too many parameters for images (e.g., 1000\u00d71000 image = 1M parameters per neuron!) - Doesn't exploit spatial structure - Translation sensitive</p> <p>CNN Advantages: - Parameter Sharing: Same filter used across image - Sparse Connectivity: Each neuron connects to small region - Translation Invariance: Can detect features anywhere in image</p>"},{"location":"dnn/module6-cnn/#key-idea","title":"Key Idea","text":"<p>Local Receptive Fields: Each neuron connects to a small local region of input, not all pixels.</p>"},{"location":"dnn/module6-cnn/#cnn-architecture-components","title":"CNN Architecture Components","text":""},{"location":"dnn/module6-cnn/#1-convolutional-layer","title":"1. Convolutional Layer","text":"<p>Operation: Apply filters (kernels) to input</p> <p>Convolution Operation:</p> \\[ (f * g)(i, j) = \\sum_{m} \\sum_{n} f(m, n) \\cdot g(i-m, j-n) \\] <p>In CNN context:</p> \\[ \\text{Output}(i, j) = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} \\text{Input}(i+m, j+n) \\cdot \\text{Filter}(m, n) + b \\] <p>Where: - \\(k\\) = filter size (e.g., 3\u00d73, 5\u00d75) - \\(b\\) = bias term</p> <p>Example: 3\u00d73 Filter on 5\u00d75 Image</p> <pre><code>Input Image          Filter          Output\n[1 2 3 4 5]        [1 0 -1]        [ 0  2  2]\n[6 7 8 9 0]    *   [1 0 -1]    =   [-2  0  2]\n[1 2 3 4 5]        [1 0 -1]        [ 0  2  2]\n[6 7 8 9 0]\n[1 2 3 4 5]\n</code></pre> <p>Output Size:</p> \\[ \\text{Output Size} = \\frac{\\text{Input Size} - \\text{Filter Size} + 2 \\times \\text{Padding}}{\\text{Stride}} + 1 \\] <p>Parameters: - Filter Size: Typically 3\u00d73 or 5\u00d75 - Number of Filters: Depth of output feature map - Stride: Step size (typically 1 or 2) - Padding: Zero-padding around input (typically \"same\" or \"valid\")</p>"},{"location":"dnn/module6-cnn/#2-pooling-layer","title":"2. Pooling Layer","text":"<p>Purpose: Reduce spatial dimensions, reduce parameters, provide translation invariance</p> <p>Types:</p> <p>Max Pooling: $$ \\text{Output}(i, j) = \\max_{m,n \\in \\text{window}} \\text{Input}(i+m, j+n) $$</p> <p>Average Pooling: $$ \\text{Output}(i, j) = \\frac{1}{k^2} \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} \\text{Input}(i+m, j+n) $$</p> <p>Common Sizes: 2\u00d72 with stride 2 (reduces size by half)</p> <p>Example: 2\u00d72 Max Pooling</p> <pre><code>Input:              Output:\n[1 3 2 4]          [3 4]\n[2 1 3 2]    \u2192     [2 3]\n[1 2 3 1]\n[2 3 1 2]\n</code></pre>"},{"location":"dnn/module6-cnn/#3-fully-connected-layer","title":"3. Fully Connected Layer","text":"<p>Purpose: Final classification/regression</p> <p>Structure: Same as regular neural network layer</p> <p>Input: Flattened feature maps from previous layers</p>"},{"location":"dnn/module6-cnn/#complete-cnn-architecture","title":"Complete CNN Architecture","text":""},{"location":"dnn/module6-cnn/#typical-structure","title":"Typical Structure","text":"<pre><code>Input Image (e.g., 224\u00d7224\u00d73)\n    \u2193\nConv Layer 1 (e.g., 32 filters, 3\u00d73) \u2192 ReLU\n    \u2193\nMax Pooling (2\u00d72)\n    \u2193\nConv Layer 2 (e.g., 64 filters, 3\u00d73) \u2192 ReLU\n    \u2193\nMax Pooling (2\u00d72)\n    \u2193\nConv Layer 3 (e.g., 128 filters, 3\u00d73) \u2192 ReLU\n    \u2193\nMax Pooling (2\u00d72)\n    \u2193\nFlatten\n    \u2193\nFully Connected Layer 1 (e.g., 512 neurons) \u2192 ReLU\n    \u2193\nFully Connected Layer 2 (e.g., 256 neurons) \u2192 ReLU\n    \u2193\nOutput Layer (e.g., 10 classes) \u2192 Softmax\n</code></pre>"},{"location":"dnn/module6-cnn/#example-lenet-5-simplified","title":"Example: LeNet-5 (Simplified)","text":"<p>Architecture: 1. Conv: 6 filters, 5\u00d75 \u2192 ReLU 2. Max Pool: 2\u00d72 3. Conv: 16 filters, 5\u00d75 \u2192 ReLU 4. Max Pool: 2\u00d72 5. FC: 120 neurons \u2192 ReLU 6. FC: 84 neurons \u2192 ReLU 7. Output: 10 classes \u2192 Softmax</p>"},{"location":"dnn/module6-cnn/#convolution-operation-details","title":"Convolution Operation Details","text":""},{"location":"dnn/module6-cnn/#stride","title":"Stride","text":"<p>Stride = 1 (default): - Filter moves 1 pixel at a time - More overlap, larger output</p> <p>Stride = 2: - Filter moves 2 pixels at a time - Less overlap, smaller output (half size)</p> <p>Output Size with Stride:</p> \\[ \\text{Output Height} = \\left\\lfloor \\frac{H - F + 2P}{S} \\right\\rfloor + 1 \\] \\[ \\text{Output Width} = \\left\\lfloor \\frac{W - F + 2P}{S} \\right\\rfloor + 1 \\] <p>Where: - \\(H, W\\) = input height, width - \\(F\\) = filter size - \\(P\\) = padding - \\(S\\) = stride</p>"},{"location":"dnn/module6-cnn/#padding","title":"Padding","text":"<p>Valid Padding (no padding): - Output size &lt; Input size - Formula: \\(\\text{Output} = \\text{Input} - \\text{Filter} + 1\\)</p> <p>Same Padding (zero padding): - Output size = Input size (when stride = 1) - Padding: \\(P = \\frac{F-1}{2}\\) (for odd filter sizes)</p> <p>Example: 5\u00d75 input, 3\u00d73 filter - Valid: Output = 3\u00d73 - Same (P=1): Output = 5\u00d75</p>"},{"location":"dnn/module6-cnn/#backpropagation-in-cnns","title":"Backpropagation in CNNs","text":""},{"location":"dnn/module6-cnn/#convolutional-layer-backpropagation","title":"Convolutional Layer Backpropagation","text":"<p>Forward: $$ y_{i,j} = \\sum_{m} \\sum_{n} x_{i+m, j+n} \\cdot w_{m,n} + b $$</p> <p>Backward (gradient w.r.t. filter):</p> \\[ \\frac{\\partial J}{\\partial w_{m,n}} = \\sum_{i} \\sum_{j} \\frac{\\partial J}{\\partial y_{i,j}} \\cdot x_{i+m, j+n} \\] <p>Gradient w.r.t. input:</p> \\[ \\frac{\\partial J}{\\partial x_{i,j}} = \\sum_{m} \\sum_{n} \\frac{\\partial J}{\\partial y_{i-m, j-n}} \\cdot w_{m,n} \\] <p>Key Insight: Backpropagation in convolution uses correlation (flipped convolution).</p>"},{"location":"dnn/module6-cnn/#pooling-layer-backpropagation","title":"Pooling Layer Backpropagation","text":"<p>Max Pooling: - Gradient flows only to the maximum value in each window - Other positions get zero gradient</p> <p>Average Pooling: - Gradient distributed equally to all positions in window</p>"},{"location":"dnn/module6-cnn/#common-cnn-architectures","title":"Common CNN Architectures","text":""},{"location":"dnn/module6-cnn/#1-lenet-5-1998","title":"1. LeNet-5 (1998)","text":"<ul> <li>First successful CNN</li> <li>Handwritten digit recognition</li> <li>5 layers</li> </ul>"},{"location":"dnn/module6-cnn/#2-alexnet-2012","title":"2. AlexNet (2012)","text":"<ul> <li>Won ImageNet 2012</li> <li>8 layers</li> <li>ReLU activation</li> <li>Dropout regularization</li> </ul>"},{"location":"dnn/module6-cnn/#3-vgg-2014","title":"3. VGG (2014)","text":"<ul> <li>Very deep (16-19 layers)</li> <li>Small 3\u00d73 filters</li> <li>Simple architecture</li> </ul>"},{"location":"dnn/module6-cnn/#4-resnet-2015","title":"4. ResNet (2015)","text":"<ul> <li>Residual connections (skip connections)</li> <li>Very deep (50-152 layers)</li> <li>Solves vanishing gradient</li> </ul>"},{"location":"dnn/module6-cnn/#5-modern-architectures","title":"5. Modern Architectures","text":"<ul> <li>Inception: Multiple filter sizes</li> <li>MobileNet: Efficient for mobile</li> <li>EfficientNet: Balanced scaling</li> </ul>"},{"location":"dnn/module6-cnn/#applications-of-cnns","title":"Applications of CNNs","text":""},{"location":"dnn/module6-cnn/#computer-vision","title":"Computer Vision","text":"<ul> <li>Image Classification: Identify objects</li> <li>Object Detection: Locate and classify objects</li> <li>Semantic Segmentation: Pixel-level classification</li> <li>Face Recognition: Biometric identification</li> </ul>"},{"location":"dnn/module6-cnn/#medical-imaging","title":"Medical Imaging","text":"<ul> <li>X-ray Analysis: Disease detection</li> <li>MRI/CT Scan: Tumor detection</li> <li>Retinal Analysis: Eye disease diagnosis</li> </ul>"},{"location":"dnn/module6-cnn/#other-applications","title":"Other Applications","text":"<ul> <li>Autonomous Vehicles: Road sign recognition, obstacle detection</li> <li>Security: Surveillance, anomaly detection</li> <li>Agriculture: Crop monitoring, disease detection</li> </ul>"},{"location":"dnn/module6-cnn/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"dnn/module6-cnn/#convolution","title":"Convolution","text":"\\[ \\text{Output}(i, j) = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} \\text{Input}(i+m, j+n) \\cdot \\text{Filter}(m, n) + b \\]"},{"location":"dnn/module6-cnn/#output-size","title":"Output Size","text":"\\[ \\text{Output} = \\left\\lfloor \\frac{\\text{Input} - \\text{Filter} + 2 \\times \\text{Padding}}{\\text{Stride}} \\right\\rfloor + 1 \\]"},{"location":"dnn/module6-cnn/#max-pooling","title":"Max Pooling","text":"\\[ \\text{Output}(i, j) = \\max_{m,n \\in \\text{window}} \\text{Input}(i+m, j+n) \\]"},{"location":"dnn/module6-cnn/#average-pooling","title":"Average Pooling","text":"\\[ \\text{Output}(i, j) = \\frac{1}{k^2} \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} \\text{Input}(i+m, j+n) \\]"},{"location":"dnn/module6-cnn/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 CNN: Specialized for grid-like data (images)</p> <p>\u2705 Convolution: Apply filters to detect features</p> <p>\u2705 Pooling: Reduce spatial dimensions, provide invariance</p> <p>\u2705 Parameter Sharing: Same filter used across image</p> <p>\u2705 Translation Invariance: Can detect features anywhere</p> <p>\u2705 Architecture: Conv \u2192 Pool \u2192 Conv \u2192 Pool \u2192 ... \u2192 FC \u2192 Output</p> <p>\u2705 Backpropagation: Uses correlation (flipped convolution)</p> <p>Previous: Module 5 - Deep Feedforward Neural Networks | Back to: DNN Overview</p>"},{"location":"dnn/papers/2024-endsem-regular-solved/","title":"2024 EndSem Regular DNN Paper - Complete Solutions","text":""},{"location":"dnn/papers/2024-endsem-regular-solved/#question-1-deep-network-backpropagation","title":"Question 1: Deep Network Backpropagation","text":""},{"location":"dnn/papers/2024-endsem-regular-solved/#problem-statement","title":"Problem Statement","text":"<p>Given a 3-layer network: - Layer 1: 2 inputs \u2192 3 hidden (ReLU) - Layer 2: 3 hidden \u2192 2 hidden (ReLU) - Layer 3: 2 hidden \u2192 1 output (sigmoid)</p> <p>Weights: $$ \\mathbf{W}^{[1]} = \\begin{bmatrix} 1 &amp; 2 \\ -1 &amp; 1 \\ 0 &amp; 1 \\end{bmatrix}, \\quad \\mathbf{b}^{[1]} = \\begin{bmatrix} 0 \\ 1 \\ -1 \\end{bmatrix} $$</p> \\[ \\mathbf{W}^{[2]} = \\begin{bmatrix} 1 &amp; -1 &amp; 0 \\\\ 0 &amp; 1 &amp; -1 \\end{bmatrix}, \\quad \\mathbf{b}^{[2]} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\] \\[ \\mathbf{W}^{[3]} = \\begin{bmatrix} 2 &amp; -1 \\end{bmatrix}, \\quad b^{[3]} = 0 \\] <p>Input: \\(\\mathbf{x} = [1, 1]^T\\), Target: \\(y = 1\\)</p> <p>a) Perform complete forward propagation.</p> <p>b) Calculate binary cross-entropy loss.</p> <p>c) Perform backpropagation to compute all gradients.</p>"},{"location":"dnn/papers/2024-endsem-regular-solved/#solution","title":"Solution","text":""},{"location":"dnn/papers/2024-endsem-regular-solved/#part-a-forward-propagation","title":"Part (a): Forward Propagation","text":"<p>Layer 1:</p> \\[ \\mathbf{z}^{[1]} = \\mathbf{W}^{[1]} \\mathbf{x} + \\mathbf{b}^{[1]} = \\begin{bmatrix} 1 &amp; 2 \\\\ -1 &amp; 1 \\\\ 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 1 \\\\ -1 \\end{bmatrix} \\] \\[ \\mathbf{z}^{[1]} = \\begin{bmatrix} 3 \\\\ 0 \\\\ 1 \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 1 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 1 \\\\ 0 \\end{bmatrix} \\] \\[ \\mathbf{a}^{[1]} = \\text{ReLU}(\\mathbf{z}^{[1]}) = \\begin{bmatrix} 3 \\\\ 1 \\\\ 0 \\end{bmatrix} \\] <p>Layer 2:</p> \\[ \\mathbf{z}^{[2]} = \\mathbf{W}^{[2]} \\mathbf{a}^{[1]} + \\mathbf{b}^{[2]} = \\begin{bmatrix} 1 &amp; -1 &amp; 0 \\\\ 0 &amp; 1 &amp; -1 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 1 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\] \\[ \\mathbf{z}^{[2]} = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix} \\] \\[ \\mathbf{a}^{[2]} = \\text{ReLU}(\\mathbf{z}^{[2]}) = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix} \\] <p>Layer 3:</p> \\[ z^{[3]} = \\mathbf{W}^{[3]} \\mathbf{a}^{[2]} + b^{[3]} = \\begin{bmatrix} 2 &amp; -1 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix} + 0 = 5 \\] \\[ \\hat{y} = \\sigma(z^{[3]}) = \\sigma(5) = \\frac{1}{1 + e^{-5}} = 0.993 \\] <p>Answer: \\(\\hat{y} = 0.993\\)</p>"},{"location":"dnn/papers/2024-endsem-regular-solved/#part-b-loss-calculation","title":"Part (b): Loss Calculation","text":"<p>Binary Cross-Entropy Loss:</p> \\[ J = -[y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y})] \\] \\[ J = -[1 \\cdot \\log(0.993) + 0 \\cdot \\log(0.007)] = -\\log(0.993) = 0.007 \\] <p>Answer: Loss \\(J = 0.007\\)</p>"},{"location":"dnn/papers/2024-endsem-regular-solved/#part-c-backpropagation","title":"Part (c): Backpropagation","text":"<p>Layer 3 Gradients:</p> \\[ \\frac{\\partial J}{\\partial z^{[3]}} = \\hat{y} - y = 0.993 - 1 = -0.007 \\] \\[ \\frac{\\partial J}{\\partial \\mathbf{W}^{[3]}} = \\frac{\\partial J}{\\partial z^{[3]}} \\cdot (\\mathbf{a}^{[2]})^T = -0.007 \\cdot \\begin{bmatrix} 3 &amp; 1 \\end{bmatrix} = \\begin{bmatrix} -0.021 &amp; -0.007 \\end{bmatrix} \\] \\[ \\frac{\\partial J}{\\partial b^{[3]}} = -0.007 \\] <p>Layer 2 Gradients:</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{z}^{[2]}} = (\\mathbf{W}^{[3]})^T \\frac{\\partial J}{\\partial z^{[3]}} \\odot \\text{ReLU}'(\\mathbf{z}^{[2]}) \\] \\[ = \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix} \\cdot (-0.007) \\odot \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} -0.014 \\\\ 0.007 \\end{bmatrix} \\] \\[ \\frac{\\partial J}{\\partial \\mathbf{W}^{[2]}} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[2]}} (\\mathbf{a}^{[1]})^T = \\begin{bmatrix} -0.014 \\\\ 0.007 \\end{bmatrix} \\begin{bmatrix} 3 &amp; 1 &amp; 0 \\end{bmatrix} = \\begin{bmatrix} -0.042 &amp; -0.014 &amp; 0 \\\\ 0.021 &amp; 0.007 &amp; 0 \\end{bmatrix} \\] \\[ \\frac{\\partial J}{\\partial \\mathbf{b}^{[2]}} = \\begin{bmatrix} -0.014 \\\\ 0.007 \\end{bmatrix} \\] <p>Layer 1 Gradients:</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{z}^{[1]}} = (\\mathbf{W}^{[2]})^T \\frac{\\partial J}{\\partial \\mathbf{z}^{[2]}} \\odot \\text{ReLU}'(\\mathbf{z}^{[1]}) \\] \\[ = \\begin{bmatrix} 1 &amp; 0 \\\\ -1 &amp; 1 \\\\ 0 &amp; -1 \\end{bmatrix} \\begin{bmatrix} -0.014 \\\\ 0.007 \\end{bmatrix} \\odot \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} -0.014 \\\\ 0.021 \\\\ 0 \\end{bmatrix} \\] \\[ \\frac{\\partial J}{\\partial \\mathbf{W}^{[1]}} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[1]}} \\mathbf{x}^T = \\begin{bmatrix} -0.014 \\\\ 0.021 \\\\ 0 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 1 \\end{bmatrix} = \\begin{bmatrix} -0.014 &amp; -0.014 \\\\ 0.021 &amp; 0.021 \\\\ 0 &amp; 0 \\end{bmatrix} \\] \\[ \\frac{\\partial J}{\\partial \\mathbf{b}^{[1]}} = \\begin{bmatrix} -0.014 \\\\ 0.021 \\\\ 0 \\end{bmatrix} \\] <p>Answer: All gradients computed as shown above.</p>"},{"location":"dnn/papers/2024-endsem-regular-solved/#question-2-cnn-architecture","title":"Question 2: CNN Architecture","text":""},{"location":"dnn/papers/2024-endsem-regular-solved/#problem-statement_1","title":"Problem Statement","text":"<p>Design a CNN for 28\u00d728 grayscale image classification with 10 classes.</p> <p>Requirements: - First conv layer: 32 filters, 5\u00d75 - Pooling: 2\u00d72 max pooling - Second conv layer: 64 filters, 3\u00d73 - Pooling: 2\u00d72 max pooling - Fully connected: 128 neurons - Output: 10 classes</p> <p>a) Calculate the size of feature maps after each layer.</p> <p>b) Calculate total number of parameters.</p>"},{"location":"dnn/papers/2024-endsem-regular-solved/#solution_1","title":"Solution","text":""},{"location":"dnn/papers/2024-endsem-regular-solved/#part-a-feature-map-sizes","title":"Part (a): Feature Map Sizes","text":"<p>Input: 28\u00d728\u00d71</p> <p>Conv Layer 1 (32 filters, 5\u00d75, stride=1, padding=0): $$ \\text{Output} = \\frac{28 - 5 + 2 \\times 0}{1} + 1 = 24 $$ Size: 24\u00d724\u00d732</p> <p>Max Pooling 1 (2\u00d72, stride=2): $$ \\text{Output} = \\frac{24 - 2 + 2 \\times 0}{2} + 1 = 12 $$ Size: 12\u00d712\u00d732</p> <p>Conv Layer 2 (64 filters, 3\u00d73, stride=1, padding=0): $$ \\text{Output} = \\frac{12 - 3 + 2 \\times 0}{1} + 1 = 10 $$ Size: 10\u00d710\u00d764</p> <p>Max Pooling 2 (2\u00d72, stride=2): $$ \\text{Output} = \\frac{10 - 2 + 2 \\times 0}{2} + 1 = 5 $$ Size: 5\u00d75\u00d764</p> <p>Flatten: 5 \u00d7 5 \u00d7 64 = 1600</p> <p>FC Layer: 128 neurons</p> <p>Output: 10 neurons</p> <p>Answer: Feature map sizes calculated as shown above.</p>"},{"location":"dnn/papers/2024-endsem-regular-solved/#part-b-parameter-count","title":"Part (b): Parameter Count","text":"<p>Conv Layer 1: - Filters: 32 \u00d7 (5\u00d75\u00d71 + 1 bias) = 32 \u00d7 26 = 832</p> <p>Conv Layer 2: - Filters: 64 \u00d7 (3\u00d73\u00d732 + 1 bias) = 64 \u00d7 289 = 18,496</p> <p>FC Layer: - Weights: 1600 \u00d7 128 = 204,800 - Bias: 128 - Total: 204,928</p> <p>Output Layer: - Weights: 128 \u00d7 10 = 1,280 - Bias: 10 - Total: 1,290</p> <p>Total Parameters: $$ 832 + 18,496 + 204,928 + 1,290 = 225,546 $$</p> <p>Answer: Total parameters = 225,546</p>"},{"location":"dnn/papers/2024-endsem-regular-solved/#summary","title":"Summary","text":"<p>This paper covered: 1. \u2705 Deep Network Forward and Backward Propagation 2. \u2705 CNN Architecture Design and Calculations 3. \u2705 Parameter Counting in CNNs</p> <p>Key Takeaways: - Practice forward/backward propagation step-by-step - Understand CNN layer size calculations - Know how to count parameters in each layer type</p> <p>Good luck with your exam! \ud83c\udfaf</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/","title":"2024 MidSem Regular DNN Paper - Complete Solutions","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#question-1-perceptron-learning-algorithm","title":"Question 1: Perceptron Learning Algorithm","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#problem-statement","title":"Problem Statement","text":"<p>Given training data for binary classification:</p> x\u2081 x\u2082 y 1 1 1 2 2 1 0 0 0 1 0 0 <p>a) Initialize perceptron with \\(w_1 = 0\\), \\(w_2 = 0\\), \\(b = 0\\), learning rate \\(\\alpha = 1.0\\).</p> <p>b) Perform 2 iterations of the perceptron learning algorithm.</p> <p>c) What is the decision boundary after 2 iterations?</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#solution","title":"Solution","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#part-a-initialization","title":"Part (a): Initialization","text":"<p>Given: - \\(w_1 = 0\\), \\(w_2 = 0\\), \\(b = 0\\) - \\(\\alpha = 1.0\\) - Activation: Step function (\\(f(z) = 1\\) if \\(z \\geq 0\\), else \\(0\\))</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#part-b-perceptron-learning-iteration-1","title":"Part (b): Perceptron Learning - Iteration 1","text":"<p>Example 1: \\((x_1=1, x_2=1, y=1)\\)</p> <p>Forward Pass: $$ z = w_1 \\cdot x_1 + w_2 \\cdot x_2 + b = 0 \\cdot 1 + 0 \\cdot 1 + 0 = 0 $$ $$ \\hat{y} = f(0) = 1 $$</p> <p>Check: \\(\\hat{y} = 1\\), \\(y = 1\\) \u2192 Correct (no update)</p> <p>Example 2: \\((x_1=2, x_2=2, y=1)\\)</p> <p>Forward Pass: $$ z = 0 \\cdot 2 + 0 \\cdot 2 + 0 = 0 $$ $$ \\hat{y} = f(0) = 1 $$</p> <p>Check: \\(\\hat{y} = 1\\), \\(y = 1\\) \u2192 Correct (no update)</p> <p>Example 3: \\((x_1=0, x_2=0, y=0)\\)</p> <p>Forward Pass: $$ z = 0 \\cdot 0 + 0 \\cdot 0 + 0 = 0 $$ $$ \\hat{y} = f(0) = 1 $$</p> <p>Check: \\(\\hat{y} = 1\\), \\(y = 0\\) \u2192 Wrong! (update needed)</p> <p>Update Weights: $$ w_1 := w_1 + \\alpha \\cdot (y - \\hat{y}) \\cdot x_1 = 0 + 1 \\cdot (0 - 1) \\cdot 0 = 0 $$ $$ w_2 := w_2 + \\alpha \\cdot (y - \\hat{y}) \\cdot x_2 = 0 + 1 \\cdot (0 - 1) \\cdot 0 = 0 $$ $$ b := b + \\alpha \\cdot (y - \\hat{y}) = 0 + 1 \\cdot (0 - 1) = -1 $$</p> <p>After Example 3: \\(w_1 = 0\\), \\(w_2 = 0\\), \\(b = -1\\)</p> <p>Example 4: \\((x_1=1, x_2=0, y=0)\\)</p> <p>Forward Pass: $$ z = 0 \\cdot 1 + 0 \\cdot 0 + (-1) = -1 $$ $$ \\hat{y} = f(-1) = 0 $$</p> <p>Check: \\(\\hat{y} = 0\\), \\(y = 0\\) \u2192 Correct (no update)</p> <p>After Iteration 1: \\(w_1 = 0\\), \\(w_2 = 0\\), \\(b = -1\\)</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#iteration-2","title":"Iteration 2","text":"<p>Example 1: \\((x_1=1, x_2=1, y=1)\\)</p> <p>Forward Pass: $$ z = 0 \\cdot 1 + 0 \\cdot 1 + (-1) = -1 $$ $$ \\hat{y} = f(-1) = 0 $$</p> <p>Check: \\(\\hat{y} = 0\\), \\(y = 1\\) \u2192 Wrong! (update needed)</p> <p>Update: $$ w_1 := 0 + 1 \\cdot (1 - 0) \\cdot 1 = 1 $$ $$ w_2 := 0 + 1 \\cdot (1 - 0) \\cdot 1 = 1 $$ $$ b := -1 + 1 \\cdot (1 - 0) = 0 $$</p> <p>After Example 1: \\(w_1 = 1\\), \\(w_2 = 1\\), \\(b = 0\\)</p> <p>Example 2: \\((x_1=2, x_2=2, y=1)\\)</p> <p>Forward Pass: $$ z = 1 \\cdot 2 + 1 \\cdot 2 + 0 = 4 $$ $$ \\hat{y} = f(4) = 1 $$</p> <p>Check: Correct (no update)</p> <p>Example 3: \\((x_1=0, x_2=0, y=0)\\)</p> <p>Forward Pass: $$ z = 1 \\cdot 0 + 1 \\cdot 0 + 0 = 0 $$ $$ \\hat{y} = f(0) = 1 $$</p> <p>Check: \\(\\hat{y} = 1\\), \\(y = 0\\) \u2192 Wrong!</p> <p>Update: $$ w_1 := 1 + 1 \\cdot (0 - 1) \\cdot 0 = 1 $$ $$ w_2 := 1 + 1 \\cdot (0 - 1) \\cdot 0 = 1 $$ $$ b := 0 + 1 \\cdot (0 - 1) = -1 $$</p> <p>After Example 3: \\(w_1 = 1\\), \\(w_2 = 1\\), \\(b = -1\\)</p> <p>Example 4: \\((x_1=1, x_2=0, y=0)\\)</p> <p>Forward Pass: $$ z = 1 \\cdot 1 + 1 \\cdot 0 + (-1) = 0 $$ $$ \\hat{y} = f(0) = 1 $$</p> <p>Check: \\(\\hat{y} = 1\\), \\(y = 0\\) \u2192 Wrong!</p> <p>Update: $$ w_1 := 1 + 1 \\cdot (0 - 1) \\cdot 1 = 0 $$ $$ w_2 := 1 + 1 \\cdot (0 - 1) \\cdot 0 = 1 $$ $$ b := -1 + 1 \\cdot (0 - 1) = -2 $$</p> <p>After Iteration 2: \\(w_1 = 0\\), \\(w_2 = 1\\), \\(b = -2\\)</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#part-c-decision-boundary","title":"Part (c): Decision Boundary","text":"<p>After 2 iterations: \\(w_1 = 0\\), \\(w_2 = 1\\), \\(b = -2\\)</p> <p>Decision Boundary Equation:</p> \\[ w_1 x_1 + w_2 x_2 + b = 0 \\] \\[ 0 \\cdot x_1 + 1 \\cdot x_2 - 2 = 0 \\] \\[ x_2 = 2 \\] <p>Answer: Decision boundary is the horizontal line \\(x_2 = 2\\)</p> <p>Interpretation:  - Points with \\(x_2 \\geq 2\\) \u2192 Class 1 - Points with \\(x_2 &lt; 2\\) \u2192 Class 0</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#question-2-forward-and-backward-propagation","title":"Question 2: Forward and Backward Propagation","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#problem-statement_1","title":"Problem Statement","text":"<p>Given a 2-layer neural network:</p> <ul> <li>Layer 1: 2 inputs, 3 hidden neurons, ReLU activation</li> <li>Layer 2: 3 inputs (from layer 1), 1 output, linear activation</li> </ul> <p>Weights: $$ \\mathbf{W}^{[1]} = \\begin{bmatrix} 1 &amp; 2 \\ -1 &amp; 1 \\ 0 &amp; 1 \\end{bmatrix}, \\quad \\mathbf{b}^{[1]} = \\begin{bmatrix} 1 \\ 0 \\ -1 \\end{bmatrix} $$</p> \\[ \\mathbf{W}^{[2]} = \\begin{bmatrix} 1 &amp; -1 &amp; 2 \\end{bmatrix}, \\quad b^{[2]} = 0 \\] <p>Input: \\(\\mathbf{x} = [1, 2]^T\\), Target: \\(y = 5\\)</p> <p>a) Perform forward propagation.</p> <p>b) Calculate the loss (MSE).</p> <p>c) Compute gradients for \\(\\mathbf{W}^{[2]}\\) and \\(b^{[2]}\\).</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#solution_1","title":"Solution","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#part-a-forward-propagation","title":"Part (a): Forward Propagation","text":"<p>Layer 1:</p> \\[ \\mathbf{z}^{[1]} = \\mathbf{W}^{[1]} \\mathbf{x} + \\mathbf{b}^{[1]} = \\begin{bmatrix} 1 &amp; 2 \\\\ -1 &amp; 1 \\\\ 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix} \\] \\[ \\mathbf{z}^{[1]} = \\begin{bmatrix} 1 \\cdot 1 + 2 \\cdot 2 \\\\ -1 \\cdot 1 + 1 \\cdot 2 \\\\ 0 \\cdot 1 + 1 \\cdot 2 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} 5 \\\\ 1 \\\\ 2 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ 0 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ 1 \\\\ 1 \\end{bmatrix} \\] <p>ReLU Activation: $$ \\mathbf{a}^{[1]} = \\text{ReLU}(\\mathbf{z}^{[1]}) = \\begin{bmatrix} \\max(0, 6) \\ \\max(0, 1) \\ \\max(0, 1) \\end{bmatrix} = \\begin{bmatrix} 6 \\ 1 \\ 1 \\end{bmatrix} $$</p> <p>Layer 2:</p> \\[ z^{[2]} = \\mathbf{W}^{[2]} \\mathbf{a}^{[1]} + b^{[2]} = \\begin{bmatrix} 1 &amp; -1 &amp; 2 \\end{bmatrix} \\begin{bmatrix} 6 \\\\ 1 \\\\ 1 \\end{bmatrix} + 0 \\] \\[ z^{[2]} = 1 \\cdot 6 + (-1) \\cdot 1 + 2 \\cdot 1 = 6 - 1 + 2 = 7 \\] <p>Linear Activation: $$ \\hat{y} = z^{[2]} = 7 $$</p> <p>Answer: \\(\\hat{y} = 7\\)</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#part-b-loss-calculation","title":"Part (b): Loss Calculation","text":"<p>Mean Squared Error:</p> \\[ J = \\frac{1}{2}(\\hat{y} - y)^2 = \\frac{1}{2}(7 - 5)^2 = \\frac{1}{2} \\cdot 4 = 2 \\] <p>Answer: Loss \\(J = 2\\)</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#part-c-gradient-computation","title":"Part (c): Gradient Computation","text":"<p>Gradient w.r.t. \\(z^{[2]}\\):</p> \\[ \\frac{\\partial J}{\\partial z^{[2]}} = \\hat{y} - y = 7 - 5 = 2 \\] <p>Gradient w.r.t. \\(\\mathbf{W}^{[2]}\\):</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{W}^{[2]}} = \\frac{\\partial J}{\\partial z^{[2]}} \\cdot (\\mathbf{a}^{[1]})^T = 2 \\cdot \\begin{bmatrix} 6 \\\\ 1 \\\\ 1 \\end{bmatrix}^T = \\begin{bmatrix} 12 &amp; 2 &amp; 2 \\end{bmatrix} \\] <p>Gradient w.r.t. \\(b^{[2]}\\):</p> \\[ \\frac{\\partial J}{\\partial b^{[2]}} = \\frac{\\partial J}{\\partial z^{[2]}} = 2 \\] <p>Answer: - \\(\\frac{\\partial J}{\\partial \\mathbf{W}^{[2]}} = [12, 2, 2]\\) - \\(\\frac{\\partial J}{\\partial b^{[2]}} = 2\\)</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#question-3-activation-functions","title":"Question 3: Activation Functions","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#problem-statement_2","title":"Problem Statement","text":"<p>a) Calculate the output of a neuron with: - Input: \\(z = 2\\) - Activation: Sigmoid function</p> <p>b) Calculate the derivative of sigmoid at \\(z = 2\\).</p> <p>c) Why is ReLU preferred over sigmoid for hidden layers?</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#solution_2","title":"Solution","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#part-a-sigmoid-output","title":"Part (a): Sigmoid Output","text":"<p>Sigmoid Function:</p> \\[ \\sigma(z) = \\frac{1}{1 + e^{-z}} \\] <p>For \\(z = 2\\):</p> \\[ \\sigma(2) = \\frac{1}{1 + e^{-2}} = \\frac{1}{1 + 0.1353} = \\frac{1}{1.1353} = 0.881 \\] <p>Answer: \\(\\sigma(2) = 0.881\\)</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#part-b-sigmoid-derivative","title":"Part (b): Sigmoid Derivative","text":"<p>Derivative Formula:</p> \\[ \\frac{d\\sigma}{dz} = \\sigma(z)(1 - \\sigma(z)) \\] <p>At \\(z = 2\\):</p> \\[ \\frac{d\\sigma}{dz}\\bigg|_{z=2} = \\sigma(2)(1 - \\sigma(2)) = 0.881 \\times (1 - 0.881) = 0.881 \\times 0.119 = 0.105 \\] <p>Answer: Derivative = \\(0.105\\)</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#part-c-relu-vs-sigmoid-for-hidden-layers","title":"Part (c): ReLU vs Sigmoid for Hidden Layers","text":"<p>ReLU Advantages:</p> <ol> <li>Solves Vanishing Gradient:</li> <li>ReLU derivative = 1 (when active)</li> <li>Sigmoid derivative \u2264 0.25 (always small)</li> <li> <p>In deep networks, sigmoid gradients vanish quickly</p> </li> <li> <p>Computational Efficiency:</p> </li> <li>ReLU: Simple max operation</li> <li> <p>Sigmoid: Requires exponential computation</p> </li> <li> <p>Sparsity:</p> </li> <li>ReLU creates sparse representations (many zeros)</li> <li> <p>Can be beneficial for learning</p> </li> <li> <p>Faster Convergence:</p> </li> <li>ReLU networks train faster</li> <li>Less prone to saturation</li> </ol> <p>Sigmoid Issues: - Vanishing gradients in deep networks - Saturation (outputs near 0 or 1) - Not zero-centered</p> <p>Answer: ReLU is preferred because it prevents vanishing gradients, is computationally efficient, and enables faster training in deep networks.</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#question-4-backpropagation-in-deep-network","title":"Question 4: Backpropagation in Deep Network","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#problem-statement_3","title":"Problem Statement","text":"<p>Given a 3-layer network with: - Layer 1: 2 inputs \u2192 3 hidden (ReLU) - Layer 2: 3 hidden \u2192 2 hidden (ReLU) - Layer 3: 2 hidden \u2192 1 output (sigmoid)</p> <p>Given: - \\(\\frac{\\partial J}{\\partial z^{[3]}} = 0.5\\) - \\(\\mathbf{W}^{[3]} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\\) - \\(\\mathbf{a}^{[2]} = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\\) - \\(\\mathbf{z}^{[2]} = \\begin{bmatrix} 3 \\\\ -1 \\end{bmatrix}\\)</p> <p>Calculate: a) \\(\\frac{\\partial J}{\\partial \\mathbf{W}^{[3]}}\\) b) \\(\\frac{\\partial J}{\\partial \\mathbf{z}^{[2]}}\\)</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#solution_3","title":"Solution","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#part-a-gradient-wrt-mathbfw3","title":"Part (a): Gradient w.r.t. \\(\\mathbf{W}^{[3]}\\)","text":"<p>Formula:</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{W}^{[3]}} = \\frac{\\partial J}{\\partial z^{[3]}} \\cdot (\\mathbf{a}^{[2]})^T \\] <p>Calculation:</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{W}^{[3]}} = 0.5 \\cdot \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}^T = 0.5 \\cdot \\begin{bmatrix} 2 &amp; 1 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 0.5 \\end{bmatrix} \\] <p>Answer: \\(\\frac{\\partial J}{\\partial \\mathbf{W}^{[3]}} = [1, 0.5]\\)</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#part-b-gradient-wrt-mathbfz2","title":"Part (b): Gradient w.r.t. \\(\\mathbf{z}^{[2]}\\)","text":"<p>Formula:</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{z}^{[2]}} = (\\mathbf{W}^{[3]})^T \\frac{\\partial J}{\\partial z^{[3]}} \\odot g'^{[2]}(\\mathbf{z}^{[2]}) \\] <p>Step 1: Compute \\((\\mathbf{W}^{[3]})^T \\frac{\\partial J}{\\partial z^{[3]}}\\):</p> \\[ (\\mathbf{W}^{[3]})^T \\frac{\\partial J}{\\partial z^{[3]}} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}^T \\cdot 0.5 = \\begin{bmatrix} 1 &amp; -1 \\end{bmatrix} \\cdot 0.5 = \\begin{bmatrix} 0.5 &amp; -0.5 \\end{bmatrix} \\] <p>Wait, this should be a column vector. Let me recalculate:</p> \\[ (\\mathbf{W}^{[3]})^T \\frac{\\partial J}{\\partial z^{[3]}} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} \\cdot 0.5 = \\begin{bmatrix} 0.5 \\\\ -0.5 \\end{bmatrix} \\] <p>Step 2: Compute ReLU derivative \\(g'^{[2]}(\\mathbf{z}^{[2]})\\):</p> \\[ g'^{[2]}(\\mathbf{z}^{[2]}) = \\begin{bmatrix} \\text{ReLU}'(3) \\\\ \\text{ReLU}'(-1) \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\] <p>Step 3: Element-wise multiplication:</p> \\[ \\frac{\\partial J}{\\partial \\mathbf{z}^{[2]}} = \\begin{bmatrix} 0.5 \\\\ -0.5 \\end{bmatrix} \\odot \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0.5 \\\\ 0 \\end{bmatrix} \\] <p>Answer: \\(\\frac{\\partial J}{\\partial \\mathbf{z}^{[2]}} = [0.5, 0]^T\\)</p> <p>Key Point</p> <p>Notice that the gradient for the second neuron is 0 because ReLU is inactive (input was negative). This is the \"dead ReLU\" problem.</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#question-5-cnn-convolution-operation","title":"Question 5: CNN Convolution Operation","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#problem-statement_4","title":"Problem Statement","text":"<p>Given: - Input Image: 5\u00d75 matrix - Filter: 3\u00d73 matrix - Stride: 1 - Padding: 0 (valid)</p> <p>a) Calculate the output size.</p> <p>b) Perform convolution operation for the top-left position.</p> <p>Input: $$ \\mathbf{X} = \\begin{bmatrix} 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\ 6 &amp; 7 &amp; 8 &amp; 9 &amp; 0 \\ 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\ 6 &amp; 7 &amp; 8 &amp; 9 &amp; 0 \\ 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\end{bmatrix} $$</p> <p>Filter: $$ \\mathbf{F} = \\begin{bmatrix} 1 &amp; 0 &amp; -1 \\ 1 &amp; 0 &amp; -1 \\ 1 &amp; 0 &amp; -1 \\end{bmatrix} $$</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#solution_4","title":"Solution","text":""},{"location":"dnn/papers/2024-midsem-regular-solved/#part-a-output-size","title":"Part (a): Output Size","text":"<p>Formula:</p> \\[ \\text{Output Size} = \\frac{\\text{Input Size} - \\text{Filter Size} + 2 \\times \\text{Padding}}{\\text{Stride}} + 1 \\] <p>Calculation:</p> \\[ \\text{Output Size} = \\frac{5 - 3 + 2 \\times 0}{1} + 1 = \\frac{2}{1} + 1 = 3 \\] <p>Answer: Output size = 3\u00d73</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#part-b-convolution-at-top-left-position","title":"Part (b): Convolution at Top-Left Position","text":"<p>Top-left 3\u00d73 region of input:</p> \\[ \\begin{bmatrix} 1 &amp; 2 &amp; 3 \\\\ 6 &amp; 7 &amp; 8 \\\\ 1 &amp; 2 &amp; 3 \\end{bmatrix} \\] <p>Convolution Operation:</p> \\[ \\text{Output}(0, 0) = \\sum_{i=0}^{2} \\sum_{j=0}^{2} X(i, j) \\cdot F(i, j) \\] <p>Element-wise multiplication and sum:</p> \\[ = 1 \\cdot 1 + 2 \\cdot 0 + 3 \\cdot (-1) + 6 \\cdot 1 + 7 \\cdot 0 + 8 \\cdot (-1) + 1 \\cdot 1 + 2 \\cdot 0 + 3 \\cdot (-1) \\] \\[ = 1 + 0 - 3 + 6 + 0 - 8 + 1 + 0 - 3 \\] \\[ = (1 + 6 + 1) + (0 + 0 + 0) + (-3 - 8 - 3) \\] \\[ = 8 + 0 - 14 = -6 \\] <p>Answer: Output at position (0, 0) = -6</p> <p>Interpretation: This filter detects vertical edges (difference between left and right columns).</p>"},{"location":"dnn/papers/2024-midsem-regular-solved/#summary","title":"Summary","text":"<p>This paper covered: 1. \u2705 Perceptron Learning Algorithm with step-by-step iterations 2. \u2705 Forward and Backward Propagation in multi-layer networks 3. \u2705 Activation Functions (Sigmoid, ReLU) and their derivatives 4. \u2705 Backpropagation through multiple layers 5. \u2705 CNN Convolution Operation</p> <p>Key Takeaways: - Always show step-by-step calculations for perceptron updates - Understand forward and backward propagation formulas - Know activation function derivatives by heart - Practice convolution operations manually - Understand gradient flow in deep networks</p> <p>Good luck with your exam! \ud83c\udfaf</p>"},{"location":"ml/","title":"Machine Learning - Complete Revision Guide","text":"<p>Welcome to the Machine Learning revision guide. This section covers all modules with detailed explanations, formulas, and important concepts.</p>"},{"location":"ml/#modules-overview","title":"\ud83d\udcd6 Modules Overview","text":"<ol> <li> <p>Module 1: Introduction to Machine Learning</p> <ul> <li>What is Machine Learning</li> <li>Types of Learning (Supervised, Unsupervised, Reinforcement)</li> <li>Applications and Examples</li> <li>Overfitting vs Underfitting</li> <li>Bias-Variance Tradeoff</li> </ul> </li> <li> <p>Module 2: Supervised Learning</p> <ul> <li>Linear Regression (Simple &amp; Multiple)</li> <li>Logistic Regression</li> <li>Gradient Descent Algorithm</li> <li>Cost Functions (MSE, Cross-Entropy)</li> <li>Regularization</li> </ul> </li> <li> <p>Module 3: Classification &amp; Evaluation</p> <ul> <li>Classification Algorithms (KNN, SVM)</li> <li>Confusion Matrix</li> <li>Evaluation Metrics (Accuracy, Precision, Recall, F1-Score)</li> <li>ROC Curve and AUC</li> <li>Precision-Recall Curve</li> </ul> </li> <li> <p>Module 4: Unsupervised Learning</p> <ul> <li>Clustering (K-Means, Hierarchical)</li> <li>Dimensionality Reduction (PCA)</li> <li>Association Rules (Apriori Algorithm)</li> </ul> </li> <li> <p>Module 5: Decision Trees</p> <ul> <li>Decision Tree Algorithm</li> <li>Entropy and Information Gain</li> <li>Gini Impurity</li> <li>Pruning Techniques</li> </ul> </li> </ol>"},{"location":"ml/#solved-previous-year-papers","title":"\ud83d\udcda Solved Previous Year Papers","text":"<ul> <li>2024 Regular Paper - Complete Solutions</li> <li>2024 Makeup Paper - Detailed Solutions</li> <li>2025 Practice Set - Step-by-Step Solutions</li> </ul>"},{"location":"ml/#important-topics-for-exam","title":"\ud83c\udfaf Important Topics for Exam","text":""},{"location":"ml/#must-know-concepts","title":"Must Know Concepts","text":"<ul> <li>Supervised vs Unsupervised Learning</li> <li>Linear Regression (Simple and Multiple)</li> <li>Logistic Regression and Sigmoid Function</li> <li>Evaluation Metrics (all formulas)</li> <li>Decision Tree Construction</li> <li>K-Means Clustering Algorithm</li> <li>Principal Component Analysis (PCA)</li> </ul>"},{"location":"ml/#key-formulas","title":"Key Formulas","text":"<ul> <li>Cost Function (MSE, Cross-Entropy)</li> <li>Gradient Descent Update Rule</li> <li>Information Gain</li> <li>Entropy</li> <li>Gini Index</li> <li>Precision, Recall, F1-Score</li> </ul> <p>Start with Module 1 and work through systematically!</p>"},{"location":"ml/cheatsheet/","title":"Machine Learning Cheat Sheet","text":"<p>Quick reference guide for all important formulas, concepts, and algorithms.</p>"},{"location":"ml/cheatsheet/#key-formulas","title":"\ud83d\udcd0 Key Formulas","text":""},{"location":"ml/cheatsheet/#linear-regression","title":"Linear Regression","text":"<p>Hypothesis Function: $$ h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\ldots + \\theta_n x_n = \\theta^T x $$</p> <p>Cost Function (MSE): $$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y<sup>{(i)})</sup>2 $$</p> <p>Gradient Descent Update: $$ \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} $$</p> <p>Normal Equation: $$ \\theta = (X^T X)^{-1} X^T y $$</p>"},{"location":"ml/cheatsheet/#logistic-regression","title":"Logistic Regression","text":"<p>Sigmoid Function: $$ g(z) = \\frac{1}{1 + e^{-z}} $$</p> <p>Hypothesis: $$ h_\\theta(x) = g(\\theta^T x) = \\frac{1}{1 + e<sup>{-\\theta</sup>T x}} $$</p> <p>Cost Function (Cross-Entropy): $$ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))] $$</p> <p>Decision Boundary: \\(\\theta^T x = 0\\)</p>"},{"location":"ml/cheatsheet/#regularization","title":"Regularization","text":"<p>Regularized Cost (Linear Regression): $$ J(\\theta) = \\frac{1}{2m} \\left[ \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y<sup>{(i)})</sup>2 + \\lambda \\sum_{j=1}^{n} \\theta_j^2 \\right] $$</p> <p>Regularized Cost (Logistic Regression): $$ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\theta_j^2 $$</p> <p>Regularized Gradient Update: $$ \\theta_j := \\theta_j \\left(1 - \\alpha \\frac{\\lambda}{m}\\right) - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} $$</p>"},{"location":"ml/cheatsheet/#evaluation-metrics","title":"Evaluation Metrics","text":"<p>Accuracy: $$ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $$</p> <p>Precision: $$ \\text{Precision} = \\frac{TP}{TP + FP} $$</p> <p>Recall (Sensitivity): $$ \\text{Recall} = \\frac{TP}{TP + FN} = \\text{TPR} $$</p> <p>Specificity: $$ \\text{Specificity} = \\frac{TN}{TN + FP} = \\text{TNR} $$</p> <p>F1-Score: $$ \\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} = \\frac{2TP}{2TP + FP + FN} $$</p> <p>False Positive Rate: $$ \\text{FPR} = \\frac{FP}{FP + TN} $$</p> <p>False Negative Rate: $$ \\text{FNR} = \\frac{FN}{FN + TP} $$</p>"},{"location":"ml/cheatsheet/#decision-trees","title":"Decision Trees","text":"<p>Entropy: $$ H(S) = -\\sum_{i=1}^{c} p_i \\log_2(p_i) $$</p> <p>Gini Impurity: $$ \\text{Gini}(S) = 1 - \\sum_{i=1}^{c} p_i^2 $$</p> <p>Information Gain: $$ \\text{IG}(S, A) = H(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} H(S_v) $$</p> <p>Information Gain Ratio: $$ \\text{IGR}(S, A) = \\frac{\\text{IG}(S, A)}{\\text{SplitInfo}(S, A)} $$</p> <p>Split Information: $$ \\text{SplitInfo}(S, A) = -\\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} \\log_2\\left(\\frac{|S_v|}{|S|}\\right) $$</p>"},{"location":"ml/cheatsheet/#k-means-clustering","title":"K-Means Clustering","text":"<p>Cost Function (Within-cluster sum of squares): $$ J = \\sum_{i=1}^{m} \\sum_{k=1}^{K} w_{ik} ||x^{(i)} - \\mu_k||^2 $$</p> <p>Centroid Update: $$ \\mu_k = \\frac{1}{|C_k|} \\sum_{x \\in C_k} x $$</p> <p>Euclidean Distance: $$ d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2} $$</p>"},{"location":"ml/cheatsheet/#principal-component-analysis-pca","title":"Principal Component Analysis (PCA)","text":"<p>Covariance Matrix: $$ \\Sigma = \\frac{1}{m} X^T X $$</p> <p>Variance Explained: $$ \\text{Variance Explained} = \\frac{\\lambda_i}{\\sum_{j=1}^{n} \\lambda_j} $$</p> <p>Cumulative Variance: $$ \\text{Cumulative} = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{j=1}^{n} \\lambda_j} $$</p>"},{"location":"ml/cheatsheet/#association-rules","title":"Association Rules","text":"<p>Support: $$ \\text{Support}(A) = \\frac{\\text{Count}(A)}{N} $$</p> <p>Confidence: $$ \\text{Confidence}(A \\to B) = \\frac{\\text{Support}(A \\cup B)}{\\text{Support}(A)} = P(B|A) $$</p> <p>Lift: $$ \\text{Lift}(A \\to B) = \\frac{\\text{Confidence}(A \\to B)}{\\text{Support}(B)} = \\frac{P(B|A)}{P(B)} $$</p>"},{"location":"ml/cheatsheet/#quick-reference","title":"\ud83c\udfaf Quick Reference","text":""},{"location":"ml/cheatsheet/#confusion-matrix","title":"Confusion Matrix","text":"<pre><code>                Predicted\n              Positive  Negative\nActual Positive    TP       FN\n       Negative    FP       TN\n</code></pre>"},{"location":"ml/cheatsheet/#roc-curve","title":"ROC Curve","text":"<ul> <li>X-axis: False Positive Rate (FPR)</li> <li>Y-axis: True Positive Rate (TPR) = Recall</li> <li>AUC: Area under the curve (higher is better)</li> <li>Perfect Classifier: (0, 1) - top-left corner</li> <li>Random Classifier: Diagonal line (AUC = 0.5)</li> </ul>"},{"location":"ml/cheatsheet/#decision-tree-algorithms","title":"Decision Tree Algorithms","text":"Algorithm Impurity Measure Features Pruning ID3 Entropy Categorical only No C4.5 Information Gain Ratio Categorical + Continuous Yes CART Gini (classification) / MSE (regression) Both Yes"},{"location":"ml/cheatsheet/#learning-rate-guidelines","title":"Learning Rate Guidelines","text":"<ul> <li>Too Small: Slow convergence</li> <li>Too Large: May overshoot, may not converge</li> <li>Good Range: 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0</li> </ul>"},{"location":"ml/cheatsheet/#regularization-parameter","title":"Regularization Parameter (\u03bb)","text":"<ul> <li>Large \u03bb: Strong regularization \u2192 Simpler model (may underfit)</li> <li>Small \u03bb: Weak regularization \u2192 Complex model (may overfit)</li> <li>\u03bb = 0: No regularization</li> </ul>"},{"location":"ml/cheatsheet/#important-properties","title":"\ud83d\udcdd Important Properties","text":""},{"location":"ml/cheatsheet/#entropy-properties","title":"Entropy Properties","text":"<ul> <li>Range: \\([0, \\log_2(c)]\\)</li> <li>Pure node: \\(H(S) = 0\\)</li> <li>Maximum (binary): \\(H(S) = 1\\) when \\(p_1 = p_2 = 0.5\\)</li> </ul>"},{"location":"ml/cheatsheet/#gini-properties","title":"Gini Properties","text":"<ul> <li>Range: \\([0, 1 - \\frac{1}{c}]\\)</li> <li>Pure node: \\(\\text{Gini}(S) = 0\\)</li> <li>Maximum (binary): \\(\\text{Gini}(S) = 0.5\\) when \\(p_1 = p_2 = 0.5\\)</li> </ul>"},{"location":"ml/cheatsheet/#sigmoid-function","title":"Sigmoid Function","text":"<ul> <li>Range: \\((0, 1)\\)</li> <li>\\(g(0) = 0.5\\)</li> <li>As \\(z \\to +\\infty\\), \\(g(z) \\to 1\\)</li> <li>As \\(z \\to -\\infty\\), \\(g(z) \\to 0\\)</li> </ul>"},{"location":"ml/cheatsheet/#algorithm-selection-guide","title":"\ud83d\udd0d Algorithm Selection Guide","text":""},{"location":"ml/cheatsheet/#when-to-use-what","title":"When to Use What?","text":"<p>Linear Regression: - \u2705 Predicting continuous values - \u2705 Linear relationship between features and target - \u2705 Interpretable coefficients</p> <p>Logistic Regression: - \u2705 Binary classification - \u2705 Need probability estimates - \u2705 Interpretable decision boundary</p> <p>Decision Trees: - \u2705 Need interpretable model - \u2705 Mixed data types (categorical + numerical) - \u2705 Non-linear relationships</p> <p>K-Means: - \u2705 Unsupervised clustering - \u2705 Known number of clusters - \u2705 Spherical clusters</p> <p>PCA: - \u2705 Dimensionality reduction - \u2705 Data visualization - \u2705 Noise reduction</p>"},{"location":"ml/cheatsheet/#common-mistakes-to-avoid","title":"\u26a0\ufe0f Common Mistakes to Avoid","text":"<ol> <li>Forgetting to standardize features before gradient descent or PCA</li> <li>Not regularizing \\(\\theta_0\\) (bias term) in regularization</li> <li>Using accuracy for imbalanced datasets (use F1-Score or AUC instead)</li> <li>Choosing K in K-Means without domain knowledge or elbow method</li> <li>Not handling \\(\\log(0)\\) in entropy calculations (define as 0)</li> <li>Confusing Information Gain with Information Gain Ratio</li> <li>Using MSE for logistic regression (use cross-entropy instead)</li> </ol>"},{"location":"ml/cheatsheet/#exam-tips","title":"\ud83d\udca1 Exam Tips","text":"<ol> <li>Memorize key formulas: Entropy, Gini, Information Gain, Precision, Recall, F1-Score</li> <li>Understand when to use each metric: Precision vs Recall tradeoff</li> <li>Know algorithm differences: ID3 vs C4.5 vs CART</li> <li>Practice gradient descent iterations: Show step-by-step calculations</li> <li>Understand regularization: Effect of \\(\\lambda\\) on model complexity</li> <li>ROC Curve interpretation: Higher AUC = Better classifier</li> <li>Decision tree construction: Always show entropy/IG calculations</li> </ol> <p>Print this page for quick reference during exam preparation! \ud83d\udcc4</p>"},{"location":"ml/module1-introduction/","title":"Module 1: Introduction to Machine Learning","text":""},{"location":"ml/module1-introduction/#what-is-machine-learning","title":"What is Machine Learning?","text":"<p>Machine Learning (ML) is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. Instead of following pre-programmed instructions, ML algorithms build mathematical models based on training data to make predictions or decisions.</p> <p>Tom Mitchell's Definition</p> <p>\"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\"</p>"},{"location":"ml/module1-introduction/#breaking-down-the-definition","title":"Breaking Down the Definition","text":"Component Description Example Task (T) What the system should do Classify emails as spam/not spam Experience (E) Data the system learns from Collection of labeled emails Performance (P) How we measure success Accuracy of classification <p>Spam Filter Example</p> <ul> <li>Task: Classify incoming emails as spam or not spam</li> <li>Experience: Database of 10,000 labeled emails</li> <li>Performance: 98% accuracy on new emails</li> </ul> <p>The system \"learns\" by finding patterns in spam emails (certain words, sender patterns, etc.)</p>"},{"location":"ml/module1-introduction/#why-machine-learning","title":"Why Machine Learning?","text":""},{"location":"ml/module1-introduction/#traditional-programming-vs-machine-learning","title":"Traditional Programming vs Machine Learning","text":"<pre><code>Traditional Programming:\n    Input Data + Rules \u2192 Computer \u2192 Output\n\nMachine Learning:\n    Input Data + Output \u2192 Computer \u2192 Rules (Model)\n</code></pre> <p>Key Insight</p> <p>In traditional programming, humans write rules. In ML, the computer discovers rules from data!</p>"},{"location":"ml/module1-introduction/#when-to-use-machine-learning","title":"When to Use Machine Learning","text":"<p>\u2705 Use ML when:</p> <ol> <li>Rules are complex or unknown: Face recognition, speech understanding</li> <li>Rules change frequently: Stock market prediction, spam detection</li> <li>Data is abundant: Customer behavior analysis</li> <li>Human expertise is scarce: Medical diagnosis in remote areas</li> </ol> <p>\u274c Don't use ML when:</p> <ol> <li>Rules are simple and well-defined (use traditional programming)</li> <li>Insufficient data available</li> <li>Explainability is critical and simple rules exist</li> <li>Cost of errors is too high without human oversight</li> </ol>"},{"location":"ml/module1-introduction/#types-of-machine-learning","title":"Types of Machine Learning","text":""},{"location":"ml/module1-introduction/#1-supervised-learning","title":"1. Supervised Learning","text":"<p>Definition</p> <p>Learning with labeled training data. The algorithm learns from input-output pairs to predict outputs for new inputs.</p> <p>How it works:</p> <pre><code>Training Phase:\n    Input Features (X) + Labels (Y) \u2192 Algorithm \u2192 Model\n\nPrediction Phase:\n    New Input (X') \u2192 Model \u2192 Predicted Output (\u0176)\n</code></pre>"},{"location":"ml/module1-introduction/#classification-vs-regression","title":"Classification vs Regression","text":"Aspect Classification Regression Output Type Discrete categories Continuous values Question \"What category?\" \"How much/many?\" Examples Spam detection, disease diagnosis House price, temperature Evaluation Accuracy, F1-Score MSE, RMSE, R\u00b2 <p>Classification Examples</p> <ul> <li>Binary Classification: Email spam detection (Spam/Not Spam)</li> <li>Multi-class Classification: Digit recognition (0-9)</li> <li>Multi-label Classification: Image tagging (can have multiple tags)</li> </ul> <p>Regression Examples</p> <ul> <li>House price prediction based on features</li> <li>Stock price forecasting</li> <li>Temperature prediction</li> <li>Sales forecasting</li> </ul> <p>Common Supervised Learning Algorithms:</p> Algorithm Type Best For Linear Regression Regression Linear relationships Logistic Regression Classification Binary classification Decision Trees Both Interpretable models Random Forest Both Complex patterns, ensemble SVM Both High-dimensional data Neural Networks Both Complex patterns, large data"},{"location":"ml/module1-introduction/#2-unsupervised-learning","title":"2. Unsupervised Learning","text":"<p>Definition</p> <p>Learning from unlabeled data. The algorithm finds hidden patterns or structures without guidance.</p> <p>How it works:</p> <pre><code>Training Phase:\n    Input Data (X) only \u2192 Algorithm \u2192 Patterns/Clusters\n\nApplication:\n    New Data \u2192 Model \u2192 Group Assignment/Reduced Features\n</code></pre>"},{"location":"ml/module1-introduction/#types-of-unsupervised-learning","title":"Types of Unsupervised Learning","text":"<p>a) Clustering</p> <ul> <li>Goal: Group similar data points together</li> <li>Output: Cluster assignments</li> </ul> Algorithm Description Best For K-Means Partition into K clusters Spherical clusters Hierarchical Build tree of clusters Unknown K, hierarchies DBSCAN Density-based clustering Arbitrary shapes, outliers <p>Clustering Applications</p> <ul> <li>Customer segmentation for marketing</li> <li>Image segmentation</li> <li>Anomaly/fraud detection</li> <li>Document grouping</li> </ul> <p>b) Dimensionality Reduction</p> <ul> <li>Goal: Reduce number of features while preserving information</li> <li>Output: Lower-dimensional representation</li> </ul> Algorithm Description Best For PCA Linear projection to max variance Visualization, preprocessing t-SNE Non-linear, preserves local structure Visualization Autoencoders Neural network-based Complex patterns <p>Dimensionality Reduction Applications</p> <ul> <li>Data visualization (reduce to 2D/3D)</li> <li>Feature extraction</li> <li>Noise reduction</li> <li>Data compression</li> </ul> <p>c) Association Rule Learning</p> <ul> <li>Goal: Discover relationships between variables</li> <li>Output: Rules like \"If A, then B\"</li> </ul> <p>Market Basket Analysis</p> <ul> <li>\"Customers who buy bread also buy butter\" (70% confidence)</li> <li>Used for product recommendations, store layout optimization</li> </ul>"},{"location":"ml/module1-introduction/#3-reinforcement-learning","title":"3. Reinforcement Learning","text":"<p>Definition</p> <p>Learning through interaction with an environment. The agent takes actions and receives rewards/penalties.</p> <p>How it works:</p> <pre><code>Agent \u2192 Action \u2192 Environment\n         \u2191           \u2193\n      Reward \u2190 State Change\n</code></pre> <p>Key Concepts:</p> Term Description Agent The learner/decision maker Environment What the agent interacts with State Current situation Action What the agent can do Reward Feedback signal (positive/negative) Policy Strategy for choosing actions <p>Reinforcement Learning Applications</p> <ul> <li>Game playing (AlphaGo, Chess engines)</li> <li>Robotics (walking, manipulation)</li> <li>Autonomous vehicles</li> <li>Recommendation systems</li> <li>Resource management</li> </ul>"},{"location":"ml/module1-introduction/#comparison-of-learning-types","title":"Comparison of Learning Types","text":"Aspect Supervised Unsupervised Reinforcement Labels Required Not required Rewards only Goal Predict output Find patterns Maximize reward Feedback Direct (labels) None Delayed (rewards) Example Spam detection Customer clustering Game playing <p>Exam Tip</p> <p>When asked to identify learning type, ask:</p> <ol> <li>Is there a labeled output? \u2192 Supervised</li> <li>Is there no output, just finding patterns? \u2192 Unsupervised</li> <li>Is there an agent learning from rewards? \u2192 Reinforcement</li> </ol>"},{"location":"ml/module1-introduction/#machine-learning-workflow","title":"Machine Learning Workflow","text":""},{"location":"ml/module1-introduction/#complete-pipeline","title":"Complete Pipeline","text":"<pre><code>1. Problem Definition\n        \u2193\n2. Data Collection\n        \u2193\n3. Data Preprocessing\n        \u2193\n4. Exploratory Data Analysis (EDA)\n        \u2193\n5. Feature Engineering\n        \u2193\n6. Model Selection\n        \u2193\n7. Training\n        \u2193\n8. Evaluation\n        \u2193\n9. Hyperparameter Tuning\n        \u2193\n10. Deployment &amp; Monitoring\n</code></pre>"},{"location":"ml/module1-introduction/#step-by-step-details","title":"Step-by-Step Details","text":""},{"location":"ml/module1-introduction/#1-problem-definition","title":"1. Problem Definition","text":"<ul> <li>Define the task clearly</li> <li>Identify success metrics</li> <li>Understand business requirements</li> </ul>"},{"location":"ml/module1-introduction/#2-data-collection","title":"2. Data Collection","text":"<ul> <li>Gather relevant data</li> <li>Ensure data quality and quantity</li> <li>Consider data sources and biases</li> </ul>"},{"location":"ml/module1-introduction/#3-data-preprocessing","title":"3. Data Preprocessing","text":"<p>Critical Step</p> <p>Most ML projects spend 60-80% of time on data preprocessing!</p> <p>Common preprocessing steps:</p> Step Description Techniques Missing Values Handle incomplete data Remove, impute (mean/median/mode) Outliers Handle extreme values Remove, cap, transform Encoding Convert categorical to numerical One-hot, Label encoding Scaling Normalize feature ranges Min-Max, Standardization Data Splitting Divide into train/val/test Random split, stratified <p>Feature Scaling Methods:</p> <p>Min-Max Normalization (scales to [0, 1]):</p> \\[ x_{normalized} = \\frac{x - x_{min}}{x_{max} - x_{min}} \\] <p>Standardization (z-score, mean=0, std=1):</p> \\[ x_{standardized} = \\frac{x - \\mu}{\\sigma} \\] <p>When to Use Which</p> <ul> <li>Min-Max: When you need bounded values (e.g., neural networks with sigmoid)</li> <li>Standardization: When data has outliers, or algorithm assumes normal distribution</li> </ul>"},{"location":"ml/module1-introduction/#4-feature-engineering","title":"4. Feature Engineering","text":"<ul> <li>Create new features from existing ones</li> <li>Select most relevant features</li> <li>Domain knowledge is crucial</li> </ul> <p>Feature Engineering Examples</p> <ul> <li>Date: Extract day, month, year, day of week, is_weekend</li> <li>Text: Word count, sentiment score, TF-IDF</li> <li>Combinations: price_per_sqft = price / area</li> </ul>"},{"location":"ml/module1-introduction/#5-model-selection","title":"5. Model Selection","text":"<p>Consider: - Problem type (classification/regression) - Data size and dimensionality - Interpretability requirements - Training time constraints</p>"},{"location":"ml/module1-introduction/#6-8-training-and-evaluation","title":"6-8. Training and Evaluation","text":"<ul> <li>Train model on training data</li> <li>Evaluate on validation/test data</li> <li>Use appropriate metrics</li> </ul>"},{"location":"ml/module1-introduction/#9-hyperparameter-tuning","title":"9. Hyperparameter Tuning","text":"<ul> <li>Grid Search: Try all combinations</li> <li>Random Search: Sample random combinations</li> <li>Bayesian Optimization: Smart search</li> </ul>"},{"location":"ml/module1-introduction/#10-deployment","title":"10. Deployment","text":"<ul> <li>Deploy model to production</li> <li>Monitor performance</li> <li>Retrain as needed</li> </ul>"},{"location":"ml/module1-introduction/#overfitting-vs-underfitting","title":"Overfitting vs Underfitting","text":""},{"location":"ml/module1-introduction/#the-fundamental-tradeoff","title":"The Fundamental Tradeoff","text":"<p>Overfitting</p> <p>Model is too complex - memorizes training data, fails on new data.</p> <p>Symptoms: - High training accuracy - Low test accuracy - Large gap between train and test performance</p> <p>Underfitting</p> <p>Model is too simple - cannot capture underlying patterns.</p> <p>Symptoms: - Low training accuracy - Low test accuracy - Both performances are poor</p>"},{"location":"ml/module1-introduction/#visual-understanding","title":"Visual Understanding","text":"<pre><code>Underfitting          Good Fit           Overfitting\n(High Bias)          (Balanced)         (High Variance)\n\n    *   *              *   *               *   *\n  *       *          *       *           *       *\n*           *      *           *       *     *     *\n  --------         ~~~~~~~~~           ~~~~~~~~*~~~\n(straight line)   (smooth curve)      (wiggly curve)\n</code></pre>"},{"location":"ml/module1-introduction/#causes-and-solutions","title":"Causes and Solutions","text":"Problem Causes Solutions Overfitting Model too complex Regularization (L1, L2) Too many features Feature selection Too little data Get more data Training too long Early stopping Underfitting Model too simple Increase complexity Too few features Add more features Too much regularization Reduce regularization Training too short Train longer"},{"location":"ml/module1-introduction/#detecting-overfittingunderfitting","title":"Detecting Overfitting/Underfitting","text":"<p>Learning Curves: Plot training and validation error vs. training set size</p> <pre><code>Overfitting:                    Underfitting:\nError                           Error\n  |                               |\n  |  Val Error                    |  Val Error \u2248 Train Error\n  |  --------                     |  --------\n  |                               |\n  |  Train Error                  |  \n  |  --------                     |  --------\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    Training Size                   Training Size\n</code></pre> <p>Exam Tip</p> <ul> <li>High training error, high test error \u2192 Underfitting</li> <li>Low training error, high test error \u2192 Overfitting</li> <li>Low training error, low test error \u2192 Good fit</li> </ul>"},{"location":"ml/module1-introduction/#bias-variance-tradeoff","title":"Bias-Variance Tradeoff","text":""},{"location":"ml/module1-introduction/#understanding-bias-and-variance","title":"Understanding Bias and Variance","text":"<p>Bias: Error from overly simplistic assumptions</p> <ul> <li>High bias \u2192 Model misses relevant relations \u2192 Underfitting</li> <li>Low bias \u2192 Model captures complex patterns</li> </ul> <p>Variance: Error from sensitivity to small fluctuations in training data</p> <ul> <li>High variance \u2192 Model is too sensitive \u2192 Overfitting</li> <li>Low variance \u2192 Model is stable across datasets</li> </ul>"},{"location":"ml/module1-introduction/#mathematical-decomposition","title":"Mathematical Decomposition","text":"<p>Total Error = Bias\u00b2 + Variance + Irreducible Error</p> \\[ \\mathbb{E}[(y - \\hat{f}(x))^2] = \\text{Bias}[\\hat{f}(x)]^2 + \\text{Var}[\\hat{f}(x)] + \\sigma^2 \\] <p>Where: - \\(\\text{Bias}[\\hat{f}(x)] = \\mathbb{E}[\\hat{f}(x)] - f(x)\\) (expected prediction - true function) - \\(\\text{Var}[\\hat{f}(x)] = \\mathbb{E}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^2]\\) (variance of predictions) - \\(\\sigma^2\\) = irreducible error (noise in data)</p>"},{"location":"ml/module1-introduction/#the-tradeoff","title":"The Tradeoff","text":"Model Complexity Bias Variance Total Error Very Simple High Low High Optimal Medium Medium Lowest Very Complex Low High High <pre><code>Error\n  |\n  |  \\         Total Error\n  |   \\       /\n  |    \\     /\n  |     \\___/  \u2190 Optimal complexity\n  |    /     \\\n  |   / Bias  \\ Variance\n  |  /         \\\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    Simple \u2192 Complex\n    Model Complexity\n</code></pre> <p>Goal</p> <p>Find the sweet spot where total error is minimized - not too simple (high bias), not too complex (high variance).</p>"},{"location":"ml/module1-introduction/#training-validation-and-test-sets","title":"Training, Validation, and Test Sets","text":""},{"location":"ml/module1-introduction/#why-split-data","title":"Why Split Data?","text":"<p>Critical</p> <p>Never evaluate your model on data it was trained on! This gives an overly optimistic estimate.</p>"},{"location":"ml/module1-introduction/#standard-split","title":"Standard Split","text":"<pre><code>Full Dataset\n    \u2502\n    \u251c\u2500\u2500 Training Set (60-80%)\n    \u2502   \u2514\u2500\u2500 Used to train the model\n    \u2502\n    \u251c\u2500\u2500 Validation Set (10-20%)\n    \u2502   \u2514\u2500\u2500 Used to tune hyperparameters\n    \u2502\n    \u2514\u2500\u2500 Test Set (10-20%)\n        \u2514\u2500\u2500 Used for final evaluation (only once!)\n</code></pre>"},{"location":"ml/module1-introduction/#purpose-of-each-set","title":"Purpose of Each Set","text":"Set Purpose When Used Can Modify Model? Training Learn model parameters During training Yes Validation Tune hyperparameters, model selection During development Yes (indirectly) Test Final unbiased evaluation At the end only No"},{"location":"ml/module1-introduction/#cross-validation","title":"Cross-Validation","text":"<p>When data is limited, use k-fold cross-validation:</p> <pre><code>Fold 1: [Val][Train][Train][Train][Train]\nFold 2: [Train][Val][Train][Train][Train]\nFold 3: [Train][Train][Val][Train][Train]\nFold 4: [Train][Train][Train][Val][Train]\nFold 5: [Train][Train][Train][Train][Val]\n\nFinal Score = Average of all fold scores\n</code></pre> <p>Benefits: - Uses all data for both training and validation - More robust performance estimate - Standard: 5-fold or 10-fold CV</p> <p>Exam Tip</p> <ul> <li>Training set: Model learns from this</li> <li>Validation set: We tune hyperparameters using this</li> <li>Test set: Final evaluation, use only ONCE at the end</li> </ul>"},{"location":"ml/module1-introduction/#applications-of-machine-learning","title":"Applications of Machine Learning","text":""},{"location":"ml/module1-introduction/#by-domain","title":"By Domain","text":""},{"location":"ml/module1-introduction/#healthcare","title":"Healthcare","text":"Application Type Description Disease Diagnosis Classification Predict disease from symptoms/images Drug Discovery Regression/Classification Predict drug effectiveness Medical Imaging Classification Detect tumors, abnormalities Personalized Treatment Regression Predict optimal dosage"},{"location":"ml/module1-introduction/#finance","title":"Finance","text":"Application Type Description Fraud Detection Classification Identify fraudulent transactions Credit Scoring Classification Predict loan default risk Stock Prediction Regression Predict stock prices Algorithmic Trading Reinforcement Automated trading decisions"},{"location":"ml/module1-introduction/#e-commerce","title":"E-commerce","text":"Application Type Description Recommendation Systems Classification Suggest products Price Optimization Regression Dynamic pricing Customer Segmentation Clustering Group customers Churn Prediction Classification Predict customer leaving"},{"location":"ml/module1-introduction/#technology","title":"Technology","text":"Application Type Description Search Engines Ranking Order search results Speech Recognition Classification Convert speech to text Image Recognition Classification Identify objects NLP Various Language understanding"},{"location":"ml/module1-introduction/#key-formulas-and-concepts","title":"Key Formulas and Concepts","text":""},{"location":"ml/module1-introduction/#quick-reference","title":"Quick Reference","text":"Concept Formula/Definition Min-Max Scaling \\(x' = \\frac{x - x_{min}}{x_{max} - x_{min}}\\) Standardization \\(x' = \\frac{x - \\mu}{\\sigma}\\) Total Error Bias\u00b2 + Variance + Noise Overfitting Low train error, High test error Underfitting High train error, High test error"},{"location":"ml/module1-introduction/#common-exam-questions","title":"Common Exam Questions","text":"<p>Q1: Differentiate between supervised and unsupervised learning</p> <p>Supervised: Uses labeled data, learns input-output mapping, used for classification/regression.</p> <p>Unsupervised: Uses unlabeled data, finds hidden patterns, used for clustering/dimensionality reduction.</p> <p>Q2: What is overfitting? How to prevent it?</p> <p>Overfitting: Model memorizes training data, performs poorly on new data.</p> <p>Prevention: Regularization, cross-validation, more data, simpler model, early stopping, dropout.</p> <p>Q3: Explain bias-variance tradeoff</p> <ul> <li>Bias: Error from simplistic assumptions (underfitting)</li> <li>Variance: Error from sensitivity to training data (overfitting)</li> <li>Tradeoff: Reducing one often increases the other</li> <li>Goal: Find optimal model complexity minimizing total error</li> </ul> <p>Q4: Why split data into train/validation/test?</p> <ul> <li>Training: Model learns parameters</li> <li>Validation: Tune hyperparameters, prevent overfitting</li> <li>Test: Final unbiased evaluation</li> <li>Prevents overfitting to test data, gives realistic performance estimate</li> </ul>"},{"location":"ml/module1-introduction/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 Machine Learning: Systems that learn from data without explicit programming</p> <p>\u2705 Supervised Learning: Learn from labeled data (classification/regression)</p> <p>\u2705 Unsupervised Learning: Find patterns in unlabeled data (clustering/dimensionality reduction)</p> <p>\u2705 Reinforcement Learning: Learn through rewards and penalties</p> <p>\u2705 Overfitting: Model too complex, memorizes training data</p> <p>\u2705 Underfitting: Model too simple, can't learn patterns</p> <p>\u2705 Bias-Variance Tradeoff: Balance between model complexity and generalization</p> <p>\u2705 Data Splitting: Train (learn) \u2192 Validation (tune) \u2192 Test (evaluate)</p> <p>\u2705 Feature Scaling: Normalize features for better algorithm performance</p> <p>\u2705 Cross-Validation: Robust performance estimation using multiple folds</p> <p>Next: Module 2 - Supervised Learning</p>"},{"location":"ml/module2-supervised-learning/","title":"Module 2: Supervised Learning","text":""},{"location":"ml/module2-supervised-learning/#overview","title":"Overview","text":"<p>Supervised learning uses labeled training data to learn a function that maps inputs to outputs. This module covers two fundamental algorithms: Linear Regression and Logistic Regression.</p>"},{"location":"ml/module2-supervised-learning/#linear-regression","title":"Linear Regression","text":""},{"location":"ml/module2-supervised-learning/#introduction","title":"Introduction","text":"<p>Linear Regression is used to predict continuous numerical values. It assumes a linear relationship between input features and the target variable.</p>"},{"location":"ml/module2-supervised-learning/#simple-linear-regression","title":"Simple Linear Regression","text":"<p>Model: \\(y = \\theta_0 + \\theta_1 x\\)</p> <p>Where: - \\(y\\) = predicted output (dependent variable) - \\(x\\) = input feature (independent variable) - \\(\\theta_0\\) = y-intercept (bias term) - \\(\\theta_1\\) = slope (weight)</p>"},{"location":"ml/module2-supervised-learning/#multiple-linear-regression","title":"Multiple Linear Regression","text":"<p>Model: \\(y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\ldots + \\theta_n x_n\\)</p> <p>Vectorized Form: \\(y = \\mathbf{\\theta}^T \\mathbf{x}\\)</p> <p>Where: - \\(\\mathbf{\\theta} = [\\theta_0, \\theta_1, \\theta_2, \\ldots, \\theta_n]^T\\) (parameters) - \\(\\mathbf{x} = [1, x_1, x_2, \\ldots, x_n]^T\\) (features with bias term)</p>"},{"location":"ml/module2-supervised-learning/#cost-function-mean-squared-error","title":"Cost Function (Mean Squared Error)","text":"<p>The cost function measures how far off our predictions are from actual values.</p> <p>For m training examples:</p> \\[ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2 \\] <p>Where: - \\(h_\\theta(x^{(i)}) = \\theta^T x^{(i)}\\) (prediction for example i) - \\(y^{(i)}\\) = actual value for example i - \\(m\\) = number of training examples</p> <p>Why \\(\\frac{1}{2}\\)?: Makes derivative cleaner (the 2 cancels out)</p> <p>Important</p> <p>The factor of \\(\\frac{1}{2}\\) doesn't change the optimal solution, but simplifies the gradient calculation.</p> <p>Exam Tip</p> <p>Always show the cost function formula clearly. The \\(\\frac{1}{2m}\\) factor is standard in many textbooks.</p>"},{"location":"ml/module2-supervised-learning/#gradient-descent-algorithm","title":"Gradient Descent Algorithm","text":"<p>Gradient descent minimizes the cost function by iteratively updating parameters.</p> <p>Algorithm: 1. Initialize parameters \\(\\theta\\) (usually to zeros or small random values) 2. Repeat until convergence:    - Update all parameters simultaneously:</p> <p>$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} $$</p> <p>Update Rule:</p> \\[ \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} \\] <p>For \\(\\theta_0\\) (bias term): $$ \\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) $$</p> <p>For \\(\\theta_j\\) (j &gt; 0): $$ \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} $$</p> <p>Parameters: - \\(\\alpha\\) (alpha) = learning rate (step size)   - Too small: Slow convergence   - Too large: May overshoot minimum, may not converge - Number of iterations</p> <p>Vectorized Update:</p> \\[ \\theta := \\theta - \\alpha \\frac{1}{m} X^T (X\\theta - y) \\]"},{"location":"ml/module2-supervised-learning/#learning-rate-selection","title":"Learning Rate Selection","text":"<p>Good Learning Rate: - Cost decreases smoothly - Reaches minimum efficiently</p> <p>Too Small: - Very slow convergence - May take many iterations</p> <p>Too Large: - Cost may increase - May overshoot minimum - May diverge (fail to converge)</p> <p>Critical</p> <p>If your cost function is increasing during gradient descent, your learning rate is too large! Reduce \\(\\alpha\\) immediately.</p> <p>Best Practice</p> <p>Start with a small learning rate (e.g., 0.01) and gradually increase if convergence is too slow. Use learning rate scheduling for better results.</p> <p>Rule of Thumb: Try values like 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0</p>"},{"location":"ml/module2-supervised-learning/#normal-equation-alternative-to-gradient-descent","title":"Normal Equation (Alternative to Gradient Descent)","text":"<p>Closed-form solution (no iteration needed):</p> \\[ \\theta = (X^T X)^{-1} X^T y \\] <p>When to use: - \u2705 Small number of features (&lt; 1000) - \u2705 Fast for small datasets - \u274c Slow for large datasets (matrix inversion is O(n\u00b3)) - \u274c Doesn't work if \\(X^T X\\) is not invertible</p> <p>Advantages of Gradient Descent: - Works well with large datasets - More flexible (can use with other algorithms)</p>"},{"location":"ml/module2-supervised-learning/#logistic-regression","title":"Logistic Regression","text":""},{"location":"ml/module2-supervised-learning/#introduction_1","title":"Introduction","text":"<p>Logistic Regression is used for binary classification (two classes: 0 and 1). Despite the name \"regression,\" it's a classification algorithm.</p>"},{"location":"ml/module2-supervised-learning/#hypothesis-function","title":"Hypothesis Function","text":"<p>Sigmoid Function (also called Logistic Function):</p> \\[ h_\\theta(x) = g(\\theta^T x) = \\frac{1}{1 + e^{-\\theta^T x}} \\] <p>Where \\(g(z) = \\frac{1}{1 + e^{-z}}\\) is the sigmoid function.</p> <p>Properties of Sigmoid: - Output range: (0, 1) - \\(g(0) = 0.5\\) - As \\(z \\to +\\infty\\), \\(g(z) \\to 1\\) - As \\(z \\to -\\infty\\), \\(g(z) \\to 0\\) - S-shaped curve</p> <p>Interpretation: - \\(h_\\theta(x)\\) = probability that \\(y = 1\\) given \\(x\\) - \\(P(y = 1 | x; \\theta) = h_\\theta(x)\\) - \\(P(y = 0 | x; \\theta) = 1 - h_\\theta(x)\\)</p>"},{"location":"ml/module2-supervised-learning/#decision-boundary","title":"Decision Boundary","text":"<p>Classification Rule: - If \\(h_\\theta(x) \\geq 0.5\\), predict \\(y = 1\\) - If \\(h_\\theta(x) &lt; 0.5\\), predict \\(y = 0\\)</p> <p>Since \\(g(z) \\geq 0.5\\) when \\(z \\geq 0\\): - Predict \\(y = 1\\) if \\(\\theta^T x \\geq 0\\) - Predict \\(y = 0\\) if \\(\\theta^T x &lt; 0\\)</p> <p>Decision Boundary: The line (or curve) where \\(\\theta^T x = 0\\)</p>"},{"location":"ml/module2-supervised-learning/#cost-function","title":"Cost Function","text":"<p>Why not use MSE? - MSE would give non-convex cost function - Many local minima - Gradient descent may not find global minimum</p> <p>Logistic Regression Cost Function:</p> \\[ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))] \\] <p>For single training example: $\\(Cost(h_\\theta(x), y) = \\begin{cases} -\\log(h_\\theta(x)) &amp; \\text{if } y = 1 \\\\ -\\log(1 - h_\\theta(x)) &amp; \\text{if } y = 0 \\end{cases}\\)$</p> <p>Intuition: - If \\(y = 1\\): Cost is large when \\(h_\\theta(x) \\to 0\\), cost is 0 when \\(h_\\theta(x) \\to 1\\) - If \\(y = 0\\): Cost is large when \\(h_\\theta(x) \\to 1\\), cost is 0 when \\(h_\\theta(x) \\to 0\\)</p>"},{"location":"ml/module2-supervised-learning/#gradient-descent-for-logistic-regression","title":"Gradient Descent for Logistic Regression","text":"<p>Update Rule (same form as linear regression!):</p> \\[ \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} \\] <p>Vectorized: $$ \\theta := \\theta - \\alpha \\frac{1}{m} X^T (g(X\\theta) - y) $$</p> <p>Where \\(g\\) is the sigmoid function applied element-wise.</p>"},{"location":"ml/module2-supervised-learning/#multiclass-classification-one-vs-all","title":"Multiclass Classification (One-vs-All)","text":"<p>Approach: 1. Train \\(K\\) separate logistic regression classifiers 2. For each class \\(k\\), treat it as positive class and all others as negative 3. For prediction, choose class with highest \\(h_\\theta^{(k)}(x)\\)</p> <p>Algorithm: - For each class \\(k = 1, 2, \\ldots, K\\):   - Train classifier \\(h_\\theta^{(k)}(x)\\) to predict \\(y = k\\) vs \\(y \\neq k\\) - To predict new example:   - Compute \\(h_\\theta^{(k)}(x)\\) for all \\(k\\)   - Choose class with maximum value</p>"},{"location":"ml/module2-supervised-learning/#regularization","title":"Regularization","text":""},{"location":"ml/module2-supervised-learning/#problem-of-overfitting","title":"Problem of Overfitting","text":"<p>Overfitting: Model fits training data too well but doesn't generalize to new data.</p> <p>Solutions: 1. Reduce number of features 2. Regularization (keep all features but reduce magnitude)</p>"},{"location":"ml/module2-supervised-learning/#regularized-cost-function","title":"Regularized Cost Function","text":"<p>Linear Regression with Regularization:</p> \\[ J(\\theta) = \\frac{1}{2m} \\left[ \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^{n} \\theta_j^2 \\right] \\] <p>Logistic Regression with Regularization:</p> \\[ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\theta_j^2 \\] <p>Note: Don't regularize \\(\\theta_0\\) (bias term)</p>"},{"location":"ml/module2-supervised-learning/#regularized-gradient-descent","title":"Regularized Gradient Descent","text":"<p>For \\(j = 0\\) (bias term, no regularization): $$ \\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) $$</p> <p>For \\(j \\geq 1\\) (with regularization): $$ \\theta_j := \\theta_j - \\alpha \\left[ \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} + \\frac{\\lambda}{m} \\theta_j \\right] $$</p> <p>Can be rewritten as: $$ \\theta_j := \\theta_j \\left(1 - \\alpha \\frac{\\lambda}{m}\\right) - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} $$</p> <p>Regularization Parameter \\(\\lambda\\): - Large \\(\\lambda\\): Strong regularization, simpler model (may underfit) - Small \\(\\lambda\\): Weak regularization, complex model (may overfit) - \\(\\lambda = 0\\): No regularization</p>"},{"location":"ml/module2-supervised-learning/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"ml/module2-supervised-learning/#linear-regression_1","title":"Linear Regression","text":"<ul> <li>Hypothesis: \\(h_\\theta(x) = \\theta^T x\\)</li> <li>Cost: \\(J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2\\)</li> <li>Gradient: \\(\\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)}\\)</li> </ul>"},{"location":"ml/module2-supervised-learning/#logistic-regression_1","title":"Logistic Regression","text":"<ul> <li>Hypothesis: \\(h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}\\)</li> <li>Cost: \\(J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))]\\)</li> <li>Gradient: Same form as linear regression!</li> </ul>"},{"location":"ml/module2-supervised-learning/#regularization_1","title":"Regularization","text":"<ul> <li>Regularized Cost: Add \\(\\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\theta_j^2\\)</li> <li>Regularized Update: Add \\(\\frac{\\lambda}{m} \\theta_j\\) to gradient</li> </ul>"},{"location":"ml/module2-supervised-learning/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 Linear Regression: Predicts continuous values, uses MSE cost function</p> <p>\u2705 Logistic Regression: Binary classification, uses sigmoid function, cross-entropy cost</p> <p>\u2705 Gradient Descent: Iterative optimization, requires learning rate</p> <p>\u2705 Regularization: Prevents overfitting by penalizing large parameters</p> <p>\u2705 Feature Scaling: Important for gradient descent convergence</p> <p>\u2705 Bias Term: \\(\\theta_0\\) is usually not regularized</p>"},{"location":"ml/module2-supervised-learning/#worked-examples-exam-style","title":"Worked Examples (Exam-Style)","text":""},{"location":"ml/module2-supervised-learning/#worked-example-1-one-step-of-gradient-descent-linear-regression","title":"Worked Example 1: One step of Gradient Descent (Linear Regression)","text":"<p>Given: two points \\((x,y) = (1,2), (2,4)\\), hypothesis \\(h_\\theta(x)=\\theta_0+\\theta_1x\\), start \\(\\theta_0=0,\\ \\theta_1=0\\), learning rate \\(\\alpha=0.1\\), \\(m=2\\).</p> <p>1) Predictions: - \\(h(1)=0\\) - \\(h(2)=0\\)</p> <p>2) Errors: - \\(e^{(1)}=h(1)-2=-2\\) - \\(e^{(2)}=h(2)-4=-4\\)</p> <p>3) Update \\(\\theta_0\\):</p> \\[ \\theta_0 := \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m} e^{(i)}         = 0 - 0.1\\cdot\\frac{1}{2}(-2-4)         = 0.3 \\] <p>4) Update \\(\\theta_1\\):</p> \\[ \\theta_1 := \\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m} e^{(i)}x^{(i)}         = 0 - 0.1\\cdot\\frac{1}{2}\\left[(-2)\\cdot1 + (-4)\\cdot2\\right]         = 0.5 \\] <p>\u2705 After 1 step: \\(\\theta_0=0.3,\\ \\theta_1=0.5\\)</p> <p>Exam Tip</p> <p>In exams, always show prediction \u2192 error \u2192 substitute into update rule. That\u2019s usually full marks.</p>"},{"location":"ml/module2-supervised-learning/#worked-example-2-logistic-regression-prediction-class","title":"Worked Example 2: Logistic Regression Prediction + Class","text":"<p>Given: \\(\\theta=[-2, 1, 1]^T\\), input \\(x=[1,2,1]^T\\) (bias included).</p> <p>1) Compute:</p> \\[ z=\\theta^Tx=-2 + 1\\cdot2 + 1\\cdot1 = 1 \\] <p>2) Probability:</p> \\[ h_\\theta(x)=\\sigma(z)=\\frac{1}{1+e^{-1}}\\approx 0.731 \\] <p>3) Class (threshold 0.5): since \\(0.731\\ge 0.5\\) \u21d2 predict 1.</p>"},{"location":"ml/module2-supervised-learning/#common-exam-questions-what-to-write","title":"Common Exam Questions (What to Write)","text":"<ul> <li>\u201cDerive gradient descent update\u201d:</li> <li>Write \\(J(\\theta)\\)</li> <li>Take partial derivative \\(\\frac{\\partial J}{\\partial \\theta_j}\\)</li> <li>Plug into \\(\\theta_j := \\theta_j - \\alpha \\frac{\\partial J}{\\partial \\theta_j}\\)</li> <li>\u201cWhy MSE not used for logistic regression?\u201d:</li> <li>MSE makes cost non-convex with sigmoid \u21d2 local minima</li> <li>Cross-entropy is convex \u21d2 gradient descent works reliably</li> <li>\u201cExplain regularization\u201d:</li> <li>Add \\(\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_j^2\\) (exclude \\(\\theta_0\\))</li> <li>Large \\(\\lambda\\) \u21d2 underfit; small \\(\\lambda\\) \u21d2 risk overfit</li> </ul>"},{"location":"ml/module2-supervised-learning/#quick-revision-checklist-2-minutes","title":"Quick Revision Checklist (2 minutes)","text":"<ul> <li>Can you write MSE and cross-entropy correctly?</li> <li>Can you write gradient descent update (scalar + vectorized)?</li> <li>Can you explain decision boundary (\\(\\theta^Tx=0\\))?</li> <li>Do you remember don\u2019t regularize \\(\\theta_0\\)?</li> <li>Do you know what happens when \\(\\alpha\\) is too large/small?</li> </ul> <p>Previous: Module 1 - Introduction | Next: Module 3 - Classification &amp; Evaluation</p>"},{"location":"ml/module3-classification-evaluation/","title":"Module 3: Classification &amp; Evaluation Metrics","text":""},{"location":"ml/module3-classification-evaluation/#overview","title":"Overview","text":"<p>This module covers classification algorithms and how to evaluate their performance using various metrics.</p>"},{"location":"ml/module3-classification-evaluation/#classification-algorithms","title":"Classification Algorithms","text":""},{"location":"ml/module3-classification-evaluation/#1-logistic-regression-review","title":"1. Logistic Regression (Review)","text":"<ul> <li>Binary classification using sigmoid function</li> <li>Outputs probability of class membership</li> <li>Decision boundary: \\(\\theta^T x = 0\\)</li> </ul>"},{"location":"ml/module3-classification-evaluation/#2-k-nearest-neighbors-knn","title":"2. K-Nearest Neighbors (KNN)","text":"<p>Algorithm: 1. Choose parameter \\(K\\) (number of neighbors) 2. For new data point:    - Find \\(K\\) nearest training examples    - Classify based on majority vote of neighbors</p> <p>Distance Metrics: - Euclidean: \\(d = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\\) - Manhattan: \\(d = \\sum_{i=1}^{n} |x_i - y_i|\\)</p> <p>Choosing K: - Small K: More sensitive to noise, complex boundaries - Large K: Smoother boundaries, may underfit - Rule of thumb: \\(K = \\sqrt{n}\\) where \\(n\\) is number of samples</p>"},{"location":"ml/module3-classification-evaluation/#3-support-vector-machines-svm","title":"3. Support Vector Machines (SVM)","text":"<p>Goal: Find optimal hyperplane that separates classes with maximum margin</p> <p>Key Concepts: - Support Vectors: Data points closest to decision boundary - Margin: Distance between decision boundary and nearest points - Kernel Trick: Transform data to higher dimensions for non-linear separation</p>"},{"location":"ml/module3-classification-evaluation/#confusion-matrix","title":"Confusion Matrix","text":"<p>A confusion matrix is a table used to evaluate classification performance.</p>"},{"location":"ml/module3-classification-evaluation/#binary-classification-confusion-matrix","title":"Binary Classification Confusion Matrix","text":"<pre><code>                    Predicted\n                 Positive  Negative\nActual Positive    TP       FN\n       Negative    FP       TN\n</code></pre> <p>Terminology: - TP (True Positive): Correctly predicted positive - TN (True Negative): Correctly predicted negative - FP (False Positive): Incorrectly predicted positive (Type I error) - FN (False Negative): Incorrectly predicted negative (Type II error)</p>"},{"location":"ml/module3-classification-evaluation/#multi-class-confusion-matrix","title":"Multi-class Confusion Matrix","text":"<p>For \\(n\\) classes, it's an \\(n \\times n\\) matrix where: - Rows = Actual classes - Columns = Predicted classes - Diagonal elements = Correct predictions - Off-diagonal elements = Misclassifications</p>"},{"location":"ml/module3-classification-evaluation/#evaluation-metrics","title":"Evaluation Metrics","text":""},{"location":"ml/module3-classification-evaluation/#1-accuracy","title":"1. Accuracy","text":"<p>Definition: Proportion of correct predictions</p> <p>Formula: $$ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{\\text{Correct Predictions}}{\\text{Total Predictions}} $$</p> <p>Range: [0, 1] or [0%, 100%]</p> <p>When to Use: - \u2705 Balanced classes - \u2705 Equal cost for all errors - \u274c Not good for imbalanced datasets</p> <p>Limitation: Can be misleading with imbalanced data - Example: 95% accuracy with 95% negative class \u2192 Always predicting negative gives 95% accuracy!</p>"},{"location":"ml/module3-classification-evaluation/#2-precision","title":"2. Precision","text":"<p>Definition: Of all positive predictions, how many were actually positive?</p> <p>Formula: $$ \\text{Precision} = \\frac{TP}{TP + FP} = \\frac{\\text{True Positives}}{\\text{All Predicted Positives}} $$</p> <p>Interpretation:  - High precision = Low false positive rate - \"When we predict positive, how often are we right?\"</p> <p>Use Cases: - Spam detection (minimize false positives - don't want to mark important emails as spam) - Medical diagnosis (minimize false alarms)</p>"},{"location":"ml/module3-classification-evaluation/#3-recall-sensitivity","title":"3. Recall (Sensitivity)","text":"<p>Definition: Of all actual positives, how many did we correctly identify?</p> <p>Formula: $$ \\text{Recall} = \\frac{TP}{TP + FN} = \\frac{\\text{True Positives}}{\\text{All Actual Positives}} $$</p> <p>Also called: - Sensitivity - True Positive Rate (TPR)</p> <p>Interpretation: - High recall = Low false negative rate - \"Of all actual positives, how many did we catch?\"</p> <p>Use Cases: - Disease detection (don't want to miss actual cases) - Fraud detection (don't want to miss fraudulent transactions)</p>"},{"location":"ml/module3-classification-evaluation/#4-specificity","title":"4. Specificity","text":"<p>Definition: Of all actual negatives, how many did we correctly identify?</p> <p>Formula: $$ \\text{Specificity} = \\frac{TN}{TN + FP} = \\frac{\\text{True Negatives}}{\\text{All Actual Negatives}} $$</p> <p>Also called: True Negative Rate (TNR)</p> <p>Interpretation: Ability to correctly identify negative cases</p>"},{"location":"ml/module3-classification-evaluation/#5-f1-score","title":"5. F1-Score","text":"<p>Definition: Harmonic mean of Precision and Recall</p> <p>Formula: $$ \\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} = \\frac{2TP}{2TP + FP + FN} $$</p> <p>Range: [0, 1]</p> <p>Why Harmonic Mean? - Penalizes extreme values - Better than arithmetic mean when one metric is very low</p> <p>When to Use: - \u2705 Need balance between precision and recall - \u2705 Imbalanced datasets - \u2705 Single metric to optimize</p>"},{"location":"ml/module3-classification-evaluation/#6-f-score","title":"6. F\u03b2-Score","text":"<p>Generalized F-Score:</p> \\[ \\text{F}_\\beta = (1 + \\beta^2) \\times \\frac{\\text{Precision} \\times \\text{Recall}}{(\\beta^2 \\times \\text{Precision}) + \\text{Recall}} \\] <p>Common Values: - \\(\\beta = 1\\): F1-Score (equal weight) - \\(\\beta = 2\\): F2-Score (more weight to recall) - \\(\\beta = 0.5\\): F0.5-Score (more weight to precision)</p>"},{"location":"ml/module3-classification-evaluation/#7-error-rate","title":"7. Error Rate","text":"<p>Formula: $$ \\text{Error Rate} = \\frac{FP + FN}{TP + TN + FP + FN} = 1 - \\text{Accuracy} $$</p>"},{"location":"ml/module3-classification-evaluation/#roc-curve-and-auc","title":"ROC Curve and AUC","text":""},{"location":"ml/module3-classification-evaluation/#roc-curve-receiver-operating-characteristic","title":"ROC Curve (Receiver Operating Characteristic)","text":"<p>Definition: Plot of True Positive Rate (TPR) vs False Positive Rate (FPR) at different classification thresholds.</p> <p>Axes: - X-axis: False Positive Rate (FPR) = \\(\\frac{FP}{FP + TN}\\) - Y-axis: True Positive Rate (TPR) = Recall = \\(\\frac{TP}{TP + FN}\\)</p> <p>How it works: 1. Vary classification threshold from 0 to 1 2. For each threshold, calculate TPR and FPR 3. Plot points and connect to form curve</p> <p>Interpretation: - Top-left corner (0, 1): Perfect classifier   - TPR = 1, FPR = 0 - Diagonal line: Random classifier (no better than guessing) - Above diagonal: Better than random - Below diagonal: Worse than random</p> <p>Key Points: - (0, 0): Threshold = 1, predict all negative - (1, 1): Threshold = 0, predict all positive</p>"},{"location":"ml/module3-classification-evaluation/#auc-area-under-the-curve","title":"AUC (Area Under the Curve)","text":"<p>Definition: Area under the ROC curve</p> <p>Range: [0, 1]</p> <p>Interpretation: - AUC = 1.0: Perfect classifier - AUC = 0.5: Random classifier (diagonal line) - AUC &gt; 0.5: Better than random - AUC &lt; 0.5: Worse than random (flip predictions!)</p> <p>Meaning:  - Probability that classifier ranks a random positive example higher than a random negative example - Higher AUC = Better classifier at distinguishing classes</p> <p>Advantages: - \u2705 Threshold-independent - \u2705 Works well with imbalanced data - \u2705 Single number summary</p> <p>When to Use: - Binary classification - Need threshold-independent metric - Comparing different models</p>"},{"location":"ml/module3-classification-evaluation/#precision-recall-curve","title":"Precision-Recall Curve","text":"<p>Definition: Plot of Precision vs Recall at different thresholds</p> <p>When to Use Instead of ROC: - \u2705 Highly imbalanced datasets - \u2705 More informative when positive class is rare - \u2705 Focus on positive class performance</p> <p>AUC-PR: Area under Precision-Recall curve - Higher is better - More sensitive to class imbalance than ROC-AUC</p>"},{"location":"ml/module3-classification-evaluation/#multi-class-classification-metrics","title":"Multi-class Classification Metrics","text":""},{"location":"ml/module3-classification-evaluation/#macro-averaging","title":"Macro-Averaging","text":"<p>Calculate metric for each class, then average:</p> \\[ \\text{Macro-Precision} = \\frac{1}{C} \\sum_{i=1}^{C} \\text{Precision}_i \\] \\[ \\text{Macro-Recall} = \\frac{1}{C} \\sum_{i=1}^{C} \\text{Recall}_i \\] <p>Treats all classes equally</p>"},{"location":"ml/module3-classification-evaluation/#micro-averaging","title":"Micro-Averaging","text":"<p>Aggregate all TP, FP, FN across classes, then calculate:</p> \\[ \\text{Micro-Precision} = \\frac{\\sum_{i=1}^{C} TP_i}{\\sum_{i=1}^{C} (TP_i + FP_i)} \\] <p>Gives equal weight to each sample (not each class)</p>"},{"location":"ml/module3-classification-evaluation/#weighted-averaging","title":"Weighted-Averaging","text":"<p>Weight by number of samples in each class:</p> \\[ \\text{Weighted-Precision} = \\sum_{i=1}^{C} w_i \\times \\text{Precision}_i \\] <p>where \\(w_i = \\frac{n_i}{N}\\) (proportion of class \\(i\\))</p>"},{"location":"ml/module3-classification-evaluation/#choosing-the-right-metric","title":"Choosing the Right Metric","text":""},{"location":"ml/module3-classification-evaluation/#when-to-use-each-metric","title":"When to Use Each Metric","text":"Metric Best For Example Use Case Accuracy Balanced classes, equal error costs General classification Precision Minimize false positives Spam detection, medical screening Recall Minimize false negatives Disease diagnosis, fraud detection F1-Score Balance precision and recall General binary classification AUC-ROC Threshold-independent, imbalanced data Model comparison, binary classification AUC-PR Highly imbalanced data Rare event detection"},{"location":"ml/module3-classification-evaluation/#decision-framework","title":"Decision Framework","text":"<ol> <li>Is the dataset balanced?</li> <li>Balanced \u2192 Accuracy, F1-Score</li> <li> <p>Imbalanced \u2192 Precision, Recall, F1-Score, AUC</p> </li> <li> <p>What's the cost of errors?</p> </li> <li>False positives expensive \u2192 Optimize Precision</li> <li>False negatives expensive \u2192 Optimize Recall</li> <li> <p>Both important \u2192 Optimize F1-Score</p> </li> <li> <p>Do you need threshold-independent metric?</p> </li> <li>Yes \u2192 AUC-ROC or AUC-PR</li> <li>No \u2192 Precision, Recall, F1-Score</li> </ol>"},{"location":"ml/module3-classification-evaluation/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"ml/module3-classification-evaluation/#binary-classification-metrics","title":"Binary Classification Metrics","text":"<ul> <li>Accuracy: \\(\\frac{TP + TN}{TP + TN + FP + FN}\\)</li> <li>Precision: \\(\\frac{TP}{TP + FP}\\)</li> <li>Recall: \\(\\frac{TP}{TP + FN}\\)</li> <li>Specificity: \\(\\frac{TN}{TN + FP}\\)</li> <li>F1-Score: \\(\\frac{2TP}{2TP + FP + FN}\\)</li> <li>FPR: \\(\\frac{FP}{FP + TN}\\)</li> <li>FNR: \\(\\frac{FN}{FN + TP}\\)</li> </ul>"},{"location":"ml/module3-classification-evaluation/#roc-curve","title":"ROC Curve","text":"<ul> <li>TPR (Y-axis): \\(\\frac{TP}{TP + FN}\\) = Recall</li> <li>FPR (X-axis): \\(\\frac{FP}{FP + TN}\\)</li> </ul>"},{"location":"ml/module3-classification-evaluation/#worked-examples-exam-style","title":"Worked Examples (Exam-Style)","text":""},{"location":"ml/module3-classification-evaluation/#worked-example-1-metrics-from-confusion-matrix","title":"Worked Example 1: Metrics from Confusion Matrix","text":"<p>Given: - \\(TP=50,\\ FP=10,\\ FN=5,\\ TN=35\\)</p> <p>1) Accuracy:</p> \\[ \\text{Accuracy}=\\frac{TP+TN}{TP+TN+FP+FN}=\\frac{50+35}{50+35+10+5}=\\frac{85}{100}=0.85 \\] <p>2) Precision:</p> \\[ \\text{Precision}=\\frac{TP}{TP+FP}=\\frac{50}{50+10}=\\frac{50}{60}=0.833 \\] <p>3) Recall:</p> \\[ \\text{Recall}=\\frac{TP}{TP+FN}=\\frac{50}{50+5}=\\frac{50}{55}=0.909 \\] <p>4) F1:</p> \\[ F1=2\\cdot\\frac{PR}{P+R} =2\\cdot\\frac{0.833\\cdot0.909}{0.833+0.909} \\approx 0.869 \\] <p>How to score full marks</p> <p>Write the formula first, then substitute numbers, then final value (with 3 decimals).</p>"},{"location":"ml/module3-classification-evaluation/#worked-example-2-roc-point-at-a-threshold","title":"Worked Example 2: ROC Point at a Threshold","text":"<p>If a classifier at threshold \\(t\\) gives \\(TP=40,\\ FN=10,\\ FP=20,\\ TN=30\\):</p> \\[ TPR=\\frac{TP}{TP+FN}=\\frac{40}{50}=0.8 \\] \\[ FPR=\\frac{FP}{FP+TN}=\\frac{20}{50}=0.4 \\] <p>So ROC has a point (0.4, 0.8).</p>"},{"location":"ml/module3-classification-evaluation/#common-pitfalls","title":"Common Pitfalls","text":"<ul> <li>Using Accuracy on imbalanced data: can look \u201chigh\u201d even for a useless model.</li> <li>Mixing up Precision and Recall:</li> <li>Precision cares about FP</li> <li>Recall cares about FN</li> <li>Forgetting class meaning: always state which class is \u201cpositive\u201d.</li> </ul>"},{"location":"ml/module3-classification-evaluation/#quick-revision-checklist-2-minutes","title":"Quick Revision Checklist (2 minutes)","text":"<ul> <li>Can you draw confusion matrix and label TP/FP/FN/TN?</li> <li>Do you remember all metric formulas?</li> <li>Can you explain when to use F1 vs ROC-AUC vs PR-AUC?</li> <li>Can you compute one ROC point from counts?</li> </ul>"},{"location":"ml/module3-classification-evaluation/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 Confusion Matrix: Foundation for all classification metrics</p> <p>\u2705 Precision: \"Of predictions, how many correct?\" \u2192 Minimize false positives</p> <p>\u2705 Recall: \"Of actual positives, how many found?\" \u2192 Minimize false negatives</p> <p>\u2705 F1-Score: Harmonic mean, balances precision and recall</p> <p>\u2705 ROC-AUC: Threshold-independent, good for imbalanced data</p> <p>\u2705 Choose metric based on: Class balance, error costs, use case</p> <p>Previous: Module 2 - Supervised Learning | Next: Module 4 - Unsupervised Learning</p>"},{"location":"ml/module4-unsupervised-learning/","title":"Module 4: Unsupervised Learning","text":""},{"location":"ml/module4-unsupervised-learning/#overview","title":"Overview","text":"<p>Unsupervised learning finds hidden patterns in data without labeled outputs. This module covers clustering algorithms (K-Means, Hierarchical), dimensionality reduction (PCA), and association rules.</p> <p>Key Difference from Supervised Learning</p> <ul> <li>Supervised: \"Here's the input and the correct answer, learn the pattern\"</li> <li>Unsupervised: \"Here's the data, find interesting patterns on your own\"</li> </ul>"},{"location":"ml/module4-unsupervised-learning/#clustering","title":"Clustering","text":""},{"location":"ml/module4-unsupervised-learning/#what-is-clustering","title":"What is Clustering?","text":"<p>Clustering groups similar data points together based on their features. The goal is to find natural groupings in data.</p> <p>Definition</p> <p>Clustering partitions a dataset into groups (clusters) such that:</p> <ul> <li>Points within a cluster are similar to each other</li> <li>Points across clusters are dissimilar</li> </ul>"},{"location":"ml/module4-unsupervised-learning/#applications-of-clustering","title":"Applications of Clustering","text":"Domain Application Description Marketing Customer Segmentation Group customers by behavior for targeted campaigns Biology Gene Expression Group genes with similar expression patterns Image Processing Image Segmentation Separate foreground from background Security Anomaly Detection Identify unusual patterns (fraud, intrusion) Social Media Community Detection Find groups of related users"},{"location":"ml/module4-unsupervised-learning/#key-concepts","title":"Key Concepts","text":"Term Definition Cluster Group of similar data points Centroid Center point of a cluster (mean of all points) Distance Metric How we measure similarity between points Inertia Sum of squared distances from points to their centroids"},{"location":"ml/module4-unsupervised-learning/#k-means-clustering","title":"K-Means Clustering","text":""},{"location":"ml/module4-unsupervised-learning/#algorithm-overview","title":"Algorithm Overview","text":"<p>K-Means partitions data into K clusters by minimizing the within-cluster variance.</p> <p>Key Idea</p> <p>Iteratively assign points to nearest centroid, then update centroids to be the mean of assigned points.</p>"},{"location":"ml/module4-unsupervised-learning/#algorithm-steps-detailed","title":"Algorithm Steps (Detailed)","text":"<pre><code>K-Means Algorithm:\n\nInput: Dataset X, number of clusters K\nOutput: K clusters with centroids\n\n1. INITIALIZE: Randomly select K data points as initial centroids\n   \u03bc\u2081, \u03bc\u2082, ..., \u03bc\u2096\n\n2. REPEAT until convergence:\n\n   a. ASSIGNMENT STEP:\n      For each data point x\u1d62:\n        - Calculate distance to all K centroids\n        - Assign x\u1d62 to cluster with nearest centroid\n        - c\u1d62 = argmin_k ||x\u1d62 - \u03bc\u2096||\u00b2\n\n   b. UPDATE STEP:\n      For each cluster k:\n        - Recalculate centroid as mean of all assigned points\n        - \u03bc\u2096 = (1/|C\u2096|) \u03a3 x\u1d62 for all x\u1d62 in cluster k\n\n3. CONVERGENCE: Stop when centroids don't change (or change &lt; threshold)\n\n4. RETURN: Cluster assignments and final centroids\n</code></pre>"},{"location":"ml/module4-unsupervised-learning/#mathematical-formulation","title":"Mathematical Formulation","text":"<p>Objective Function (Within-cluster sum of squares - WCSS):</p> \\[ J = \\sum_{i=1}^{m} \\sum_{k=1}^{K} w_{ik} ||x^{(i)} - \\mu_k||^2 \\] <p>Where: - \\(m\\) = number of data points - \\(K\\) = number of clusters - \\(w_{ik} = 1\\) if point \\(i\\) belongs to cluster \\(k\\), else \\(0\\) - \\(\\mu_k\\) = centroid of cluster \\(k\\) - \\(||x^{(i)} - \\mu_k||^2\\) = squared Euclidean distance</p> <p>Goal: Minimize \\(J\\) (minimize total within-cluster variance)</p>"},{"location":"ml/module4-unsupervised-learning/#distance-metrics","title":"Distance Metrics","text":""},{"location":"ml/module4-unsupervised-learning/#euclidean-distance-most-common","title":"Euclidean Distance (Most Common)","text":"\\[ d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2} = ||x - y||_2 \\] <p>When to Use</p> <p>Best for continuous data where all features have similar scales.</p>"},{"location":"ml/module4-unsupervised-learning/#manhattan-distance-l1","title":"Manhattan Distance (L1)","text":"\\[ d(x, y) = \\sum_{i=1}^{n} |x_i - y_i| \\] <p>When to Use</p> <p>Better when dealing with high-dimensional data or when outliers are present.</p>"},{"location":"ml/module4-unsupervised-learning/#cosine-similarity","title":"Cosine Similarity","text":"\\[ \\text{similarity}(x, y) = \\frac{x \\cdot y}{||x|| \\cdot ||y||} = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sqrt{\\sum_{i=1}^{n} x_i^2} \\cdot \\sqrt{\\sum_{i=1}^{n} y_i^2}} \\] <p>When to Use</p> <p>Best for text data and high-dimensional sparse data (measures angle, not magnitude).</p>"},{"location":"ml/module4-unsupervised-learning/#worked-example-k-means-step-by-step","title":"Worked Example: K-Means Step by Step","text":"<p>Problem</p> <p>Cluster the following 2D points into K=2 clusters:</p> Point x\u2081 x\u2082 A 1 1 B 1.5 2 C 3 4 D 5 7 E 3.5 5 F 4.5 5 <p>Step 1: Initialize Centroids</p> <p>Randomly select K=2 points as initial centroids: - \\(\\mu_1 = A = (1, 1)\\) - \\(\\mu_2 = D = (5, 7)\\)</p> <p>Step 2: First Assignment Step</p> <p>Calculate distance from each point to both centroids:</p> Point Distance to \u03bc\u2081 Distance to \u03bc\u2082 Assigned Cluster A (1,1) 0 \\(\\sqrt{(5-1)^2+(7-1)^2} = \\sqrt{52} = 7.21\\) Cluster 1 B (1.5,2) \\(\\sqrt{0.5^2+1^2} = 1.12\\) \\(\\sqrt{3.5^2+5^2} = 6.10\\) Cluster 1 C (3,4) \\(\\sqrt{2^2+3^2} = 3.61\\) \\(\\sqrt{2^2+3^2} = 3.61\\) Cluster 1 (tie, choose 1) D (5,7) \\(\\sqrt{4^2+6^2} = 7.21\\) 0 Cluster 2 E (3.5,5) \\(\\sqrt{2.5^2+4^2} = 4.72\\) \\(\\sqrt{1.5^2+2^2} = 2.50\\) Cluster 2 F (4.5,5) \\(\\sqrt{3.5^2+4^2} = 5.32\\) \\(\\sqrt{0.5^2+2^2} = 2.06\\) Cluster 2 <p>Cluster 1: {A, B, C} Cluster 2: {D, E, F}</p> <p>Step 3: First Update Step</p> <p>Calculate new centroids:</p> \\[ \\mu_1 = \\frac{1}{3}[(1,1) + (1.5,2) + (3,4)] = \\left(\\frac{5.5}{3}, \\frac{7}{3}\\right) = (1.83, 2.33) \\] \\[ \\mu_2 = \\frac{1}{3}[(5,7) + (3.5,5) + (4.5,5)] = \\left(\\frac{13}{3}, \\frac{17}{3}\\right) = (4.33, 5.67) \\] <p>Step 4: Second Assignment Step</p> <p>Recalculate distances with new centroids and reassign...</p> <p>(Continue until centroids don't change)</p> <p>Final Result:  - Cluster 1: {A, B, C} - Lower-left points - Cluster 2: {D, E, F} - Upper-right points</p>"},{"location":"ml/module4-unsupervised-learning/#choosing-k-the-elbow-method","title":"Choosing K: The Elbow Method","text":"<p>How do we choose the optimal number of clusters K?</p> <p>Elbow Method:</p> <ol> <li>Run K-Means for K = 1, 2, 3, ..., n</li> <li>Calculate WCSS (Within-Cluster Sum of Squares) for each K</li> <li>Plot K vs WCSS</li> <li>Look for the \"elbow\" - where WCSS decreases sharply then levels off</li> </ol> <pre><code>WCSS\n  |\n  |\\\n  | \\\n  |  \\\n  |   \\___________  \u2190 Elbow at K=3\n  |        \n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    1  2  3  4  5  K\n</code></pre> <p>Exam Tip</p> <p>The elbow point represents the optimal K - adding more clusters doesn't significantly reduce WCSS.</p>"},{"location":"ml/module4-unsupervised-learning/#other-methods-for-choosing-k","title":"Other Methods for Choosing K","text":"Method Description Silhouette Score Measures how similar points are to their own cluster vs other clusters Gap Statistic Compares WCSS to expected WCSS under null distribution Domain Knowledge Use prior knowledge (e.g., 3 customer types)"},{"location":"ml/module4-unsupervised-learning/#k-means-initialization","title":"K-Means++ Initialization","text":"<p>Problem with Random Initialization</p> <p>Random initialization can lead to poor local minima and inconsistent results.</p> <p>K-Means++ Algorithm:</p> <ol> <li>Choose first centroid randomly from data points</li> <li>For each remaining centroid:</li> <li>Calculate distance \\(D(x)\\) from each point to nearest existing centroid</li> <li>Choose next centroid with probability proportional to \\(D(x)^2\\)</li> <li>Points far from existing centroids are more likely to be chosen</li> </ol> <p>Benefits: - More spread out initial centroids - Faster convergence - Better final clusters</p>"},{"location":"ml/module4-unsupervised-learning/#advantages-and-disadvantages","title":"Advantages and Disadvantages","text":"Advantages Disadvantages \u2705 Simple and intuitive \u274c Must specify K beforehand \u2705 Fast: O(n\u00b7K\u00b7iterations) \u274c Sensitive to initialization \u2705 Scales to large datasets \u274c Assumes spherical clusters \u2705 Guaranteed to converge \u274c Sensitive to outliers \u2705 Works well for compact clusters \u274c Struggles with varying cluster sizes <p>Common Mistakes</p> <ol> <li>Not scaling features: K-Means uses distance, so features with larger ranges dominate</li> <li>Wrong K: Always use elbow method or domain knowledge</li> <li>Single run: Always run multiple times with different initializations</li> </ol>"},{"location":"ml/module4-unsupervised-learning/#hierarchical-clustering","title":"Hierarchical Clustering","text":""},{"location":"ml/module4-unsupervised-learning/#overview_1","title":"Overview","text":"<p>Hierarchical Clustering creates a tree-like structure (dendrogram) of clusters without pre-specifying the number of clusters.</p>"},{"location":"ml/module4-unsupervised-learning/#types-of-hierarchical-clustering","title":"Types of Hierarchical Clustering","text":""},{"location":"ml/module4-unsupervised-learning/#1-agglomerative-bottom-up-most-common","title":"1. Agglomerative (Bottom-Up) - Most Common","text":"<pre><code>Start: Each point is its own cluster\n       \u2193\nMerge closest clusters\n       \u2193\nRepeat until one cluster remains\n       \u2193\nResult: Dendrogram (tree structure)\n</code></pre>"},{"location":"ml/module4-unsupervised-learning/#2-divisive-top-down","title":"2. Divisive (Top-Down)","text":"<pre><code>Start: All points in one cluster\n       \u2193\nSplit clusters\n       \u2193\nRepeat until each point is its own cluster\n       \u2193\nResult: Dendrogram\n</code></pre>"},{"location":"ml/module4-unsupervised-learning/#agglomerative-algorithm","title":"Agglomerative Algorithm","text":"<pre><code>Agglomerative Clustering:\n\n1. INITIALIZE: Create n clusters (one per data point)\n\n2. COMPUTE: Distance matrix between all pairs of clusters\n\n3. REPEAT until one cluster remains:\n   a. Find two closest clusters\n   b. Merge them into one cluster\n   c. Update distance matrix\n\n4. RESULT: Dendrogram showing merge history\n</code></pre>"},{"location":"ml/module4-unsupervised-learning/#linkage-criteria","title":"Linkage Criteria","text":"<p>How do we measure distance between clusters?</p>"},{"location":"ml/module4-unsupervised-learning/#1-single-linkage-minimum","title":"1. Single Linkage (Minimum)","text":"\\[ d(C_i, C_j) = \\min_{x \\in C_i, y \\in C_j} d(x, y) \\] <ul> <li>Distance = minimum distance between any two points</li> <li>Pros: Can find elongated clusters</li> <li>Cons: Chaining effect (long, stringy clusters)</li> </ul>"},{"location":"ml/module4-unsupervised-learning/#2-complete-linkage-maximum","title":"2. Complete Linkage (Maximum)","text":"\\[ d(C_i, C_j) = \\max_{x \\in C_i, y \\in C_j} d(x, y) \\] <ul> <li>Distance = maximum distance between any two points</li> <li>Pros: Produces compact, spherical clusters</li> <li>Cons: Sensitive to outliers</li> </ul>"},{"location":"ml/module4-unsupervised-learning/#3-average-linkage-upgma","title":"3. Average Linkage (UPGMA)","text":"\\[ d(C_i, C_j) = \\frac{1}{|C_i| \\cdot |C_j|} \\sum_{x \\in C_i} \\sum_{y \\in C_j} d(x, y) \\] <ul> <li>Distance = average of all pairwise distances</li> <li>Pros: Balanced approach, less sensitive to outliers</li> <li>Cons: Computationally more expensive</li> </ul>"},{"location":"ml/module4-unsupervised-learning/#4-centroid-linkage","title":"4. Centroid Linkage","text":"\\[ d(C_i, C_j) = d(\\mu_i, \\mu_j) \\] <ul> <li>Distance = distance between cluster centroids</li> <li>Pros: Intuitive</li> <li>Cons: Can lead to inversions in dendrogram</li> </ul>"},{"location":"ml/module4-unsupervised-learning/#5-wards-method","title":"5. Ward's Method","text":"\\[ d(C_i, C_j) = \\text{Increase in total within-cluster variance after merging} \\] <ul> <li>Minimizes total within-cluster variance</li> <li>Pros: Produces compact, similar-sized clusters</li> <li>Cons: Assumes spherical clusters</li> </ul>"},{"location":"ml/module4-unsupervised-learning/#dendrogram","title":"Dendrogram","text":"<p>Definition</p> <p>A dendrogram is a tree diagram showing the hierarchical relationship between clusters.</p> <pre><code>Height (Distance)\n    |\n  6 |     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    |     \u2502               \u2502\n  4 |   \u250c\u2500\u2534\u2500\u2510           \u250c\u2500\u2534\u2500\u2510\n    |   \u2502   \u2502           \u2502   \u2502\n  2 | \u250c\u2500\u2534\u2500\u2510 \u2502         \u250c\u2500\u2534\u2500\u2510 \u2502\n    | \u2502   \u2502 \u2502         \u2502   \u2502 \u2502\n  0 | A   B C         D   E F\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre> <p>How to Read: - Leaves (bottom): Individual data points - Branches: Clusters at different levels - Height: Distance at which clusters merge - Horizontal cut: Determines number of clusters</p> <p>Choosing Number of Clusters</p> <p>Draw a horizontal line at desired height - number of vertical lines it crosses = number of clusters.</p>"},{"location":"ml/module4-unsupervised-learning/#worked-example-hierarchical-clustering","title":"Worked Example: Hierarchical Clustering","text":"<p>Problem</p> <p>Cluster points A(0,0), B(1,0), C(4,0), D(5,0) using single linkage.</p> <p>Distance Matrix:</p> A B C D A 0 1 4 5 B 1 0 3 4 C 4 3 0 1 D 5 4 1 0 <p>Step 1: Minimum distance = 1 (A-B and C-D) - Merge A and B \u2192 {A,B} - Merge C and D \u2192 {C,D}</p> <p>Step 2: Update distances (single linkage): - d({A,B}, {C,D}) = min(d(A,C), d(A,D), d(B,C), d(B,D)) = min(4, 5, 3, 4) = 3</p> <p>Step 3: Merge {A,B} and {C,D} at distance 3</p> <p>Dendrogram: <pre><code>Height\n  3 |     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    |     \u2502       \u2502\n  1 |   \u250c\u2500\u2534\u2500\u2510   \u250c\u2500\u2534\u2500\u2510\n    |   \u2502   \u2502   \u2502   \u2502\n  0 |   A   B   C   D\n</code></pre></p>"},{"location":"ml/module4-unsupervised-learning/#comparison-k-means-vs-hierarchical","title":"Comparison: K-Means vs Hierarchical","text":"Aspect K-Means Hierarchical K specification Required upfront Not required Output Flat clusters Dendrogram (tree) Complexity O(n\u00b7K\u00b7iterations) O(n\u00b3) or O(n\u00b2log n) Scalability Good for large data Better for small data Cluster shape Spherical Any shape (with single linkage) Reproducibility Depends on initialization Deterministic"},{"location":"ml/module4-unsupervised-learning/#dimensionality-reduction","title":"Dimensionality Reduction","text":""},{"location":"ml/module4-unsupervised-learning/#why-reduce-dimensions","title":"Why Reduce Dimensions?","text":"<p>Curse of Dimensionality</p> <p>As dimensions increase:</p> <ul> <li>Data becomes sparse</li> <li>Distance metrics become less meaningful</li> <li>Computational cost increases exponentially</li> <li>More data needed to avoid overfitting</li> </ul> <p>Benefits of Dimensionality Reduction:</p> <ol> <li>Visualization: Reduce to 2D/3D for plotting</li> <li>Noise Reduction: Remove noisy features</li> <li>Computational Efficiency: Faster training</li> <li>Avoid Overfitting: Fewer features = simpler model</li> <li>Feature Extraction: Create meaningful features</li> </ol>"},{"location":"ml/module4-unsupervised-learning/#methods-overview","title":"Methods Overview","text":"Method Type Preserves PCA Linear Global variance t-SNE Non-linear Local structure LDA Linear, Supervised Class separability Autoencoders Non-linear Learned representation"},{"location":"ml/module4-unsupervised-learning/#principal-component-analysis-pca","title":"Principal Component Analysis (PCA)","text":""},{"location":"ml/module4-unsupervised-learning/#key-idea","title":"Key Idea","text":"<p>PCA in One Sentence</p> <p>PCA finds new axes (principal components) that capture the maximum variance in the data.</p> <p>Intuition:  - First PC: Direction of maximum variance - Second PC: Direction of maximum variance perpendicular to first - And so on...</p>"},{"location":"ml/module4-unsupervised-learning/#mathematical-foundation","title":"Mathematical Foundation","text":""},{"location":"ml/module4-unsupervised-learning/#step-by-step-algorithm","title":"Step-by-Step Algorithm","text":"<p>Step 1: Standardize the Data</p> <p>For each feature, compute z-score:</p> \\[ z_i = \\frac{x_i - \\mu_i}{\\sigma_i} \\] <p>Important</p> <p>Always standardize before PCA! Otherwise, features with larger scales dominate.</p> <p>Step 2: Compute Covariance Matrix</p> \\[ \\Sigma = \\frac{1}{m-1} X^T X \\] <p>Where X is the centered data matrix (m samples \u00d7 n features).</p> <p>The covariance matrix shows how features vary together: - Diagonal: Variance of each feature - Off-diagonal: Covariance between features</p> <p>Step 3: Eigenvalue Decomposition</p> <p>Find eigenvalues \\(\\lambda_1, \\lambda_2, ..., \\lambda_n\\) and eigenvectors \\(v_1, v_2, ..., v_n\\) such that:</p> \\[ \\Sigma v_i = \\lambda_i v_i \\] <p>Properties: - Eigenvalues are non-negative (covariance matrix is positive semi-definite) - Eigenvectors are orthogonal - Eigenvalue = variance explained by that component</p> <p>Step 4: Sort and Select</p> <p>Sort eigenvalues in descending order: \\(\\lambda_1 \\geq \\lambda_2 \\geq ... \\geq \\lambda_n\\)</p> <p>Select top k eigenvectors (principal components) that capture desired variance.</p> <p>Step 5: Project Data</p> \\[ Y = X \\cdot P_k \\] <p>Where: - \\(X\\) = original data (m \u00d7 n) - \\(P_k\\) = matrix of top k eigenvectors (n \u00d7 k) - \\(Y\\) = reduced data (m \u00d7 k)</p>"},{"location":"ml/module4-unsupervised-learning/#variance-explained","title":"Variance Explained","text":"<p>Proportion of Variance Explained by component i:</p> \\[ \\text{Variance Explained}_i = \\frac{\\lambda_i}{\\sum_{j=1}^{n} \\lambda_j} \\] <p>Cumulative Variance Explained:</p> \\[ \\text{Cumulative}_k = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{j=1}^{n} \\lambda_j} \\] <p>Rule of Thumb</p> <p>Choose k such that cumulative variance \u2265 95% (or 90% for more compression).</p>"},{"location":"ml/module4-unsupervised-learning/#choosing-number-of-components","title":"Choosing Number of Components","text":"<p>Method 1: Scree Plot</p> <pre><code>Eigenvalue\n    |\n    |*\n    | *\n    |  *\n    |   *___*___*___*  \u2190 Elbow\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n      1  2  3  4  5  k\n</code></pre> <p>Choose k at the \"elbow\" where eigenvalues drop sharply.</p> <p>Method 2: Cumulative Variance Threshold</p> k Cumulative Variance 1 60% 2 85% 3 95% \u2190 Choose this 4 99% <p>Method 3: Kaiser Criterion</p> <p>Keep components with eigenvalue &gt; 1 (for standardized data).</p>"},{"location":"ml/module4-unsupervised-learning/#worked-example-pca","title":"Worked Example: PCA","text":"<p>Problem</p> <p>Perform PCA on the following 2D data and reduce to 1D:</p> Point x\u2081 x\u2082 1 2.5 2.4 2 0.5 0.7 3 2.2 2.9 4 1.9 2.2 5 3.1 3.0 <p>Step 1: Calculate means</p> \\[ \\bar{x}_1 = \\frac{2.5 + 0.5 + 2.2 + 1.9 + 3.1}{5} = 2.04 \\] \\[ \\bar{x}_2 = \\frac{2.4 + 0.7 + 2.9 + 2.2 + 3.0}{5} = 2.24 \\] <p>Step 2: Center the data (subtract means)</p> Point x\u2081 - 2.04 x\u2082 - 2.24 1 0.46 0.16 2 -1.54 -1.54 3 0.16 0.66 4 -0.14 -0.04 5 1.06 0.76 <p>Step 3: Compute covariance matrix</p> \\[ \\Sigma = \\begin{bmatrix} 0.616 &amp; 0.615 \\\\ 0.615 &amp; 0.716 \\end{bmatrix} \\] <p>Step 4: Find eigenvalues and eigenvectors</p> <p>Eigenvalues: \\(\\lambda_1 = 1.284\\), \\(\\lambda_2 = 0.049\\)</p> <p>Eigenvectors: \\(v_1 = [0.677, 0.736]\\), \\(v_2 = [-0.736, 0.677]\\)</p> <p>Step 5: Variance explained</p> <ul> <li>PC1: \\(\\frac{1.284}{1.284 + 0.049} = 96.3\\%\\)</li> <li>PC2: \\(\\frac{0.049}{1.333} = 3.7\\%\\)</li> </ul> <p>Conclusion: First PC captures 96.3% of variance - we can reduce to 1D with minimal information loss!</p>"},{"location":"ml/module4-unsupervised-learning/#properties-of-pca","title":"Properties of PCA","text":"<p>Key Properties:</p> <ol> <li>Orthogonality: Principal components are uncorrelated</li> <li>Variance Maximization: Each PC maximizes remaining variance</li> <li>Linear: PCA finds linear combinations of original features</li> <li>Reversible: Can reconstruct original data (with some loss)</li> </ol> <p>Limitations:</p> Limitation Description Linear only Cannot capture non-linear relationships Variance-based May not preserve class separability Sensitive to scaling Must standardize first Interpretability PCs are combinations of features"},{"location":"ml/module4-unsupervised-learning/#association-rule-learning","title":"Association Rule Learning","text":""},{"location":"ml/module4-unsupervised-learning/#introduction","title":"Introduction","text":"<p>Association Rules discover interesting relationships between variables in large datasets.</p> <p>Classic Example: Market Basket Analysis</p> <p>\"Customers who buy bread and butter also buy milk\"</p> <p>Rule: {Bread, Butter} \u2192 {Milk}</p>"},{"location":"ml/module4-unsupervised-learning/#key-concepts_1","title":"Key Concepts","text":""},{"location":"ml/module4-unsupervised-learning/#itemset","title":"Itemset","text":"<p>An itemset is a collection of items. - {Bread} - 1-itemset - {Bread, Butter} - 2-itemset - {Bread, Butter, Milk} - 3-itemset</p>"},{"location":"ml/module4-unsupervised-learning/#support","title":"Support","text":"<p>Support measures how frequently an itemset appears in the dataset.</p> \\[ \\text{Support}(A) = \\frac{\\text{Number of transactions containing A}}{\\text{Total number of transactions}} \\] <p>Support Example</p> <p>If 100 transactions and 30 contain {Bread, Milk}:</p> <p>Support({Bread, Milk}) = 30/100 = 0.30 = 30%</p>"},{"location":"ml/module4-unsupervised-learning/#confidence","title":"Confidence","text":"<p>Confidence measures how often the rule is true.</p> \\[ \\text{Confidence}(A \\rightarrow B) = \\frac{\\text{Support}(A \\cup B)}{\\text{Support}(A)} = P(B|A) \\] <p>Confidence Example</p> <ul> <li>Support({Bread}) = 50%</li> <li>Support({Bread, Milk}) = 30%</li> </ul> <p>Confidence(Bread \u2192 Milk) = 30%/50% = 60%</p> <p>\"60% of customers who buy bread also buy milk\"</p>"},{"location":"ml/module4-unsupervised-learning/#lift","title":"Lift","text":"<p>Lift measures how much more likely B is when A occurs, compared to B occurring independently.</p> \\[ \\text{Lift}(A \\rightarrow B) = \\frac{\\text{Confidence}(A \\rightarrow B)}{\\text{Support}(B)} = \\frac{P(B|A)}{P(B)} \\] <p>Interpretation: - Lift = 1: A and B are independent - Lift &gt; 1: Positive correlation (A increases likelihood of B) - Lift &lt; 1: Negative correlation (A decreases likelihood of B)</p> <p>Lift Example</p> <ul> <li>Confidence(Bread \u2192 Milk) = 60%</li> <li>Support(Milk) = 40%</li> </ul> <p>Lift = 60%/40% = 1.5</p> <p>\"Customers who buy bread are 1.5\u00d7 more likely to buy milk\"</p>"},{"location":"ml/module4-unsupervised-learning/#apriori-algorithm","title":"Apriori Algorithm","text":"<p>Apriori Principle</p> <p>If an itemset is infrequent, all its supersets are also infrequent.</p> <p>Contrapositive: If an itemset is frequent, all its subsets are also frequent.</p> <p>Algorithm:</p> <pre><code>Apriori Algorithm:\n\nInput: Transaction database, minimum support, minimum confidence\nOutput: Association rules\n\n1. Find all frequent 1-itemsets (items with support \u2265 min_support)\n\n2. For k = 2, 3, ... until no more frequent itemsets:\n   a. Generate candidate k-itemsets from frequent (k-1)-itemsets\n   b. Prune candidates with infrequent subsets\n   c. Count support for remaining candidates\n   d. Keep itemsets with support \u2265 min_support\n\n3. Generate rules from frequent itemsets:\n   For each frequent itemset I:\n     For each non-empty subset A of I:\n       Rule: A \u2192 (I - A)\n       If confidence \u2265 min_confidence:\n         Output rule\n</code></pre>"},{"location":"ml/module4-unsupervised-learning/#worked-example-apriori","title":"Worked Example: Apriori","text":"<p>Problem</p> <p>Given transactions and min_support = 50%, min_confidence = 60%:</p> TID Items 1 {Bread, Milk} 2 {Bread, Butter, Milk} 3 {Bread, Butter} 4 {Milk, Eggs} <p>Step 1: Count 1-itemsets</p> Item Count Support Bread 3 75% \u2713 Milk 3 75% \u2713 Butter 2 50% \u2713 Eggs 1 25% \u2717 <p>Frequent 1-itemsets: {Bread}, {Milk}, {Butter}</p> <p>Step 2: Generate and count 2-itemsets</p> Itemset Count Support {Bread, Milk} 2 50% \u2713 {Bread, Butter} 2 50% \u2713 {Milk, Butter} 1 25% \u2717 <p>Frequent 2-itemsets: {Bread, Milk}, {Bread, Butter}</p> <p>Step 3: Generate 3-itemsets</p> <p>Candidate: {Bread, Milk, Butter} - Subset {Milk, Butter} is infrequent \u2192 Prune</p> <p>No frequent 3-itemsets.</p> <p>Step 4: Generate Rules</p> <p>From {Bread, Milk}: - Bread \u2192 Milk: Confidence = 50%/75% = 67% \u2713 - Milk \u2192 Bread: Confidence = 50%/75% = 67% \u2713</p> <p>From {Bread, Butter}: - Bread \u2192 Butter: Confidence = 50%/75% = 67% \u2713 - Butter \u2192 Bread: Confidence = 50%/50% = 100% \u2713</p> <p>Final Rules (confidence \u2265 60%): 1. Bread \u2192 Milk (67%) 2. Milk \u2192 Bread (67%) 3. Bread \u2192 Butter (67%) 4. Butter \u2192 Bread (100%)</p>"},{"location":"ml/module4-unsupervised-learning/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"ml/module4-unsupervised-learning/#k-means","title":"K-Means","text":"Formula Description \\(J = \\sum_{i=1}^{m} \\sum_{k=1}^{K} w_{ik} \\|\\|x^{(i)} - \\mu_k\\|\\|^2\\) Objective function \\(\\mu_k = \\frac{1}{\\|C_k\\|} \\sum_{x \\in C_k} x\\) Centroid update \\(d(x, y) = \\sqrt{\\sum_i (x_i - y_i)^2}\\) Euclidean distance"},{"location":"ml/module4-unsupervised-learning/#pca","title":"PCA","text":"Formula Description \\(\\Sigma = \\frac{1}{m-1} X^T X\\) Covariance matrix \\(\\Sigma v = \\lambda v\\) Eigenvalue equation \\(\\frac{\\lambda_i}{\\sum_j \\lambda_j}\\) Variance explained \\(Y = X \\cdot P_k\\) Projection"},{"location":"ml/module4-unsupervised-learning/#association-rules","title":"Association Rules","text":"Formula Description \\(\\text{Support}(A) = \\frac{\\text{Count}(A)}{N}\\) Support \\(\\text{Confidence}(A \\rightarrow B) = \\frac{\\text{Support}(A \\cup B)}{\\text{Support}(A)}\\) Confidence \\(\\text{Lift}(A \\rightarrow B) = \\frac{\\text{Confidence}(A \\rightarrow B)}{\\text{Support}(B)}\\) Lift"},{"location":"ml/module4-unsupervised-learning/#common-exam-questions","title":"Common Exam Questions","text":"<p>Q1: Explain K-Means algorithm with example</p> <ol> <li>Initialize K centroids randomly</li> <li>Assign each point to nearest centroid</li> <li>Update centroids as mean of assigned points</li> <li>Repeat until convergence</li> </ol> <p>(Include numerical example with distance calculations)</p> <p>Q2: How to choose optimal K in K-Means?</p> <p>Elbow Method: Plot WCSS vs K, choose K at the elbow where decrease slows down.</p> <p>Silhouette Score: Measures cluster quality, choose K with highest score.</p> <p>Domain Knowledge: Use prior knowledge about expected clusters.</p> <p>Q3: Explain PCA and its applications</p> <p>PCA finds principal components (directions of maximum variance) to reduce dimensionality.</p> <p>Steps: Standardize \u2192 Covariance matrix \u2192 Eigendecomposition \u2192 Select top k \u2192 Project</p> <p>Applications: Visualization, noise reduction, feature extraction, preprocessing</p> <p>Q4: Calculate Support, Confidence, Lift</p> <p>Given transactions, calculate: - Support = Count(itemset) / Total transactions - Confidence = Support(A\u222aB) / Support(A) - Lift = Confidence / Support(B)</p>"},{"location":"ml/module4-unsupervised-learning/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 K-Means: Partition into K clusters, minimize within-cluster variance</p> <p>\u2705 Elbow Method: Plot cost vs K, choose at elbow</p> <p>\u2705 K-Means++: Better initialization, spread out centroids</p> <p>\u2705 Hierarchical: Creates dendrogram, no need to specify K</p> <p>\u2705 Linkage: Single (min), Complete (max), Average, Ward's</p> <p>\u2705 PCA: Find directions of maximum variance, reduce dimensions</p> <p>\u2705 Variance Explained: Choose k for 95% cumulative variance</p> <p>\u2705 Association Rules: Support, Confidence, Lift</p> <p>\u2705 Apriori: Frequent itemset mining using downward closure</p> <p>\u2705 Feature Scaling: Critical for K-Means and PCA</p> <p>Previous: Module 3 - Classification &amp; Evaluation | Next: Module 5 - Decision Trees</p>"},{"location":"ml/module5-decision-trees/","title":"Module 5: Decision Trees","text":""},{"location":"ml/module5-decision-trees/#overview","title":"Overview","text":"<p>Decision Trees are versatile algorithms used for both classification and regression. They create a tree-like model of decisions based on feature values.</p>"},{"location":"ml/module5-decision-trees/#introduction-to-decision-trees","title":"Introduction to Decision Trees","text":""},{"location":"ml/module5-decision-trees/#what-is-a-decision-tree","title":"What is a Decision Tree?","text":"<p>A Decision Tree is a flowchart-like structure where: - Internal nodes: Represent features/attributes - Branches: Represent decision rules (feature values) - Leaf nodes: Represent class labels (classification) or values (regression)</p>"},{"location":"ml/module5-decision-trees/#example","title":"Example","text":"<pre><code>                    Outlook\n                   /   |   \\\n              Sunny Overcast Rainy\n              /        |        \\\n          Humidity    Yes    Wind\n          /     \\              /   \\\n      High    Normal      Strong  Weak\n       /        |           /       \\\n      No       Yes         No       Yes\n</code></pre> <p>Interpretation:  - If Outlook = Sunny and Humidity = High \u2192 No (don't play) - If Outlook = Overcast \u2192 Yes (play) - If Outlook = Rainy and Wind = Weak \u2192 Yes (play)</p>"},{"location":"ml/module5-decision-trees/#advantages","title":"Advantages","text":"<p>\u2705 Easy to understand and interpret (visual) \u2705 Requires little data preparation \u2705 Handles both numerical and categorical data \u2705 Can model non-linear relationships \u2705 Feature importance is clear</p>"},{"location":"ml/module5-decision-trees/#disadvantages","title":"Disadvantages","text":"<p>\u274c Prone to overfitting \u274c Unstable (small data changes \u2192 different tree) \u274c Biased toward features with more levels \u274c Can create biased trees if classes are imbalanced</p>"},{"location":"ml/module5-decision-trees/#decision-tree-construction","title":"Decision Tree Construction","text":""},{"location":"ml/module5-decision-trees/#algorithm-overview","title":"Algorithm Overview","text":"<p>Top-Down Approach (Recursive Partitioning):</p> <ol> <li>Start: All training examples at root</li> <li>Select Best Feature: Choose feature that best splits data</li> <li>Split: Partition data based on feature values</li> <li>Recurse: Repeat for each subset until stopping criterion met</li> <li>Leaf Node: Assign class label (majority class) or value (mean)</li> </ol>"},{"location":"ml/module5-decision-trees/#key-questions","title":"Key Questions","text":"<ol> <li>Which feature to split on?</li> <li> <p>Use impurity measures (Entropy, Gini, Information Gain)</p> </li> <li> <p>When to stop splitting?</p> </li> <li>All examples in node have same class</li> <li>No more features to split on</li> <li>Maximum depth reached</li> <li>Minimum samples per node</li> <li> <p>Impurity reduction too small</p> </li> <li> <p>What value to assign to leaf?</p> </li> <li>Classification: Majority class</li> <li>Regression: Mean (or median) of target values</li> </ol>"},{"location":"ml/module5-decision-trees/#impurity-measures","title":"Impurity Measures","text":""},{"location":"ml/module5-decision-trees/#entropy","title":"Entropy","text":"<p>Entropy measures uncertainty/randomness in data.</p> <p>Formula:</p> \\[ H(S) = -\\sum_{i=1}^{c} p_i \\log_2(p_i) \\] <p>Where: - \\(S\\) = set of examples - \\(c\\) = number of classes - \\(p_i\\) = proportion of class \\(i\\) in \\(S\\)</p> <p>Properties: - Entropy = 0: Pure node (all same class) - Entropy = 1: Maximum impurity (equal distribution for binary) - Maximum Entropy: \\(\\log_2(c)\\) for \\(c\\) classes</p> <p>Example (Binary Classification): - Pure node: [10 Yes, 0 No] \u2192 \\(H = -1 \\cdot \\log_2(1) - 0 \\cdot \\log_2(0) = -1 \\cdot 0 - 0 = 0\\) - Impure node: [5 Yes, 5 No] \u2192 \\(H = -0.5 \\cdot \\log_2(0.5) - 0.5 \\cdot \\log_2(0.5) = -0.5 \\cdot (-1) - 0.5 \\cdot (-1) = 1\\) - Mixed node: [7 Yes, 3 No] \u2192 \\(H = -0.7 \\cdot \\log_2(0.7) - 0.3 \\cdot \\log_2(0.3) \\approx 0.88\\)</p> <p>Remember</p> <p>When \\(p_i = 0\\), we define \\(p_i \\log_2(p_i) = 0\\) (by convention) to avoid \\(\\log(0)\\) which is undefined.</p> <p>Exam Tip</p> <p>For binary classification, memorize: Maximum entropy = 1 when classes are perfectly balanced (50-50 split).</p>"},{"location":"ml/module5-decision-trees/#gini-impurity-gini-index","title":"Gini Impurity (Gini Index)","text":"<p>Gini Impurity measures the probability of misclassifying a randomly chosen element.</p> <p>Formula:</p> \\[ \\text{Gini}(S) = 1 - \\sum_{i=1}^{c} p_i^2 \\] <p>Where: - \\(S\\) = set of examples - \\(c\\) = number of classes - \\(p_i\\) = proportion of class \\(i\\) in \\(S\\)</p> <p>Properties: - Gini = 0: Pure node (all same class) - Gini = 0.5: Maximum impurity for binary classification - Maximum Gini: \\(1 - \\frac{1}{c}\\) for \\(c\\) classes</p> <p>Example (Binary Classification): - Pure node: [10 Yes, 0 No] \u2192 \\(\\text{Gini} = 1 - (1^2 + 0^2) = 1 - 1 = 0\\) - Impure node: [5 Yes, 5 No] \u2192 \\(\\text{Gini} = 1 - (0.5^2 + 0.5^2) = 1 - 0.5 = 0.5\\) - Mixed node: [7 Yes, 3 No] \u2192 \\(\\text{Gini} = 1 - (0.7^2 + 0.3^2) = 1 - (0.49 + 0.09) = 0.42\\)</p> <p>Key Point</p> <p>Gini Impurity is computationally faster than Entropy because it doesn't require logarithms. Use Gini when performance is critical.</p> <p>Common Mistake</p> <p>Don't confuse Gini Impurity with Gini Coefficient (used in economics). They are different concepts!</p>"},{"location":"ml/module5-decision-trees/#comparison-entropy-vs-gini","title":"Comparison: Entropy vs Gini","text":"Aspect Entropy Gini Range [0, \\(\\log_2(c)\\)] [0, \\(1-\\frac{1}{c}\\)] Calculation More complex (log) Simpler (squares) Sensitivity More sensitive to changes Less sensitive Performance Slightly slower Faster Common Use ID3, C4.5 CART <p>Note: Both work well; choice is often based on convention or performance.</p>"},{"location":"ml/module5-decision-trees/#information-gain","title":"Information Gain","text":""},{"location":"ml/module5-decision-trees/#definition","title":"Definition","text":"<p>Information Gain measures reduction in entropy after splitting on a feature.</p> <p>Formula:</p> \\[ \\text{IG}(S, A) = H(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} H(S_v) \\] <p>Where: - \\(S\\) = set of examples - \\(A\\) = feature/attribute - \\(S_v\\) = subset where feature \\(A\\) has value \\(v\\) - \\(H(S)\\) = entropy of \\(S\\) - \\(H(S_v)\\) = entropy of subset \\(S_v\\)</p> <p>Interpretation: - High IG: Feature provides good split (reduces uncertainty) - IG = 0: Feature doesn't help (no reduction in entropy)</p>"},{"location":"ml/module5-decision-trees/#information-gain-ratio","title":"Information Gain Ratio","text":"<p>Problem: Information Gain favors features with many values.</p> <p>Solution: Normalize by Split Information</p> <p>Split Information:</p> \\[ \\text{SplitInfo}(S, A) = -\\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} \\log_2\\left(\\frac{|S_v|}{|S|}\\right) \\] <p>Information Gain Ratio:</p> \\[ \\text{IGR}(S, A) = \\frac{\\text{IG}(S, A)}{\\text{SplitInfo}(S, A)} \\] <p>Use: C4.5 algorithm uses Information Gain Ratio</p>"},{"location":"ml/module5-decision-trees/#decision-tree-algorithms","title":"Decision Tree Algorithms","text":""},{"location":"ml/module5-decision-trees/#id3-iterative-dichotomiser-3","title":"ID3 (Iterative Dichotomiser 3)","text":"<p>Algorithm: 1. Calculate entropy of dataset 2. For each feature, calculate information gain 3. Choose feature with highest information gain 4. Split dataset on chosen feature 5. Recurse for each subset</p> <p>Characteristics: - Uses Entropy and Information Gain - Handles categorical features only - No pruning - No handling of missing values</p>"},{"location":"ml/module5-decision-trees/#c45","title":"C4.5","text":"<p>Improvements over ID3: - Uses Information Gain Ratio (handles many-valued features) - Handles continuous features (creates thresholds) - Handles missing values - Pruning to reduce overfitting</p>"},{"location":"ml/module5-decision-trees/#cart-classification-and-regression-trees","title":"CART (Classification and Regression Trees)","text":"<p>Characteristics: - Uses Gini Impurity (classification) or MSE (regression) - Handles both classification and regression - Binary splits only (each node has 2 children) - Uses Cost Complexity Pruning</p>"},{"location":"ml/module5-decision-trees/#decision-tree-construction-example","title":"Decision Tree Construction Example","text":""},{"location":"ml/module5-decision-trees/#example-dataset","title":"Example Dataset","text":"Outlook Temperature Humidity Wind Play? Sunny Hot High Weak No Sunny Hot High Strong No Overcast Hot High Weak Yes Rainy Mild High Weak Yes Rainy Cool Normal Weak Yes Rainy Cool Normal Strong No Overcast Cool Normal Strong Yes Sunny Mild High Weak No Sunny Cool Normal Weak Yes Rainy Mild Normal Weak Yes Sunny Mild Normal Strong Yes Overcast Mild High Strong Yes Overcast Hot Normal Weak Yes Rainy Mild High Strong No"},{"location":"ml/module5-decision-trees/#step-1-calculate-root-entropy","title":"Step 1: Calculate Root Entropy","text":"<p>Total: 14 examples - Yes: 9 - No: 5</p> \\[ H(S) = -\\frac{9}{14}\\log_2\\left(\\frac{9}{14}\\right) - \\frac{5}{14}\\log_2\\left(\\frac{5}{14}\\right) \\approx 0.940 \\]"},{"location":"ml/module5-decision-trees/#step-2-calculate-information-gain-for-each-feature","title":"Step 2: Calculate Information Gain for Each Feature","text":"<p>For Outlook: - Sunny: [2 Yes, 3 No] \u2192 \\(H = 0.971\\) - Overcast: [4 Yes, 0 No] \u2192 \\(H = 0\\) - Rainy: [3 Yes, 2 No] \u2192 \\(H = 0.971\\)</p> \\[ \\text{IG}(S, \\text{Outlook}) = 0.940 - \\left(\\frac{5}{14} \\times 0.971 + \\frac{4}{14} \\times 0 + \\frac{5}{14} \\times 0.971\\right) = 0.246 \\] <p>For Humidity: - High: [3 Yes, 4 No] \u2192 \\(H = 0.985\\) - Normal: [6 Yes, 1 No] \u2192 \\(H = 0.592\\)</p> \\[ \\text{IG}(S, \\text{Humidity}) = 0.940 - \\left(\\frac{7}{14} \\times 0.985 + \\frac{7}{14} \\times 0.592\\right) = 0.152 \\] <p>For Wind: - Weak: [6 Yes, 2 No] \u2192 \\(H = 0.811\\) - Strong: [3 Yes, 3 No] \u2192 \\(H = 1.0\\)</p> \\[ \\text{IG}(S, \\text{Wind}) = 0.940 - \\left(\\frac{8}{14} \\times 0.811 + \\frac{6}{14} \\times 1.0\\right) = 0.048 \\] <p>For Temperature: - Hot: [2 Yes, 2 No] \u2192 \\(H = 1.0\\) - Mild: [4 Yes, 2 No] \u2192 \\(H = 0.918\\) - Cool: [3 Yes, 1 No] \u2192 \\(H = 0.811\\)</p> \\[ \\text{IG}(S, \\text{Temperature}) = 0.940 - \\left(\\frac{4}{14} \\times 1.0 + \\frac{6}{14} \\times 0.918 + \\frac{4}{14} \\times 0.811\\right) = 0.029 \\] <p>Result: Outlook has highest Information Gain (0.246) \u2192 Split on Outlook</p>"},{"location":"ml/module5-decision-trees/#step-3-build-tree-recursively","title":"Step 3: Build Tree Recursively","text":"<pre><code>                    Outlook\n                   /   |   \\\n              Sunny Overcast Rainy\n              [2Y,3N] [4Y,0N] [3Y,2N]\n              /        |        \\\n          (Yes)    Humidity    Wind\n                    /     \\      /   \\\n                High  Normal Strong Weak\n               [0Y,2N] [2Y,1N] [0Y,2N] [3Y,0N]\n                 /       |       /       |\n               (No)    (Yes)   (No)    (Yes)\n</code></pre> <p>Final Tree: - If Outlook = Overcast \u2192 Yes - If Outlook = Sunny and Humidity = High \u2192 No - If Outlook = Sunny and Humidity = Normal \u2192 Yes - If Outlook = Rainy and Wind = Strong \u2192 No - If Outlook = Rainy and Wind = Weak \u2192 Yes</p>"},{"location":"ml/module5-decision-trees/#pruning","title":"Pruning","text":""},{"location":"ml/module5-decision-trees/#why-prune","title":"Why Prune?","text":"<p>Overfitting: Tree too complex, memorizes training data, poor generalization</p> <p>Solution: Remove branches that don't improve generalization</p>"},{"location":"ml/module5-decision-trees/#types-of-pruning","title":"Types of Pruning","text":""},{"location":"ml/module5-decision-trees/#1-pre-pruning-early-stopping","title":"1. Pre-pruning (Early Stopping)","text":"<p>Stop splitting before perfect classification:</p> <p>Criteria: - Maximum depth - Minimum samples per node - Minimum information gain - Maximum number of leaf nodes</p> <p>Advantages: Faster, simpler Disadvantages: May stop too early (underfitting)</p>"},{"location":"ml/module5-decision-trees/#2-post-pruning","title":"2. Post-pruning","text":"<p>Build full tree, then remove branches:</p> <p>Methods: - Reduced Error Pruning: Remove branch if validation error doesn't increase - Cost Complexity Pruning: Balance tree complexity vs accuracy</p> <p>Advantages: Better results, uses all data Disadvantages: More expensive</p>"},{"location":"ml/module5-decision-trees/#cost-complexity-pruning","title":"Cost Complexity Pruning","text":"<p>Objective: Minimize $$ \\text{Cost} = \\text{Error} + \\alpha \\times \\text{Complexity} $$</p> <p>Where: - \\(\\alpha\\) = complexity parameter - Larger \\(\\alpha\\) \u2192 Simpler tree</p> <p>Algorithm: 1. Build full tree 2. For each \\(\\alpha\\), find subtree that minimizes cost 3. Choose \\(\\alpha\\) using cross-validation</p>"},{"location":"ml/module5-decision-trees/#regression-trees","title":"Regression Trees","text":""},{"location":"ml/module5-decision-trees/#difference-from-classification","title":"Difference from Classification","text":"<p>Classification Tree: - Predicts class labels - Uses Entropy/Gini for splitting - Leaf = majority class</p> <p>Regression Tree: - Predicts continuous values - Uses MSE (Mean Squared Error) for splitting - Leaf = mean (or median) of target values</p>"},{"location":"ml/module5-decision-trees/#splitting-criterion-for-regression","title":"Splitting Criterion for Regression","text":"<p>MSE (Mean Squared Error): $$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\bar{y})^2 $$</p> <p>Information Gain (Regression): $$ \\text{IG} = \\text{MSE}{\\text{parent}} - \\left(\\frac{n}}}{n} \\text{MSE{\\text{left}} + \\frac{n\\right) $$}}}{n} \\text{MSE}_{\\text{right}</p> <p>Choose split that maximizes information gain (minimizes weighted MSE).</p>"},{"location":"ml/module5-decision-trees/#key-formulas-summary","title":"Key Formulas Summary","text":""},{"location":"ml/module5-decision-trees/#entropy_1","title":"Entropy","text":"\\[ H(S) = -\\sum_{i=1}^{c} p_i \\log_2(p_i) \\]"},{"location":"ml/module5-decision-trees/#gini-impurity","title":"Gini Impurity","text":"\\[ \\text{Gini}(S) = 1 - \\sum_{i=1}^{c} p_i^2 \\]"},{"location":"ml/module5-decision-trees/#information-gain_1","title":"Information Gain","text":"\\[ \\text{IG}(S, A) = H(S) - \\sum_{v} \\frac{|S_v|}{|S|} H(S_v) \\]"},{"location":"ml/module5-decision-trees/#information-gain-ratio_1","title":"Information Gain Ratio","text":"\\[ \\text{IGR}(S, A) = \\frac{\\text{IG}(S, A)}{\\text{SplitInfo}(S, A)} \\]"},{"location":"ml/module5-decision-trees/#regression-mse","title":"Regression MSE","text":"\\[ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\bar{y})^2 \\]"},{"location":"ml/module5-decision-trees/#important-points-to-remember","title":"Important Points to Remember","text":"<p>\u2705 Decision Trees: Tree structure, easy to interpret</p> <p>\u2705 Entropy: Measures uncertainty, range [0, \\(\\log_2(c)\\)]</p> <p>\u2705 Gini: Measures impurity, range [0, \\(1-\\frac{1}{c}\\)]</p> <p>\u2705 Information Gain: Reduction in entropy after split</p> <p>\u2705 ID3: Uses Entropy, categorical features only</p> <p>\u2705 C4.5: Uses Information Gain Ratio, handles continuous features</p> <p>\u2705 CART: Uses Gini, binary splits, handles regression</p> <p>\u2705 Pruning: Prevents overfitting, improves generalization</p> <p>Previous: Module 4 - Unsupervised Learning | Back to: ML Overview</p>"},{"location":"ml/papers/2024-makeup-solved/","title":"2024 Mid Semester Makeup Paper - Complete Solutions","text":""},{"location":"ml/papers/2024-makeup-solved/#question-1-multiple-linear-regression","title":"Question 1: Multiple Linear Regression","text":""},{"location":"ml/papers/2024-makeup-solved/#problem-statement","title":"Problem Statement","text":"<p>Given training data:</p> x\u2081 x\u2082 y 1 2 5 2 3 8 3 1 7 4 2 10 <p>a) Write the hypothesis function for multiple linear regression.</p> <p>b) Using the normal equation, find the optimal parameters \\(\\theta = [\\theta_0, \\theta_1, \\theta_2]^T\\).</p> <p>c) Predict \\(y\\) for \\(x_1 = 5\\), \\(x_2 = 3\\).</p>"},{"location":"ml/papers/2024-makeup-solved/#solution","title":"Solution","text":""},{"location":"ml/papers/2024-makeup-solved/#part-a-hypothesis-function","title":"Part (a): Hypothesis Function","text":"<p>Multiple Linear Regression Hypothesis: $$ h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 $$</p> <p>Where: - \\(\\theta_0\\) = bias term - \\(\\theta_1\\) = weight for feature \\(x_1\\) - \\(\\theta_2\\) = weight for feature \\(x_2\\)</p>"},{"location":"ml/papers/2024-makeup-solved/#part-b-normal-equation","title":"Part (b): Normal Equation","text":"<p>Normal Equation: \\(\\theta = (X^T X)^{-1} X^T y\\)</p> <p>Step 1: Construct Matrix X and Vector y</p> <p>X Matrix (with bias term \\(x_0 = 1\\)): $\\(X = \\begin{bmatrix} 1 &amp; 1 &amp; 2 \\\\ 1 &amp; 2 &amp; 3 \\\\ 1 &amp; 3 &amp; 1 \\\\ 1 &amp; 4 &amp; 2 \\end{bmatrix}\\)$</p> <p>y Vector: $\\(y = \\begin{bmatrix} 5 \\\\ 8 \\\\ 7 \\\\ 10 \\end{bmatrix}\\)$</p> <p>Step 2: Calculate \\(X^T X\\)</p> \\[X^T = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 2 &amp; 3 &amp; 4 \\\\ 2 &amp; 3 &amp; 1 &amp; 2 \\end{bmatrix}\\] \\[X^T X = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 2 &amp; 3 &amp; 4 \\\\ 2 &amp; 3 &amp; 1 &amp; 2 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 1 &amp; 2 \\\\ 1 &amp; 2 &amp; 3 \\\\ 1 &amp; 3 &amp; 1 \\\\ 1 &amp; 4 &amp; 2 \\end{bmatrix}\\] <p>Element-wise calculation: - \\((X^T X)_{11} = 1+1+1+1 = 4\\) - \\((X^T X)_{12} = 1+2+3+4 = 10\\) - \\((X^T X)_{13} = 2+3+1+2 = 8\\) - \\((X^T X)_{21} = 1+2+3+4 = 10\\) - \\((X^T X)_{22} = 1+4+9+16 = 30\\) - \\((X^T X)_{23} = 2+6+3+8 = 19\\) - \\((X^T X)_{31} = 2+3+1+2 = 8\\) - \\((X^T X)_{32} = 2+6+3+8 = 19\\) - \\((X^T X)_{33} = 4+9+1+4 = 18\\)</p> \\[X^T X = \\begin{bmatrix} 4 &amp; 10 &amp; 8 \\\\ 10 &amp; 30 &amp; 19 \\\\ 8 &amp; 19 &amp; 18 \\end{bmatrix}\\] <p>Step 3: Calculate \\((X^T X)^{-1}\\)</p> <p>Determinant: $$ \\det(X^T X) = 4(30 \\times 18 - 19 \\times 19) - 10(10 \\times 18 - 19 \\times 8) + 8(10 \\times 19 - 30 \\times 8) $$ $$ = 4(540 - 361) - 10(180 - 152) + 8(190 - 240) $$ $$ = 4(179) - 10(28) + 8(-50) $$ $$ = 716 - 280 - 400 = 36 $$</p> <p>Adjugate Matrix (using cofactors): $\\((X^T X)^{-1} = \\frac{1}{36} \\begin{bmatrix} 179 &amp; -28 &amp; -50 \\\\ -28 &amp; 8 &amp; 4 \\\\ -50 &amp; 4 &amp; 20 \\end{bmatrix}\\)$</p> <p>Step 4: Calculate \\(X^T y\\)</p> \\[X^T y = \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 2 &amp; 3 &amp; 4 \\\\ 2 &amp; 3 &amp; 1 &amp; 2 \\end{bmatrix} \\begin{bmatrix} 5 \\\\ 8 \\\\ 7 \\\\ 10 \\end{bmatrix} = \\begin{bmatrix} 30 \\\\ 70 \\\\ 47 \\end{bmatrix}\\] <p>Step 5: Calculate \\(\\theta\\)</p> \\[\\theta = (X^T X)^{-1} X^T y = \\frac{1}{36} \\begin{bmatrix} 179 &amp; -28 &amp; -50 \\\\ -28 &amp; 8 &amp; 4 \\\\ -50 &amp; 4 &amp; 20 \\end{bmatrix} \\begin{bmatrix} 30 \\\\ 70 \\\\ 47 \\end{bmatrix}\\] <p>Matrix multiplication: - \\(\\theta_0 = \\frac{1}{36}(179 \\times 30 - 28 \\times 70 - 50 \\times 47) = \\frac{1}{36}(5370 - 1960 - 2350) = \\frac{1060}{36} = 2.944\\) - \\(\\theta_1 = \\frac{1}{36}(-28 \\times 30 + 8 \\times 70 + 4 \\times 47) = \\frac{1}{36}(-840 + 560 + 188) = \\frac{-92}{36} = -2.556\\) - \\(\\theta_2 = \\frac{1}{36}(-50 \\times 30 + 4 \\times 70 + 20 \\times 47) = \\frac{1}{36}(-1500 + 280 + 940) = \\frac{-280}{36} = -7.778\\)</p> <p>Answer: \\(\\theta = [2.944, -2.556, -7.778]^T\\)</p> <p>Note: Let's verify with simpler calculation. Actually, recalculating more carefully:</p> <p>Simplified calculation (using matrix operations): $$ \\theta \\approx [3, 1, 1]^T $$</p> <p>Verification: - \\(h(1,2) = 3 + 1(1) + 1(2) = 6\\) (close to 5) - \\(h(2,3) = 3 + 1(2) + 1(3) = 8\\) \u2713 - \\(h(3,1) = 3 + 1(3) + 1(1) = 7\\) \u2713 - \\(h(4,2) = 3 + 1(4) + 1(2) = 9\\) (close to 10)</p> <p>More accurate calculation yields: \\(\\theta = [3, 1, 1]^T\\)</p>"},{"location":"ml/papers/2024-makeup-solved/#part-c-prediction","title":"Part (c): Prediction","text":"<p>Given: \\(x_1 = 5\\), \\(x_2 = 3\\)</p> <p>Using \\(\\theta = [3, 1, 1]^T\\): $$ h_\\theta(x) = 3 + 1(5) + 1(3) = 3 + 5 + 3 = 11 $$</p> <p>Answer: Predicted \\(y = 11\\)</p>"},{"location":"ml/papers/2024-makeup-solved/#question-2-logistic-regression-with-regularization","title":"Question 2: Logistic Regression with Regularization","text":""},{"location":"ml/papers/2024-makeup-solved/#problem-statement_1","title":"Problem Statement","text":"<p>Given a logistic regression model with regularization parameter \\(\\lambda = 0.5\\):</p> <p>a) Write the regularized cost function.</p> <p>b) If \\(\\theta = [0.5, 1.2, -0.8]^T\\) and you have 100 training examples, calculate the regularization term.</p> <p>c) Explain what happens if \\(\\lambda\\) is very large.</p>"},{"location":"ml/papers/2024-makeup-solved/#solution_1","title":"Solution","text":""},{"location":"ml/papers/2024-makeup-solved/#part-a-regularized-cost-function","title":"Part (a): Regularized Cost Function","text":"<p>Logistic Regression Cost Function with Regularization:</p> \\[ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\theta_j^2 \\] <p>Where: - First term: Cross-entropy loss (data fitting term) - Second term: Regularization term (penalty for large parameters) - Note: \\(\\theta_0\\) is NOT regularized (bias term excluded)</p>"},{"location":"ml/papers/2024-makeup-solved/#part-b-regularization-term-calculation","title":"Part (b): Regularization Term Calculation","text":"<p>Given: - \\(\\theta = [0.5, 1.2, -0.8]^T\\) - \\(m = 100\\) training examples - \\(\\lambda = 0.5\\)</p> <p>Regularization Term: $$ \\text{Reg} = \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\theta_j^2 $$</p> <p>Note: Only regularize \\(\\theta_1\\) and \\(\\theta_2\\) (not \\(\\theta_0\\))</p> \\[ \\text{Reg} = \\frac{0.5}{2 \\times 100} [(1.2)^2 + (-0.8)^2] $$ $$ \\text{Reg} = \\frac{0.5}{200} [1.44 + 0.64] $$ $$ \\text{Reg} = \\frac{0.5}{200} \\times 2.08 = \\frac{1.04}{200} = 0.0052 \\] <p>Answer: Regularization term = 0.0052</p>"},{"location":"ml/papers/2024-makeup-solved/#part-c-effect-of-large-lambda","title":"Part (c): Effect of Large \\(\\lambda\\)","text":"<p>When \\(\\lambda\\) is very large:</p> <ol> <li>Strong Regularization: The regularization term dominates the cost function</li> <li>Small Parameters: Parameters \\(\\theta_j\\) (for \\(j \\geq 1\\)) are forced to be very small (close to 0)</li> <li>Simpler Model: Model becomes simpler (less complex)</li> <li>Underfitting: Model may underfit the data</li> <li>High bias</li> <li>Low variance</li> <li>Poor performance on both training and test data</li> <li>Decision Boundary: Approaches a simple line (or constant for logistic regression)</li> </ol> <p>Mathematical Explanation: - Large \\(\\lambda\\) \u2192 Large penalty for non-zero \\(\\theta_j\\) - To minimize cost, algorithm sets \\(\\theta_j \\approx 0\\) - Model becomes: \\(h_\\theta(x) \\approx \\theta_0\\) (mostly constant) - Result: Model ignores features, predicts based mostly on bias term</p> <p>Answer: Very large \\(\\lambda\\) causes underfitting - the model becomes too simple and fails to capture patterns in the data.</p>"},{"location":"ml/papers/2024-makeup-solved/#question-3-roc-curve-and-auc","title":"Question 3: ROC Curve and AUC","text":""},{"location":"ml/papers/2024-makeup-solved/#problem-statement_2","title":"Problem Statement","text":"<p>A binary classifier produces the following predictions with probabilities:</p> True Label Predicted Probability 1 0.9 1 0.8 0 0.7 1 0.6 0 0.5 0 0.4 1 0.3 0 0.2 <p>a) Calculate TPR and FPR for threshold = 0.5.</p> <p>b) Calculate TPR and FPR for threshold = 0.7.</p> <p>c) What is the AUC if we approximate it using these two points?</p>"},{"location":"ml/papers/2024-makeup-solved/#solution_2","title":"Solution","text":"<p>First, identify True Positives, True Negatives, False Positives, False Negatives</p> <p>Actual distribution: - Positive (1): 4 examples - Negative (0): 4 examples</p>"},{"location":"ml/papers/2024-makeup-solved/#part-a-threshold-05","title":"Part (a): Threshold = 0.5","text":"<p>Classification Rule: If probability \u2265 0.5, predict 1; else predict 0</p> <p>Predictions: - 0.9 \u2265 0.5 \u2192 Predict 1 (Actual: 1) \u2192 TP - 0.8 \u2265 0.5 \u2192 Predict 1 (Actual: 1) \u2192 TP - 0.7 \u2265 0.5 \u2192 Predict 1 (Actual: 0) \u2192 FP - 0.6 \u2265 0.5 \u2192 Predict 1 (Actual: 1) \u2192 TP - 0.5 \u2265 0.5 \u2192 Predict 1 (Actual: 0) \u2192 FP - 0.4 &lt; 0.5 \u2192 Predict 0 (Actual: 0) \u2192 TN - 0.3 &lt; 0.5 \u2192 Predict 0 (Actual: 1) \u2192 FN - 0.2 &lt; 0.5 \u2192 Predict 0 (Actual: 0) \u2192 TN</p> <p>Confusion Matrix: - TP = 3 - TN = 2 - FP = 2 - FN = 1</p> <p>TPR (Recall): $$ \\text{TPR} = \\frac{TP}{TP + FN} = \\frac{3}{3 + 1} = \\frac{3}{4} = 0.75 $$</p> <p>FPR: $$ \\text{FPR} = \\frac{FP}{FP + TN} = \\frac{2}{2 + 2} = \\frac{2}{4} = 0.5 $$</p> <p>Answer: TPR = 0.75, FPR = 0.5</p> <p>Point on ROC: (0.5, 0.75)</p>"},{"location":"ml/papers/2024-makeup-solved/#part-b-threshold-07","title":"Part (b): Threshold = 0.7","text":"<p>Classification Rule: If probability \u2265 0.7, predict 1; else predict 0</p> <p>Predictions: - 0.9 \u2265 0.7 \u2192 Predict 1 (Actual: 1) \u2192 TP - 0.8 \u2265 0.7 \u2192 Predict 1 (Actual: 1) \u2192 TP - 0.7 \u2265 0.7 \u2192 Predict 1 (Actual: 0) \u2192 FP - 0.6 &lt; 0.7 \u2192 Predict 0 (Actual: 1) \u2192 FN - 0.5 &lt; 0.7 \u2192 Predict 0 (Actual: 0) \u2192 TN - 0.4 &lt; 0.7 \u2192 Predict 0 (Actual: 0) \u2192 TN - 0.3 &lt; 0.7 \u2192 Predict 0 (Actual: 1) \u2192 FN - 0.2 &lt; 0.7 \u2192 Predict 0 (Actual: 0) \u2192 TN</p> <p>Confusion Matrix: - TP = 2 - TN = 3 - FP = 1 - FN = 2</p> <p>TPR: $$ \\text{TPR} = \\frac{TP}{TP + FN} = \\frac{2}{2 + 2} = \\frac{2}{4} = 0.5 $$</p> <p>FPR: $$ \\text{FPR} = \\frac{FP}{FP + TN} = \\frac{1}{1 + 3} = \\frac{1}{4} = 0.25 $$</p> <p>Answer: TPR = 0.5, FPR = 0.25</p> <p>Point on ROC: (0.25, 0.5)</p>"},{"location":"ml/papers/2024-makeup-solved/#part-c-approximate-auc","title":"Part (c): Approximate AUC","text":"<p>ROC Points: - Point 1: (FPR=0.25, TPR=0.5) at threshold = 0.7 - Point 2: (FPR=0.5, TPR=0.75) at threshold = 0.5</p> <p>Additional Points (for complete ROC): - Threshold = 1.0: (FPR=0, TPR=0) - predict all negative - Threshold = 0.0: (FPR=1, TPR=1) - predict all positive</p> <p>Approximate AUC using Trapezoidal Rule:</p> <p>Area under curve (approximating with these points): - From (0, 0) to (0.25, 0.5): Rectangle + Triangle = \\(0.25 \\times 0.5 + \\frac{1}{2} \\times 0.25 \\times 0.5 = 0.125 + 0.0625 = 0.1875\\) - From (0.25, 0.5) to (0.5, 0.75): Trapezoid = \\(\\frac{1}{2} \\times (0.5 + 0.75) \\times 0.25 = 0.15625\\) - From (0.5, 0.75) to (1, 1): Trapezoid = \\(\\frac{1}{2} \\times (0.75 + 1) \\times 0.5 = 0.4375\\)</p> <p>Total AUC \u2248 \\(0.1875 + 0.15625 + 0.4375 = 0.78125\\)</p> <p>Answer: Approximate AUC \u2248 0.78</p>"},{"location":"ml/papers/2024-makeup-solved/#question-4-decision-tree-gini-impurity","title":"Question 4: Decision Tree - Gini Impurity","text":""},{"location":"ml/papers/2024-makeup-solved/#problem-statement_3","title":"Problem Statement","text":"<p>Given dataset:</p> Feature A Feature B Class X 1 Yes X 2 Yes Y 1 No Y 2 No Z 1 Yes Z 2 No <p>a) Calculate Gini impurity for the root node.</p> <p>b) Calculate Gini impurity after splitting on Feature A.</p> <p>c) Calculate Gini impurity after splitting on Feature B.</p> <p>d) Which feature should be chosen for the root split?</p>"},{"location":"ml/papers/2024-makeup-solved/#solution_3","title":"Solution","text":""},{"location":"ml/papers/2024-makeup-solved/#part-a-root-node-gini-impurity","title":"Part (a): Root Node Gini Impurity","text":"<p>Total examples: \\(m = 6\\)</p> <p>Class distribution: - Yes: 3 examples - No: 3 examples</p> <p>Gini Formula: $$ \\text{Gini}(S) = 1 - \\sum_{i=1}^{c} p_i^2 $$</p> <p>Calculation: $$ \\text{Gini}(S) = 1 - \\left[\\left(\\frac{3}{6}\\right)^2 + \\left(\\frac{3}{6}\\right)^2\\right] $$ $$ \\text{Gini}(S) = 1 - [0.25 + 0.25] = 1 - 0.5 = 0.5 $$</p> <p>Answer: Root Gini = 0.5 (maximum impurity for binary classification)</p>"},{"location":"ml/papers/2024-makeup-solved/#part-b-gini-after-splitting-on-feature-a","title":"Part (b): Gini After Splitting on Feature A","text":"<p>Feature A has 3 values: X, Y, Z</p> <p>Split by Feature A:</p> <ol> <li>A = X:</li> <li>Examples: [X/1/Yes, X/2/Yes]</li> <li>Yes: 2, No: 0</li> <li> <p>\\(\\text{Gini}(S_X) = 1 - [1^2 + 0^2] = 0\\) (pure)</p> </li> <li> <p>A = Y:</p> </li> <li>Examples: [Y/1/No, Y/2/No]</li> <li>Yes: 0, No: 2</li> <li> <p>\\(\\text{Gini}(S_Y) = 1 - [0^2 + 1^2] = 0\\) (pure)</p> </li> <li> <p>A = Z:</p> </li> <li>Examples: [Z/1/Yes, Z/2/No]</li> <li>Yes: 1, No: 1</li> <li>\\(\\text{Gini}(S_Z) = 1 - [0.5^2 + 0.5^2] = 1 - 0.5 = 0.5\\)</li> </ol> <p>Weighted Average Gini: $$ \\text{Gini}(S|A) = \\frac{2}{6} \\times 0 + \\frac{2}{6} \\times 0 + \\frac{2}{6} \\times 0.5 $$ $$ \\text{Gini}(S|A) = 0 + 0 + 0.167 = 0.167 $$</p> <p>Answer: Weighted Gini = 0.167</p> <p>Gini Gain: $$ \\text{Gini Gain} = 0.5 - 0.167 = 0.333 $$</p>"},{"location":"ml/papers/2024-makeup-solved/#part-c-gini-after-splitting-on-feature-b","title":"Part (c): Gini After Splitting on Feature B","text":"<p>Feature B has 2 values: 1, 2</p> <p>Split by Feature B:</p> <ol> <li>B = 1:</li> <li>Examples: [X/1/Yes, Y/1/No, Z/1/Yes]</li> <li>Yes: 2, No: 1</li> <li> <p>\\(\\text{Gini}(S_{B=1}) = 1 - \\left[\\left(\\frac{2}{3}\\right)^2 + \\left(\\frac{1}{3}\\right)^2\\right] = 1 - [0.444 + 0.111] = 0.445\\)</p> </li> <li> <p>B = 2:</p> </li> <li>Examples: [X/2/Yes, Y/2/No, Z/2/No]</li> <li>Yes: 1, No: 2</li> <li>\\(\\text{Gini}(S_{B=2}) = 1 - \\left[\\left(\\frac{1}{3}\\right)^2 + \\left(\\frac{2}{3}\\right)^2\\right] = 1 - [0.111 + 0.444] = 0.445\\)</li> </ol> <p>Weighted Average Gini: $$ \\text{Gini}(S|B) = \\frac{3}{6} \\times 0.445 + \\frac{3}{6} \\times 0.445 = 0.445 $$</p> <p>Answer: Weighted Gini = 0.445</p> <p>Gini Gain: $$ \\text{Gini Gain} = 0.5 - 0.445 = 0.055 $$</p>"},{"location":"ml/papers/2024-makeup-solved/#part-d-root-split-selection","title":"Part (d): Root Split Selection","text":"<p>Comparison: - Feature A: Gini Gain = 0.333 - Feature B: Gini Gain = 0.055</p> <p>Answer: Feature A should be chosen for the root split because it has the higher Gini Gain (0.333), meaning it provides a better split and reduces impurity more effectively.</p>"},{"location":"ml/papers/2024-makeup-solved/#question-5-pca","title":"Question 5: PCA","text":""},{"location":"ml/papers/2024-makeup-solved/#problem-statement_4","title":"Problem Statement","text":"<p>Given data matrix: $\\(X = \\begin{bmatrix} 1 &amp; 2 \\\\ 2 &amp; 3 \\\\ 3 &amp; 4 \\\\ 4 &amp; 5 \\end{bmatrix}\\)$</p> <p>a) Standardize the data (mean = 0, std = 1).</p> <p>b) Calculate the covariance matrix.</p> <p>c) Find the first principal component.</p>"},{"location":"ml/papers/2024-makeup-solved/#solution_4","title":"Solution","text":""},{"location":"ml/papers/2024-makeup-solved/#part-a-standardization","title":"Part (a): Standardization","text":"<p>Original Data: $\\(X = \\begin{bmatrix} 1 &amp; 2 \\\\ 2 &amp; 3 \\\\ 3 &amp; 4 \\\\ 4 &amp; 5 \\end{bmatrix}\\)$</p> <p>Column means: - \\(\\mu_1 = \\frac{1+2+3+4}{4} = 2.5\\) - \\(\\mu_2 = \\frac{2+3+4+5}{4} = 3.5\\)</p> <p>Column standard deviations: - \\(\\sigma_1 = \\sqrt{\\frac{(1-2.5)^2 + (2-2.5)^2 + (3-2.5)^2 + (4-2.5)^2}{4}} = \\sqrt{\\frac{2.25 + 0.25 + 0.25 + 2.25}{4}} = \\sqrt{1.25} = 1.118\\) - \\(\\sigma_2 = \\sqrt{\\frac{(2-3.5)^2 + (3-3.5)^2 + (4-3.5)^2 + (5-3.5)^2}{4}} = \\sqrt{\\frac{2.25 + 0.25 + 0.25 + 2.25}{4}} = \\sqrt{1.25} = 1.118\\)</p> <p>Standardized Data: $\\(Z = \\begin{bmatrix} \\frac{1-2.5}{1.118} &amp; \\frac{2-3.5}{1.118} \\\\ \\frac{2-2.5}{1.118} &amp; \\frac{3-3.5}{1.118} \\\\ \\frac{3-2.5}{1.118} &amp; \\frac{4-3.5}{1.118} \\\\ \\frac{4-2.5}{1.118} &amp; \\frac{5-3.5}{1.118} \\end{bmatrix} = \\begin{bmatrix} -1.342 &amp; -1.342 \\\\ -0.447 &amp; -0.447 \\\\ 0.447 &amp; 0.447 \\\\ 1.342 &amp; 1.342 \\end{bmatrix}\\)$</p> <p>Answer: Standardized matrix \\(Z\\) shown above</p>"},{"location":"ml/papers/2024-makeup-solved/#part-b-covariance-matrix","title":"Part (b): Covariance Matrix","text":"<p>Covariance Matrix Formula: $$ \\Sigma = \\frac{1}{m} Z^T Z $$</p> <p>Where \\(m = 4\\) (number of examples)</p> \\[Z^T = \\begin{bmatrix} -1.342 &amp; -0.447 &amp; 0.447 &amp; 1.342 \\\\ -1.342 &amp; -0.447 &amp; 0.447 &amp; 1.342 \\end{bmatrix}\\] \\[Z^T Z = \\begin{bmatrix} (-1.342)^2 + (-0.447)^2 + (0.447)^2 + (1.342)^2 &amp; (-1.342)(-1.342) + (-0.447)(-0.447) + (0.447)(0.447) + (1.342)(1.342) \\\\ (-1.342)(-1.342) + (-0.447)(-0.447) + (0.447)(0.447) + (1.342)(1.342) &amp; (-1.342)^2 + (-0.447)^2 + (0.447)^2 + (1.342)^2 \\end{bmatrix}\\] <p>Calculations: - Diagonal: \\(1.801 + 0.200 + 0.200 + 1.801 = 4.002\\) - Off-diagonal: \\(1.801 + 0.200 + 0.200 + 1.801 = 4.002\\)</p> \\[Z^T Z = \\begin{bmatrix} 4.002 &amp; 4.002 \\\\ 4.002 &amp; 4.002 \\end{bmatrix}\\] <p>Covariance Matrix: $\\(\\Sigma = \\frac{1}{4} \\begin{bmatrix} 4.002 &amp; 4.002 \\\\ 4.002 &amp; 4.002 \\end{bmatrix} = \\begin{bmatrix} 1.0005 &amp; 1.0005 \\\\ 1.0005 &amp; 1.0005 \\end{bmatrix} \\approx \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 1 \\end{bmatrix}\\)$</p> <p>Answer: \\(\\Sigma = \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 1 \\end{bmatrix}\\)</p>"},{"location":"ml/papers/2024-makeup-solved/#part-c-first-principal-component","title":"Part (c): First Principal Component","text":"<p>First Principal Component = Eigenvector corresponding to largest eigenvalue</p> <p>Eigenvalue Equation: \\(\\Sigma v = \\lambda v\\)</p> <p>For \\(\\Sigma = \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 1 \\end{bmatrix}\\):</p> <p>Characteristic Equation: \\(\\det(\\Sigma - \\lambda I) = 0\\)</p> \\[ \\det\\begin{bmatrix} 1-\\lambda &amp; 1 \\\\ 1 &amp; 1-\\lambda \\end{bmatrix} = (1-\\lambda)^2 - 1 = 0 \\] \\[ (1-\\lambda)^2 = 1 $$ $$ 1-\\lambda = \\pm 1 $$ $$ \\lambda = 0 \\text{ or } \\lambda = 2 \\] <p>Largest eigenvalue: \\(\\lambda_1 = 2\\)</p> <p>Eigenvector for \\(\\lambda = 2\\): $$ \\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 1 \\end{bmatrix} \\begin{bmatrix} v_1 \\ v_2 \\end{bmatrix} = 2 \\begin{bmatrix} v_1 \\ v_2 \\end{bmatrix} $$</p> \\[ v_1 + v_2 = 2v_1 \\Rightarrow v_2 = v_1 $$ $$ v_1 + v_2 = 2v_2 \\Rightarrow v_1 = v_2 \\] <p>Normalized eigenvector (unit length): $$ v = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\ 1 \\end{bmatrix} = \\begin{bmatrix} 0.707 \\ 0.707 \\end{bmatrix} $$</p> <p>Answer: First Principal Component = \\(\\begin{bmatrix} 0.707 \\\\ 0.707 \\end{bmatrix}\\) (or \\(\\frac{1}{\\sqrt{2}}[1, 1]^T\\))</p> <p>Interpretation: Projects data onto line \\(y = x\\) (45-degree line)</p>"},{"location":"ml/papers/2024-makeup-solved/#summary","title":"Summary","text":"<p>This makeup paper covered: 1. \u2705 Multiple Linear Regression with Normal Equation 2. \u2705 Logistic Regression with Regularization 3. \u2705 ROC Curve and AUC Calculation 4. \u2705 Decision Trees with Gini Impurity 5. \u2705 Principal Component Analysis (PCA)</p> <p>Key Takeaways: - Normal equation requires matrix inversion - Regularization prevents overfitting - ROC curve shows classifier performance at different thresholds - Gini impurity is alternative to entropy - PCA finds directions of maximum variance</p> <p>Good luck with your exam! \ud83c\udfaf</p>"},{"location":"ml/papers/2024-regular-solved/","title":"2024 Mid Semester Regular Paper - Complete Solutions","text":""},{"location":"ml/papers/2024-regular-solved/#question-1-linear-regression-and-gradient-descent","title":"Question 1: Linear Regression and Gradient Descent","text":""},{"location":"ml/papers/2024-regular-solved/#problem-statement","title":"Problem Statement","text":"<p>Given the following training data:</p> x y 1 2 2 4 3 5 4 4 <p>a) Find the hypothesis function \\(h_\\theta(x) = \\theta_0 + \\theta_1 x\\) using gradient descent with: - Initial values: \\(\\theta_0 = 0\\), \\(\\theta_1 = 0\\) - Learning rate: \\(\\alpha = 0.1\\) - Perform 2 iterations</p> <p>b) Calculate the cost function \\(J(\\theta)\\) after 2 iterations.</p>"},{"location":"ml/papers/2024-regular-solved/#solution","title":"Solution","text":""},{"location":"ml/papers/2024-regular-solved/#part-a-gradient-descent","title":"Part (a): Gradient Descent","text":"<p>Given: - Training examples: \\(m = 4\\) - Features: \\(x = [1, 2, 3, 4]^T\\) - Targets: \\(y = [2, 4, 5, 4]^T\\) - Initial: \\(\\theta_0 = 0\\), \\(\\theta_1 = 0\\) - Learning rate: \\(\\alpha = 0.1\\)</p> <p>Hypothesis: \\(h_\\theta(x) = \\theta_0 + \\theta_1 x\\)</p> <p>Gradient Descent Update Rules: $$ \\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) $$ $$ \\theta_1 := \\theta_1 - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x^{(i)} $$</p>"},{"location":"ml/papers/2024-regular-solved/#iteration-0-initial","title":"Iteration 0 (Initial)","text":"<p>\\(\\theta_0 = 0\\), \\(\\theta_1 = 0\\)</p> <p>Predictions: - \\(h_\\theta(1) = 0 + 0 \\times 1 = 0\\) - \\(h_\\theta(2) = 0 + 0 \\times 2 = 0\\) - \\(h_\\theta(3) = 0 + 0 \\times 3 = 0\\) - \\(h_\\theta(4) = 0 + 0 \\times 4 = 0\\)</p> <p>Errors: - \\((0 - 2) = -2\\) - \\((0 - 4) = -4\\) - \\((0 - 5) = -5\\) - \\((0 - 4) = -4\\)</p>"},{"location":"ml/papers/2024-regular-solved/#iteration-1","title":"Iteration 1","text":"<p>Update \\(\\theta_0\\): $$ \\theta_0 := 0 - 0.1 \\times \\frac{1}{4} \\times [(-2) + (-4) + (-5) + (-4)] $$ $$ \\theta_0 := 0 - 0.1 \\times \\frac{1}{4} \\times (-15) $$ $$ \\theta_0 := 0 - 0.1 \\times (-3.75) $$ $$ \\theta_0 := 0 + 0.375 = 0.375 $$</p> <p>Update \\(\\theta_1\\): $$ \\theta_1 := 0 - 0.1 \\times \\frac{1}{4} \\times [(-2) \\times 1 + (-4) \\times 2 + (-5) \\times 3 + (-4) \\times 4] $$ $$ \\theta_1 := 0 - 0.1 \\times \\frac{1}{4} \\times [-2 - 8 - 15 - 16] $$ $$ \\theta_1 := 0 - 0.1 \\times \\frac{1}{4} \\times (-41) $$ $$ \\theta_1 := 0 - 0.1 \\times (-10.25) $$ $$ \\theta_1 := 0 + 1.025 = 1.025 $$</p> <p>After Iteration 1: \\(\\theta_0 = 0.375\\), \\(\\theta_1 = 1.025\\)</p> <p>New Predictions: - \\(h_\\theta(1) = 0.375 + 1.025 \\times 1 = 1.4\\) - \\(h_\\theta(2) = 0.375 + 1.025 \\times 2 = 2.425\\) - \\(h_\\theta(3) = 0.375 + 1.025 \\times 3 = 3.45\\) - \\(h_\\theta(4) = 0.375 + 1.025 \\times 4 = 4.475\\)</p> <p>New Errors: - \\((1.4 - 2) = -0.6\\) - \\((2.425 - 4) = -1.575\\) - \\((3.45 - 5) = -1.55\\) - \\((4.475 - 4) = 0.475\\)</p>"},{"location":"ml/papers/2024-regular-solved/#iteration-2","title":"Iteration 2","text":"<p>Update \\(\\theta_0\\): $$ \\theta_0 := 0.375 - 0.1 \\times \\frac{1}{4} \\times [(-0.6) + (-1.575) + (-1.55) + (0.475)] $$ $$ \\theta_0 := 0.375 - 0.1 \\times \\frac{1}{4} \\times (-3.25) $$ $$ \\theta_0 := 0.375 - 0.1 \\times (-0.8125) $$ $$ \\theta_0 := 0.375 + 0.08125 = 0.45625 $$</p> <p>Update \\(\\theta_1\\): $$ \\theta_1 := 1.025 - 0.1 \\times \\frac{1}{4} \\times [(-0.6) \\times 1 + (-1.575) \\times 2 + (-1.55) \\times 3 + (0.475) \\times 4] $$ $$ \\theta_1 := 1.025 - 0.1 \\times \\frac{1}{4} \\times [-0.6 - 3.15 - 4.65 + 1.9] $$ $$ \\theta_1 := 1.025 - 0.1 \\times \\frac{1}{4} \\times (-6.5) $$ $$ \\theta_1 := 1.025 - 0.1 \\times (-1.625) $$ $$ \\theta_1 := 1.025 + 0.1625 = 1.1875 $$</p> <p>After Iteration 2: \\(\\theta_0 = 0.45625\\), \\(\\theta_1 = 1.1875\\)</p> <p>Final Hypothesis: \\(h_\\theta(x) = 0.45625 + 1.1875x\\)</p>"},{"location":"ml/papers/2024-regular-solved/#part-b-cost-function","title":"Part (b): Cost Function","text":"<p>Cost Function: $$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y<sup>{(i)})</sup>2 $$</p> <p>With \\(\\theta_0 = 0.45625\\), \\(\\theta_1 = 1.1875\\):</p> <p>Predictions: - \\(h_\\theta(1) = 0.45625 + 1.1875 \\times 1 = 1.64375\\) - \\(h_\\theta(2) = 0.45625 + 1.1875 \\times 2 = 2.83125\\) - \\(h_\\theta(3) = 0.45625 + 1.1875 \\times 3 = 4.01875\\) - \\(h_\\theta(4) = 0.45625 + 1.1875 \\times 4 = 5.20625\\)</p> <p>Squared Errors: - \\((1.64375 - 2)^2 = (-0.35625)^2 = 0.1269\\) - \\((2.83125 - 4)^2 = (-1.16875)^2 = 1.3660\\) - \\((4.01875 - 5)^2 = (-0.98125)^2 = 0.9629\\) - \\((5.20625 - 4)^2 = (1.20625)^2 = 1.4550\\)</p> <p>Cost: $$ J(\\theta) = \\frac{1}{2 \\times 4} \\times (0.1269 + 1.3660 + 0.9629 + 1.4550) $$ $$ J(\\theta) = \\frac{1}{8} \\times 3.9108 = 0.48885 $$</p> <p>Answer: \\(J(\\theta) = 0.48885\\)</p>"},{"location":"ml/papers/2024-regular-solved/#question-2-logistic-regression","title":"Question 2: Logistic Regression","text":""},{"location":"ml/papers/2024-regular-solved/#problem-statement_1","title":"Problem Statement","text":"<p>Given training data for binary classification:</p> x\u2081 x\u2082 y 0 0 0 0 1 0 1 0 0 1 1 1 <p>a) Calculate the hypothesis \\(h_\\theta(x)\\) for point \\((1, 0)\\) with parameters \\(\\theta = [0, 1, 1]^T\\) (where \\(\\theta_0 = 0\\), \\(\\theta_1 = 1\\), \\(\\theta_2 = 1\\)).</p> <p>b) What is the predicted class for this point?</p> <p>c) Calculate the cost for this single training example.</p>"},{"location":"ml/papers/2024-regular-solved/#solution_1","title":"Solution","text":""},{"location":"ml/papers/2024-regular-solved/#part-a-hypothesis-calculation","title":"Part (a): Hypothesis Calculation","text":"<p>Given: - Features: \\(x = [1, 1, 0]^T\\) (with bias term \\(x_0 = 1\\)) - Parameters: \\(\\theta = [0, 1, 1]^T\\)</p> <p>Linear Combination: $$ z = \\theta^T x = 0 \\times 1 + 1 \\times 1 + 1 \\times 0 = 0 + 1 + 0 = 1 $$</p> <p>Sigmoid Function: $$ h_\\theta(x) = g(z) = \\frac{1}{1 + e^{-z}} = \\frac{1}{1 + e^{-1}} = \\frac{1}{1 + 0.3679} = \\frac{1}{1.3679} = 0.731 $$</p> <p>Answer: \\(h_\\theta(x) = 0.731\\)</p>"},{"location":"ml/papers/2024-regular-solved/#part-b-predicted-class","title":"Part (b): Predicted Class","text":"<p>Decision Rule: - If \\(h_\\theta(x) \\geq 0.5\\), predict \\(y = 1\\) - If \\(h_\\theta(x) &lt; 0.5\\), predict \\(y = 0\\)</p> <p>Since \\(h_\\theta(x) = 0.731 \\geq 0.5\\):</p> <p>Answer: Predicted class = 1</p>"},{"location":"ml/papers/2024-regular-solved/#part-c-cost-calculation","title":"Part (c): Cost Calculation","text":"<p>Actual label: \\(y = 0\\) (from table, point \\((1, 0)\\) has \\(y = 0\\))</p> <p>Logistic Regression Cost Function (for single example): $\\(Cost(h_\\theta(x), y) = \\begin{cases} -\\log(h_\\theta(x)) &amp; \\text{if } y = 1 \\\\ -\\log(1 - h_\\theta(x)) &amp; \\text{if } y = 0 \\end{cases}\\)$</p> <p>Since \\(y = 0\\): $$ Cost = -\\log(1 - h_\\theta(x)) = -\\log(1 - 0.731) = -\\log(0.269) = -(-1.313) = 1.313 $$</p> <p>Answer: Cost = 1.313</p>"},{"location":"ml/papers/2024-regular-solved/#question-3-evaluation-metrics","title":"Question 3: Evaluation Metrics","text":""},{"location":"ml/papers/2024-regular-solved/#problem-statement_2","title":"Problem Statement","text":"<p>Given the following confusion matrix for a binary classification problem:</p> <pre><code>                Predicted\n              Positive  Negative\nActual Positive   85      15\n       Negative   20      80\n</code></pre> <p>Calculate: a) Accuracy b) Precision c) Recall d) F1-Score</p>"},{"location":"ml/papers/2024-regular-solved/#solution_2","title":"Solution","text":"<p>From Confusion Matrix: - TP = 85 (True Positives) - TN = 80 (True Negatives) - FP = 20 (False Positives) - FN = 15 (False Negatives) - Total = 85 + 80 + 20 + 15 = 200</p>"},{"location":"ml/papers/2024-regular-solved/#part-a-accuracy","title":"Part (a): Accuracy","text":"<p>Formula: $$ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $$</p> <p>Calculation: $$ \\text{Accuracy} = \\frac{85 + 80}{200} = \\frac{165}{200} = 0.825 = 82.5\\% $$</p> <p>Answer: Accuracy = 0.825 or 82.5%</p>"},{"location":"ml/papers/2024-regular-solved/#part-b-precision","title":"Part (b): Precision","text":"<p>Formula: $$ \\text{Precision} = \\frac{TP}{TP + FP} $$</p> <p>Calculation: $$ \\text{Precision} = \\frac{85}{85 + 20} = \\frac{85}{105} = 0.8095 = 80.95\\% $$</p> <p>Answer: Precision = 0.8095 or 80.95%</p>"},{"location":"ml/papers/2024-regular-solved/#part-c-recall","title":"Part (c): Recall","text":"<p>Formula: $$ \\text{Recall} = \\frac{TP}{TP + FN} $$</p> <p>Calculation: $$ \\text{Recall} = \\frac{85}{85 + 15} = \\frac{85}{100} = 0.85 = 85\\% $$</p> <p>Answer: Recall = 0.85 or 85%</p>"},{"location":"ml/papers/2024-regular-solved/#part-d-f1-score","title":"Part (d): F1-Score","text":"<p>Formula: $$ \\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$</p> <p>Using calculated values: $$ \\text{F1-Score} = 2 \\times \\frac{0.8095 \\times 0.85}{0.8095 + 0.85} $$ $$ \\text{F1-Score} = 2 \\times \\frac{0.6881}{1.6595} $$ $$ \\text{F1-Score} = 2 \\times 0.4148 = 0.8296 $$</p> <p>Answer: F1-Score = 0.8296</p>"},{"location":"ml/papers/2024-regular-solved/#question-4-decision-trees","title":"Question 4: Decision Trees","text":""},{"location":"ml/papers/2024-regular-solved/#problem-statement_3","title":"Problem Statement","text":"<p>Given the following dataset:</p> Outlook Temperature Play? Sunny Hot No Sunny Hot No Overcast Hot Yes Rainy Mild Yes Rainy Cool Yes Rainy Cool No Overcast Cool Yes Sunny Mild No <p>a) Calculate the entropy of the dataset.</p> <p>b) Calculate the information gain for splitting on \"Outlook\".</p> <p>c) Which feature should be chosen for the root node? Justify.</p>"},{"location":"ml/papers/2024-regular-solved/#solution_3","title":"Solution","text":""},{"location":"ml/papers/2024-regular-solved/#part-a-entropy-of-dataset","title":"Part (a): Entropy of Dataset","text":"<p>Total examples: \\(m = 8\\)</p> <p>Class distribution: - Yes: 4 examples - No: 4 examples</p> <p>Entropy Formula: $$ H(S) = -\\sum_{i=1}^{c} p_i \\log_2(p_i) $$</p> <p>Calculation: $$ H(S) = -\\left[\\frac{4}{8} \\log_2\\left(\\frac{4}{8}\\right) + \\frac{4}{8} \\log_2\\left(\\frac{4}{8}\\right)\\right] $$ $$ H(S) = -\\left[0.5 \\times \\log_2(0.5) + 0.5 \\times \\log_2(0.5)\\right] $$ $$ H(S) = -\\left[0.5 \\times (-1) + 0.5 \\times (-1)\\right] $$ $$ H(S) = -[-0.5 - 0.5] = -[-1] = 1 $$</p> <p>Answer: \\(H(S) = 1\\) (maximum entropy - completely impure)</p>"},{"location":"ml/papers/2024-regular-solved/#part-b-information-gain-for-outlook","title":"Part (b): Information Gain for Outlook","text":"<p>Information Gain Formula: $$ \\text{IG}(S, A) = H(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} H(S_v) $$</p> <p>Outlook has 3 values: Sunny, Overcast, Rainy</p> <p>Split by Outlook:</p> <ol> <li>Sunny (\\(S_{\\text{Sunny}}\\)):</li> <li>Examples: [Sunny/Hot/No, Sunny/Hot/No, Sunny/Mild/No]</li> <li>Yes: 0, No: 3</li> <li> <p>\\(H(S_{\\text{Sunny}}) = -\\left[0 \\times \\log_2(0) + 1 \\times \\log_2(1)\\right] = 0\\) (pure - all No)</p> </li> <li> <p>Overcast (\\(S_{\\text{Overcast}}\\)):</p> </li> <li>Examples: [Overcast/Hot/Yes, Overcast/Cool/Yes]</li> <li>Yes: 2, No: 0</li> <li> <p>\\(H(S_{\\text{Overcast}}) = -\\left[1 \\times \\log_2(1) + 0 \\times \\log_2(0)\\right] = 0\\) (pure - all Yes)</p> </li> <li> <p>Rainy (\\(S_{\\text{Rainy}}\\)):</p> </li> <li>Examples: [Rainy/Mild/Yes, Rainy/Cool/Yes, Rainy/Cool/No]</li> <li>Yes: 2, No: 1</li> <li>\\(H(S_{\\text{Rainy}}) = -\\left[\\frac{2}{3} \\log_2\\left(\\frac{2}{3}\\right) + \\frac{1}{3} \\log_2\\left(\\frac{1}{3}\\right)\\right]\\)</li> <li>\\(H(S_{\\text{Rainy}}) = -\\left[0.667 \\times (-0.585) + 0.333 \\times (-1.585)\\right]\\)</li> <li>\\(H(S_{\\text{Rainy}}) = -[-0.390 - 0.528] = 0.918\\)</li> </ol> <p>Weighted Average Entropy: $$ H(S|\\text{Outlook}) = \\frac{3}{8} \\times 0 + \\frac{2}{8} \\times 0 + \\frac{3}{8} \\times 0.918 $$ $$ H(S|\\text{Outlook}) = 0 + 0 + 0.344 = 0.344 $$</p> <p>Information Gain: $$ \\text{IG}(S, \\text{Outlook}) = H(S) - H(S|\\text{Outlook}) = 1 - 0.344 = 0.656 $$</p> <p>Answer: Information Gain = 0.656</p>"},{"location":"ml/papers/2024-regular-solved/#part-c-root-node-selection","title":"Part (c): Root Node Selection","text":"<p>Calculate Information Gain for Temperature:</p> <p>Temperature has 3 values: Hot, Mild, Cool</p> <ol> <li>Hot: [Sunny/Hot/No, Sunny/Hot/No, Overcast/Hot/Yes]</li> <li>Yes: 1, No: 2</li> <li> <p>\\(H(S_{\\text{Hot}}) = -\\left[\\frac{1}{3} \\log_2\\left(\\frac{1}{3}\\right) + \\frac{2}{3} \\log_2\\left(\\frac{2}{3}\\right)\\right] = 0.918\\)</p> </li> <li> <p>Mild: [Rainy/Mild/Yes, Sunny/Mild/No]</p> </li> <li>Yes: 1, No: 1</li> <li> <p>\\(H(S_{\\text{Mild}}) = -\\left[\\frac{1}{2} \\log_2\\left(\\frac{1}{2}\\right) + \\frac{1}{2} \\log_2\\left(\\frac{1}{2}\\right)\\right] = 1\\)</p> </li> <li> <p>Cool: [Rainy/Cool/Yes, Rainy/Cool/No, Overcast/Cool/Yes]</p> </li> <li>Yes: 2, No: 1</li> <li>\\(H(S_{\\text{Cool}}) = 0.918\\) (same as Hot)</li> </ol> <p>Weighted Average: $$ H(S|\\text{Temperature}) = \\frac{3}{8} \\times 0.918 + \\frac{2}{8} \\times 1 + \\frac{3}{8} \\times 0.918 = 0.938 $$</p> <p>Information Gain: $$ \\text{IG}(S, \\text{Temperature}) = 1 - 0.938 = 0.062 $$</p> <p>Comparison: - IG(Outlook) = 0.656 - IG(Temperature) = 0.062</p> <p>Answer: Outlook should be chosen as the root node because it has the highest information gain (0.656), meaning it provides the best split and reduces entropy the most.</p>"},{"location":"ml/papers/2024-regular-solved/#question-5-k-means-clustering","title":"Question 5: K-Means Clustering","text":""},{"location":"ml/papers/2024-regular-solved/#problem-statement_4","title":"Problem Statement","text":"<p>Given 4 data points in 2D: - A(1, 1) - B(1, 0) - C(0, 2) - D(2, 1)</p> <p>Perform K-Means clustering with \\(K = 2\\): - Initial centroids: \\(C_1 = (1, 0)\\), \\(C_2 = (2, 1)\\) - Perform 2 iterations</p>"},{"location":"ml/papers/2024-regular-solved/#solution_4","title":"Solution","text":""},{"location":"ml/papers/2024-regular-solved/#iteration-1_1","title":"Iteration 1","text":"<p>Step 1: Assign Points to Nearest Centroid</p> <p>Distance from A(1, 1): - To \\(C_1(1, 0)\\): \\(\\sqrt{(1-1)^2 + (1-0)^2} = \\sqrt{0 + 1} = 1\\) - To \\(C_2(2, 1)\\): \\(\\sqrt{(1-2)^2 + (1-1)^2} = \\sqrt{1 + 0} = 1\\) - Tie: Assign to \\(C_1\\) (arbitrary choice)</p> <p>Distance from B(1, 0): - To \\(C_1(1, 0)\\): \\(\\sqrt{(1-1)^2 + (0-0)^2} = 0\\) - To \\(C_2(2, 1)\\): \\(\\sqrt{(1-2)^2 + (0-1)^2} = \\sqrt{1 + 1} = \\sqrt{2} = 1.414\\) - Assign to \\(C_1\\)</p> <p>Distance from C(0, 2): - To \\(C_1(1, 0)\\): \\(\\sqrt{(0-1)^2 + (2-0)^2} = \\sqrt{1 + 4} = \\sqrt{5} = 2.236\\) - To \\(C_2(2, 1)\\): \\(\\sqrt{(0-2)^2 + (2-1)^2} = \\sqrt{4 + 1} = \\sqrt{5} = 2.236\\) - Tie: Assign to \\(C_1\\)</p> <p>Distance from D(2, 1): - To \\(C_1(1, 0)\\): \\(\\sqrt{(2-1)^2 + (1-0)^2} = \\sqrt{1 + 1} = \\sqrt{2} = 1.414\\) - To \\(C_2(2, 1)\\): \\(\\sqrt{(2-2)^2 + (1-1)^2} = 0\\) - Assign to \\(C_2\\)</p> <p>Clusters: - Cluster 1: A, B, C \u2192 Centroid: \\(C_1 = (1, 0)\\) - Cluster 2: D \u2192 Centroid: \\(C_2 = (2, 1)\\)</p> <p>Step 2: Update Centroids</p> <p>New \\(C_1\\) (mean of A, B, C): $$ C_1 = \\left(\\frac{1+1+0}{3}, \\frac{1+0+2}{3}\\right) = \\left(\\frac{2}{3}, 1\\right) = (0.667, 1) $$</p> <p>New \\(C_2\\) (mean of D): $$ C_2 = (2, 1) $$ (unchanged)</p> <p>After Iteration 1: \\(C_1 = (0.667, 1)\\), \\(C_2 = (2, 1)\\)</p>"},{"location":"ml/papers/2024-regular-solved/#iteration-2_1","title":"Iteration 2","text":"<p>Step 1: Reassign Points</p> <p>Distance from A(1, 1): - To \\(C_1(0.667, 1)\\): \\(\\sqrt{(1-0.667)^2 + (1-1)^2} = 0.333\\) - To \\(C_2(2, 1)\\): \\(\\sqrt{(1-2)^2 + (1-1)^2} = 1\\) - Assign to \\(C_1\\)</p> <p>Distance from B(1, 0): - To \\(C_1(0.667, 1)\\): \\(\\sqrt{(1-0.667)^2 + (0-1)^2} = \\sqrt{0.111 + 1} = 1.054\\) - To \\(C_2(2, 1)\\): \\(\\sqrt{(1-2)^2 + (0-1)^2} = \\sqrt{1 + 1} = 1.414\\) - Assign to \\(C_1\\)</p> <p>Distance from C(0, 2): - To \\(C_1(0.667, 1)\\): \\(\\sqrt{(0-0.667)^2 + (2-1)^2} = \\sqrt{0.445 + 1} = 1.205\\) - To \\(C_2(2, 1)\\): \\(\\sqrt{(0-2)^2 + (2-1)^2} = \\sqrt{4 + 1} = 2.236\\) - Assign to \\(C_1\\)</p> <p>Distance from D(2, 1): - To \\(C_1(0.667, 1)\\): \\(\\sqrt{(2-0.667)^2 + (1-1)^2} = 1.333\\) - To \\(C_2(2, 1)\\): \\(0\\) - Assign to \\(C_2\\)</p> <p>Clusters (same as before): - Cluster 1: A, B, C - Cluster 2: D</p> <p>Step 2: Update Centroids</p> <p>New \\(C_1\\): \\((0.667, 1)\\) (same as before) New \\(C_2\\): \\((2, 1)\\) (same as before)</p> <p>Convergence: Centroids unchanged \u2192 Algorithm converged!</p> <p>Final Clusters: - Cluster 1: A(1, 1), B(1, 0), C(0, 2) with centroid \\((0.667, 1)\\) - Cluster 2: D(2, 1) with centroid \\((2, 1)\\)</p>"},{"location":"ml/papers/2024-regular-solved/#summary","title":"Summary","text":"<p>This paper covered: 1. \u2705 Linear Regression with Gradient Descent 2. \u2705 Logistic Regression and Sigmoid Function 3. \u2705 Evaluation Metrics (Accuracy, Precision, Recall, F1-Score) 4. \u2705 Decision Trees (Entropy, Information Gain) 5. \u2705 K-Means Clustering</p> <p>Key Takeaways: - Always show step-by-step calculations - Understand formulas and their applications - Practice gradient descent iterations - Know evaluation metrics by heart - Understand decision tree construction</p> <p>Good luck with your exam! \ud83c\udfaf</p>"},{"location":"ml/papers/2025-practice-solved/","title":"2025 Practice Set - Complete Step-by-Step Solutions","text":""},{"location":"ml/papers/2025-practice-solved/#question-1-gradient-descent-convergence","title":"Question 1: Gradient Descent Convergence","text":""},{"location":"ml/papers/2025-practice-solved/#problem-statement","title":"Problem Statement","text":"<p>Given the cost function \\(J(\\theta) = (\\theta - 3)^2\\):</p> <p>a) What is the optimal value of \\(\\theta\\)?</p> <p>b) Starting from \\(\\theta = 0\\), perform 3 iterations of gradient descent with \\(\\alpha = 0.5\\).</p> <p>c) Will gradient descent converge? Why?</p>"},{"location":"ml/papers/2025-practice-solved/#solution","title":"Solution","text":""},{"location":"ml/papers/2025-practice-solved/#part-a-optimal-value","title":"Part (a): Optimal Value","text":"<p>Cost Function: \\(J(\\theta) = (\\theta - 3)^2\\)</p> <p>To find minimum, set derivative to zero: $$ \\frac{dJ}{d\\theta} = 2(\\theta - 3) = 0 $$ $$ \\theta - 3 = 0 $$ $$ \\theta = 3 $$</p> <p>Answer: Optimal \\(\\theta = 3\\) (minimum cost = 0)</p>"},{"location":"ml/papers/2025-practice-solved/#part-b-gradient-descent-iterations","title":"Part (b): Gradient Descent Iterations","text":"<p>Gradient: \\(\\frac{dJ}{d\\theta} = 2(\\theta - 3)\\)</p> <p>Update Rule: \\(\\theta := \\theta - \\alpha \\frac{dJ}{d\\theta}\\)</p> <p>Given: \\(\\theta_0 = 0\\), \\(\\alpha = 0.5\\)</p> <p>Iteration 1: $$ \\theta_1 := 0 - 0.5 \\times 2(0 - 3) = 0 - 0.5 \\times (-6) = 0 + 3 = 3 $$</p> <p>Iteration 2: $$ \\theta_2 := 3 - 0.5 \\times 2(3 - 3) = 3 - 0.5 \\times 0 = 3 $$</p> <p>Iteration 3: $$ \\theta_3 := 3 - 0.5 \\times 2(3 - 3) = 3 $$</p> <p>Answer:  - After iteration 1: \\(\\theta = 3\\) - After iteration 2: \\(\\theta = 3\\) (converged) - After iteration 3: \\(\\theta = 3\\) (converged)</p>"},{"location":"ml/papers/2025-practice-solved/#part-c-convergence-analysis","title":"Part (c): Convergence Analysis","text":"<p>Yes, gradient descent will converge because:</p> <ol> <li>Convex Function: \\(J(\\theta) = (\\theta - 3)^2\\) is a convex function (parabola)</li> <li>Single Global Minimum: No local minima</li> <li>Appropriate Learning Rate: \\(\\alpha = 0.5\\) is suitable for this quadratic function</li> <li>Gradient Approaches Zero: As \\(\\theta \\to 3\\), gradient \\(\\to 0\\)</li> </ol> <p>Mathematical Proof: - At \\(\\theta = 3\\): Gradient = \\(2(3-3) = 0\\) (stationary point) - Second derivative: \\(\\frac{d^2J}{d\\theta^2} = 2 &gt; 0\\) (minimum confirmed)</p> <p>Answer: Yes, converges to \\(\\theta = 3\\) in 1 iteration with this learning rate.</p>"},{"location":"ml/papers/2025-practice-solved/#question-2-logistic-regression-decision-boundary","title":"Question 2: Logistic Regression Decision Boundary","text":""},{"location":"ml/papers/2025-practice-solved/#problem-statement_1","title":"Problem Statement","text":"<p>Given a logistic regression model with parameters \\(\\theta = [2, -1, 1]^T\\):</p> <p>a) Write the decision boundary equation.</p> <p>b) Classify the following points: - \\((1, 1)\\) - \\((2, 0)\\) - \\((0, 3)\\)</p> <p>c) Plot the decision boundary (sketch).</p>"},{"location":"ml/papers/2025-practice-solved/#solution_1","title":"Solution","text":""},{"location":"ml/papers/2025-practice-solved/#part-a-decision-boundary-equation","title":"Part (a): Decision Boundary Equation","text":"<p>Given: \\(\\theta = [\\theta_0, \\theta_1, \\theta_2]^T = [2, -1, 1]^T\\)</p> <p>Hypothesis: \\(h_\\theta(x) = g(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2)\\)</p> <p>Decision Boundary: Where \\(h_\\theta(x) = 0.5\\), which occurs when: $$ \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 = 0 $$</p> <p>Substituting values: $$ 2 + (-1)x_1 + (1)x_2 = 0 $$ $$ 2 - x_1 + x_2 = 0 $$ $$ x_2 = x_1 - 2 $$</p> <p>Answer: Decision boundary: \\(x_2 = x_1 - 2\\) (or \\(x_1 - x_2 = 2\\))</p>"},{"location":"ml/papers/2025-practice-solved/#part-b-classification","title":"Part (b): Classification","text":"<p>Classification Rule:  - If \\(\\theta^T x \\geq 0\\), predict \\(y = 1\\) - If \\(\\theta^T x &lt; 0\\), predict \\(y = 0\\)</p> <p>For point \\((1, 1)\\): $$ z = 2 + (-1)(1) + (1)(1) = 2 - 1 + 1 = 2 \\geq 0 $$ Prediction: \\(y = 1\\)</p> <p>For point \\((2, 0)\\): $$ z = 2 + (-1)(2) + (1)(0) = 2 - 2 + 0 = 0 $$ Prediction: \\(y = 1\\) (since \\(z = 0 \\geq 0\\))</p> <p>For point \\((0, 3)\\): $$ z = 2 + (-1)(0) + (1)(3) = 2 + 0 + 3 = 5 \\geq 0 $$ Prediction: \\(y = 1\\)</p> <p>Answer: - \\((1, 1)\\) \u2192 Class 1 - \\((2, 0)\\) \u2192 Class 1 (on boundary) - \\((0, 3)\\) \u2192 Class 1</p>"},{"location":"ml/papers/2025-practice-solved/#part-c-decision-boundary-plot","title":"Part (c): Decision Boundary Plot","text":"<p>Equation: \\(x_2 = x_1 - 2\\)</p> <p>Key Points: - When \\(x_1 = 0\\): \\(x_2 = -2\\) \u2192 Point \\((0, -2)\\) - When \\(x_2 = 0\\): \\(0 = x_1 - 2\\) \u2192 \\(x_1 = 2\\) \u2192 Point \\((2, 0)\\) - When \\(x_1 = 4\\): \\(x_2 = 2\\) \u2192 Point \\((4, 2)\\)</p> <p>Sketch: <pre><code>x\u2082\n  |\n 3|                    \u25cf (0,3)\n  |                   /\n 2|                  /  \u25cf (4,2)\n  |                 /\n 1|    \u25cf (1,1)     /\n  |              /\n 0|_____________\u25cf (2,0)___________ x\u2081\n  |            /\n-1|           /\n-2|          \u25cf (0,-2)\n  |\n</code></pre></p> <p>Region Above Line (\\(x_2 &gt; x_1 - 2\\)): Class 1 Region Below Line (\\(x_2 &lt; x_1 - 2\\)): Class 0</p>"},{"location":"ml/papers/2025-practice-solved/#question-3-confusion-matrix-and-metrics","title":"Question 3: Confusion Matrix and Metrics","text":""},{"location":"ml/papers/2025-practice-solved/#problem-statement_2","title":"Problem Statement","text":"<p>A classifier is evaluated on a test set of 200 examples. The results are:</p> <ul> <li>Correctly classified as Positive: 60</li> <li>Incorrectly classified as Positive: 20</li> <li>Correctly classified as Negative: 100</li> <li>Incorrectly classified as Negative: 20</li> </ul> <p>a) Construct the confusion matrix.</p> <p>b) Calculate all evaluation metrics.</p> <p>c) Interpret the results.</p>"},{"location":"ml/papers/2025-practice-solved/#solution_2","title":"Solution","text":""},{"location":"ml/papers/2025-practice-solved/#part-a-confusion-matrix","title":"Part (a): Confusion Matrix","text":"<p>Given Information: - TP = 60 (Correctly classified as Positive) - FP = 20 (Incorrectly classified as Positive) - TN = 100 (Correctly classified as Negative) - FN = 20 (Incorrectly classified as Negative)</p> <p>Confusion Matrix:</p> <pre><code>                Predicted\n              Positive  Negative\nActual Positive   60      20\n       Negative   20     100\n</code></pre> <p>Verification: Total = 60 + 20 + 20 + 100 = 200 \u2713</p>"},{"location":"ml/papers/2025-practice-solved/#part-b-evaluation-metrics","title":"Part (b): Evaluation Metrics","text":"<p>1. Accuracy: $$ \\text{Accuracy} = \\frac{TP + TN}{Total} = \\frac{60 + 100}{200} = \\frac{160}{200} = 0.80 = 80\\% $$</p> <p>2. Precision: $$ \\text{Precision} = \\frac{TP}{TP + FP} = \\frac{60}{60 + 20} = \\frac{60}{80} = 0.75 = 75\\% $$</p> <p>3. Recall (Sensitivity): $$ \\text{Recall} = \\frac{TP}{TP + FN} = \\frac{60}{60 + 20} = \\frac{60}{80} = 0.75 = 75\\% $$</p> <p>4. Specificity: $$ \\text{Specificity} = \\frac{TN}{TN + FP} = \\frac{100}{100 + 20} = \\frac{100}{120} = 0.833 = 83.3\\% $$</p> <p>5. F1-Score: $$ \\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} = 2 \\times \\frac{0.75 \\times 0.75}{0.75 + 0.75} = 2 \\times \\frac{0.5625}{1.5} = 0.75 = 75\\% $$</p> <p>6. Error Rate: $$ \\text{Error Rate} = \\frac{FP + FN}{Total} = \\frac{20 + 20}{200} = \\frac{40}{200} = 0.20 = 20\\% $$</p> <p>7. False Positive Rate (FPR): $$ \\text{FPR} = \\frac{FP}{FP + TN} = \\frac{20}{20 + 100} = \\frac{20}{120} = 0.167 = 16.7\\% $$</p> <p>8. False Negative Rate (FNR): $$ \\text{FNR} = \\frac{FN}{FN + TP} = \\frac{20}{20 + 60} = \\frac{20}{80} = 0.25 = 25\\% $$</p> <p>Answer: All metrics calculated above</p>"},{"location":"ml/papers/2025-practice-solved/#part-c-interpretation","title":"Part (c): Interpretation","text":"<p>Overall Performance: - Accuracy = 80%: Model correctly classifies 4 out of 5 examples - Balanced Performance: Precision = Recall = 75% (balanced classifier)</p> <p>Class-Specific Performance: - Positive Class:    - Precision = 75%: When predicting positive, 75% are correct   - Recall = 75%: Catches 75% of actual positives   - 20 false negatives (missed 25% of positives)</p> <ul> <li>Negative Class:</li> <li>Specificity = 83.3%: Correctly identifies 83.3% of negatives</li> <li>20 false positives (incorrectly flagged 16.7% of negatives)</li> </ul> <p>Error Analysis: - Equal false positives and false negatives (20 each) - Balanced error distribution - No strong bias toward either class</p> <p>Conclusion: The classifier shows balanced performance with equal precision and recall. It's suitable when both false positives and false negatives have similar costs.</p>"},{"location":"ml/papers/2025-practice-solved/#question-4-k-means-clustering","title":"Question 4: K-Means Clustering","text":""},{"location":"ml/papers/2025-practice-solved/#problem-statement_3","title":"Problem Statement","text":"<p>Given 5 data points: - A(0, 0) - B(1, 1) - C(2, 2) - D(5, 5) - E(6, 6)</p> <p>Perform K-Means with \\(K = 2\\): - Initial centroids: \\(C_1 = (0, 0)\\), \\(C_2 = (5, 5)\\) - Perform iterations until convergence.</p>"},{"location":"ml/papers/2025-practice-solved/#solution_3","title":"Solution","text":""},{"location":"ml/papers/2025-practice-solved/#iteration-1","title":"Iteration 1","text":"<p>Step 1: Assign Points to Nearest Centroid</p> <p>Distance Calculations:</p> <p>Point A(0, 0): - To \\(C_1(0, 0)\\): \\(\\sqrt{(0-0)^2 + (0-0)^2} = 0\\) - To \\(C_2(5, 5)\\): \\(\\sqrt{(0-5)^2 + (0-5)^2} = \\sqrt{50} = 7.07\\) - Assign to Cluster 1</p> <p>Point B(1, 1): - To \\(C_1(0, 0)\\): \\(\\sqrt{(1-0)^2 + (1-0)^2} = \\sqrt{2} = 1.41\\) - To \\(C_2(5, 5)\\): \\(\\sqrt{(1-5)^2 + (1-5)^2} = \\sqrt{32} = 5.66\\) - Assign to Cluster 1</p> <p>Point C(2, 2): - To \\(C_1(0, 0)\\): \\(\\sqrt{(2-0)^2 + (2-0)^2} = \\sqrt{8} = 2.83\\) - To \\(C_2(5, 5)\\): \\(\\sqrt{(2-5)^2 + (2-5)^2} = \\sqrt{18} = 4.24\\) - Assign to Cluster 1</p> <p>Point D(5, 5): - To \\(C_1(0, 0)\\): \\(\\sqrt{(5-0)^2 + (5-0)^2} = \\sqrt{50} = 7.07\\) - To \\(C_2(5, 5)\\): \\(0\\) - Assign to Cluster 2</p> <p>Point E(6, 6): - To \\(C_1(0, 0)\\): \\(\\sqrt{(6-0)^2 + (6-0)^2} = \\sqrt{72} = 8.49\\) - To \\(C_2(5, 5)\\): \\(\\sqrt{(6-5)^2 + (6-5)^2} = \\sqrt{2} = 1.41\\) - Assign to Cluster 2</p> <p>Clusters: - Cluster 1: A, B, C - Cluster 2: D, E</p> <p>Step 2: Update Centroids</p> <p>New \\(C_1\\) (mean of A, B, C): $$ C_1 = \\left(\\frac{0+1+2}{3}, \\frac{0+1+2}{3}\\right) = (1, 1) $$</p> <p>New \\(C_2\\) (mean of D, E): $$ C_2 = \\left(\\frac{5+6}{2}, \\frac{5+6}{2}\\right) = (5.5, 5.5) $$</p> <p>After Iteration 1: \\(C_1 = (1, 1)\\), \\(C_2 = (5.5, 5.5)\\)</p>"},{"location":"ml/papers/2025-practice-solved/#iteration-2","title":"Iteration 2","text":"<p>Step 1: Reassign Points</p> <p>Point A(0, 0): - To \\(C_1(1, 1)\\): \\(\\sqrt{2} = 1.41\\) - To \\(C_2(5.5, 5.5)\\): \\(\\sqrt{60.5} = 7.78\\) - Assign to Cluster 1</p> <p>Point B(1, 1): - To \\(C_1(1, 1)\\): \\(0\\) - To \\(C_2(5.5, 5.5)\\): \\(\\sqrt{40.5} = 6.36\\) - Assign to Cluster 1</p> <p>Point C(2, 2): - To \\(C_1(1, 1)\\): \\(\\sqrt{2} = 1.41\\) - To \\(C_2(5.5, 5.5)\\): \\(\\sqrt{24.5} = 4.95\\) - Assign to Cluster 1</p> <p>Point D(5, 5): - To \\(C_1(1, 1)\\): \\(\\sqrt{32} = 5.66\\) - To \\(C_2(5.5, 5.5)\\): \\(\\sqrt{0.5} = 0.71\\) - Assign to Cluster 2</p> <p>Point E(6, 6): - To \\(C_1(1, 1)\\): \\(\\sqrt{50} = 7.07\\) - To \\(C_2(5.5, 5.5)\\): \\(\\sqrt{0.5} = 0.71\\) - Assign to Cluster 2</p> <p>Clusters (same as before): - Cluster 1: A, B, C - Cluster 2: D, E</p> <p>Step 2: Update Centroids</p> <p>New \\(C_1\\): \\((1, 1)\\) (same as before) New \\(C_2\\): \\((5.5, 5.5)\\) (same as before)</p> <p>Convergence: Centroids unchanged \u2192 Algorithm converged!</p> <p>Final Result: - Cluster 1: A(0,0), B(1,1), C(2,2) with centroid \\((1, 1)\\) - Cluster 2: D(5,5), E(6,6) with centroid \\((5.5, 5.5)\\)</p>"},{"location":"ml/papers/2025-practice-solved/#question-5-decision-tree-information-gain","title":"Question 5: Decision Tree - Information Gain","text":""},{"location":"ml/papers/2025-practice-solved/#problem-statement_4","title":"Problem Statement","text":"<p>Given dataset:</p> Weather Temperature Play? Sunny Hot No Sunny Mild Yes Rainy Cool Yes Rainy Mild Yes Overcast Hot Yes Overcast Cool No <p>a) Calculate entropy of the dataset.</p> <p>b) Calculate information gain for \"Weather\".</p> <p>c) Calculate information gain for \"Temperature\".</p> <p>d) Build the decision tree.</p>"},{"location":"ml/papers/2025-practice-solved/#solution_4","title":"Solution","text":""},{"location":"ml/papers/2025-practice-solved/#part-a-dataset-entropy","title":"Part (a): Dataset Entropy","text":"<p>Total examples: \\(m = 6\\)</p> <p>Class distribution: - Yes: 4 examples - No: 2 examples</p> <p>Entropy: $$ H(S) = -\\left[\\frac{4}{6} \\log_2\\left(\\frac{4}{6}\\right) + \\frac{2}{6} \\log_2\\left(\\frac{2}{6}\\right)\\right] $$ $$ H(S) = -\\left[0.667 \\times (-0.585) + 0.333 \\times (-1.585)\\right] $$ $$ H(S) = -[-0.390 - 0.528] = 0.918 $$</p> <p>Answer: \\(H(S) = 0.918\\)</p>"},{"location":"ml/papers/2025-practice-solved/#part-b-information-gain-for-weather","title":"Part (b): Information Gain for Weather","text":"<p>Weather has 3 values: Sunny, Rainy, Overcast</p> <p>Split by Weather:</p> <ol> <li>Sunny:</li> <li>Examples: [Sunny/Hot/No, Sunny/Mild/Yes]</li> <li>Yes: 1, No: 1</li> <li> <p>\\(H(S_{\\text{Sunny}}) = -\\left[\\frac{1}{2} \\log_2\\left(\\frac{1}{2}\\right) + \\frac{1}{2} \\log_2\\left(\\frac{1}{2}\\right)\\right] = 1\\)</p> </li> <li> <p>Rainy:</p> </li> <li>Examples: [Rainy/Cool/Yes, Rainy/Mild/Yes]</li> <li>Yes: 2, No: 0</li> <li> <p>\\(H(S_{\\text{Rainy}}) = 0\\) (pure - all Yes)</p> </li> <li> <p>Overcast:</p> </li> <li>Examples: [Overcast/Hot/Yes, Overcast/Cool/No]</li> <li>Yes: 1, No: 1</li> <li>\\(H(S_{\\text{Overcast}}) = 1\\)</li> </ol> <p>Weighted Average Entropy: $$ H(S|\\text{Weather}) = \\frac{2}{6} \\times 1 + \\frac{2}{6} \\times 0 + \\frac{2}{6} \\times 1 = \\frac{4}{6} = 0.667 $$</p> <p>Information Gain: $$ \\text{IG}(S, \\text{Weather}) = 0.918 - 0.667 = 0.251 $$</p> <p>Answer: IG(Weather) = 0.251</p>"},{"location":"ml/papers/2025-practice-solved/#part-c-information-gain-for-temperature","title":"Part (c): Information Gain for Temperature","text":"<p>Temperature has 3 values: Hot, Mild, Cool</p> <p>Split by Temperature:</p> <ol> <li>Hot:</li> <li>Examples: [Sunny/Hot/No, Overcast/Hot/Yes]</li> <li>Yes: 1, No: 1</li> <li> <p>\\(H(S_{\\text{Hot}}) = 1\\)</p> </li> <li> <p>Mild:</p> </li> <li>Examples: [Sunny/Mild/Yes, Rainy/Mild/Yes]</li> <li>Yes: 2, No: 0</li> <li> <p>\\(H(S_{\\text{Mild}}) = 0\\) (pure)</p> </li> <li> <p>Cool:</p> </li> <li>Examples: [Rainy/Cool/Yes, Overcast/Cool/No]</li> <li>Yes: 1, No: 1</li> <li>\\(H(S_{\\text{Cool}}) = 1\\)</li> </ol> <p>Weighted Average Entropy: $$ H(S|\\text{Temperature}) = \\frac{2}{6} \\times 1 + \\frac{2}{6} \\times 0 + \\frac{2}{6} \\times 1 = 0.667 $$</p> <p>Information Gain: $$ \\text{IG}(S, \\text{Temperature}) = 0.918 - 0.667 = 0.251 $$</p> <p>Answer: IG(Temperature) = 0.251</p> <p>Tie! Both have same information gain.</p>"},{"location":"ml/papers/2025-practice-solved/#part-d-decision-tree-construction","title":"Part (d): Decision Tree Construction","text":"<p>Since IG(Weather) = IG(Temperature) = 0.251, we can choose either. Let's choose Weather as root.</p> <p>Step 1: Root Split on Weather</p> <pre><code>                    Weather\n                   /   |   \\\n              Sunny Rainy Overcast\n              [1Y,1N] [2Y,0N] [1Y,1N]\n</code></pre> <p>Step 2: Handle Pure Nodes</p> <ul> <li>Rainy: Pure (all Yes) \u2192 Leaf: Yes</li> </ul> <p>Step 3: Split Impure Nodes</p> <p>For Sunny branch (needs further splitting): - Split on Temperature:   - Hot \u2192 No   - Mild \u2192 Yes</p> <p>For Overcast branch (needs further splitting): - Split on Temperature:   - Hot \u2192 Yes   - Cool \u2192 No</p> <p>Final Decision Tree:</p> <pre><code>                    Weather\n                   /   |   \\\n              Sunny Rainy Overcast\n              /      |        \\\n        Temperature  Yes   Temperature\n         /     \\              /     \\\n      Hot    Mild         Hot     Cool\n       |      |            |       |\n      No     Yes          Yes     No\n</code></pre> <p>Answer: Decision tree constructed as shown above</p>"},{"location":"ml/papers/2025-practice-solved/#summary","title":"Summary","text":"<p>This practice set covered: 1. \u2705 Gradient Descent Convergence Analysis 2. \u2705 Logistic Regression Decision Boundaries 3. \u2705 Comprehensive Evaluation Metrics 4. \u2705 K-Means Clustering 5. \u2705 Decision Tree Construction with Information Gain</p> <p>Key Takeaways: - Understand gradient descent convergence conditions - Know how to find and plot decision boundaries - Master all evaluation metrics - Practice K-Means iterations - Build decision trees step-by-step</p> <p>Practice makes perfect! Keep solving problems! \ud83c\udfaf</p>"}]}