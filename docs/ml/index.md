# Machine Learning - Complete Revision Guide

Welcome to the Machine Learning revision guide. This section covers all modules with detailed explanations, formulas, and important concepts.

## ðŸ“– Modules Overview

1. **[Module 1: Introduction to Machine Learning](module1-introduction.md)**
    - What is Machine Learning
    - Types of Learning (Supervised, Unsupervised, Reinforcement)
    - Applications and Examples
    - Overfitting vs Underfitting
    - Bias-Variance Tradeoff

2. **[Module 2: Supervised Learning](module2-supervised-learning.md)**
    - Linear Regression (Simple & Multiple)
    - Logistic Regression
    - Gradient Descent Algorithm
    - Cost Functions (MSE, Cross-Entropy)
    - Regularization

3. **[Module 3: Classification & Evaluation](module3-classification-evaluation.md)**
    - Classification Algorithms (KNN, SVM)
    - Confusion Matrix
    - Evaluation Metrics (Accuracy, Precision, Recall, F1-Score)
    - ROC Curve and AUC
    - Precision-Recall Curve

4. **[Module 4: Unsupervised Learning](module4-unsupervised-learning.md)**
    - Clustering (K-Means, Hierarchical)
    - Dimensionality Reduction (PCA)
    - Association Rules (Apriori Algorithm)

5. **[Module 5: Decision Trees](module5-decision-trees.md)**
    - Decision Tree Algorithm
    - Entropy and Information Gain
    - Gini Impurity
    - Pruning Techniques

## ðŸ“š Solved Previous Year Papers

- [2024 Regular Paper - Complete Solutions](papers/2024-regular-solved.md)
- [2024 Makeup Paper - Detailed Solutions](papers/2024-makeup-solved.md)
- [2025 Practice Set - Step-by-Step Solutions](papers/2025-practice-solved.md)

## ðŸŽ¯ MidSem Important Topics

### Must Know Concepts

1. **Decision Tree**
   - ID3 Algorithm with Example & Calculations
   - Information Gain computation
   - Entropy and Gini Impurity
   - Step-by-step tree construction

2. **Linear/Logistic Regression**
   - Cost function (MSE for linear, Cross-Entropy for logistic)
   - Gradient descent algorithm
   - Step-by-step calculations

3. **Confusion Matrix and Metrics**
   - Confusion matrix construction
   - Accuracy, Precision, Recall, F1-Score
   - ROC Curve and AUC
   - Precision-Recall Curve

4. **Gradient Descent**
   - Step-by-step algorithm
   - Update rules
   - Learning rate selection

### Important Note

```{admonition} Exam Strategy
:class: warning

**Make sure to go through all the slides and write answers or solutions step-by-step in the exam. Marks are given based on the steps, not just the final answer.**
```

### Key Formulas
- Cost Function (MSE, Cross-Entropy)
- Gradient Descent Update Rule: $\theta_j := \theta_j - \alpha \frac{\partial J}{\partial \theta_j}$
- Information Gain: $IG(S, A) = H(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} H(S_v)$
- Entropy: $H(S) = -\sum_{i=1}^{c} p_i \log_2(p_i)$
- Gini Index: $Gini(S) = 1 - \sum_{i=1}^{c} p_i^2$
- Precision: $\frac{TP}{TP + FP}$
- Recall: $\frac{TP}{TP + FN}$
- F1-Score: $\frac{2 \times Precision \times Recall}{Precision + Recall}$

### Study Resources

- Past papers topic wise: ML Past Papers
- Practice questions: ML_Practice_Set_2025_Sem1.pdf
- Additional resources: ML Additional Resources
- Decision tree: Lec-10: Decision Tree ðŸŒ² ID3 Algorithm with Example & Calculations ðŸ§®
- Linear/Logistic - cost function
- Confusion matrix, score, F1, recall, other metrics
- Gradient descent: Gradient Descent, Step-by-Step

---

**Start with Module 1 and work through systematically!**

