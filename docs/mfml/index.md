# Mathematical Foundations for Machine Learning (MFML) - Complete Revision Guide

Welcome to the Mathematical Foundations for Machine Learning revision guide. This section covers all modules with detailed explanations, proofs, and important mathematical concepts.

## üìñ Modules Overview

1. **[Module 1: Linear Algebra Fundamentals](modules/module1-linear-algebra.md)**
    - Vectors and Vector Spaces
    - Matrices and Matrix Operations
    - Linear Transformations
    - Eigenvalues and Eigenvectors

2. **[Module 2: Matrix Decompositions](modules/module2-matrix-decompositions.md)**
    - LU Decomposition
    - QR Decomposition
    - Cholesky Decomposition
    - Singular Value Decomposition (SVD)
    - Eigen-decomposition

3. **[Module 3: Vector Spaces and Inner Products](modules/module3-vector-spaces.md)**
    - Inner Product Spaces
    - Norms and Distances
    - Orthogonality and Orthonormal Bases
    - Gram-Schmidt Process
    - Projections

4. **[Module 4: Systems of Linear Equations](modules/module4-linear-systems.md)**
    - Gaussian Elimination
    - Echelon Form and Reduced Row Echelon Form
    - Solving Linear Systems
    - Matrix Inversion Methods
    - Applications to Machine Learning

5. **[Module 5: Calculus for Optimization](modules/module5-calculus-optimization.md)**
    - Partial Derivatives
    - Gradient and Hessian
    - Chain Rule for Multivariable Functions
    - Optimization Techniques
    - Lagrange Multipliers

6. **[Module 6: Probability and Statistics](modules/module6-probability-statistics.md)**
    - Probability Distributions
    - Expectation and Variance
    - Covariance and Correlation
    - Maximum Likelihood Estimation
    - Bayesian Inference

7. **[Module 7: Numerical Methods](modules/module7-numerical-methods.md)**
    - Numerical Linear Algebra
    - Iterative Methods
    - Numerical Stability
    - Floating Point Arithmetic
    - Condition Numbers

## üìö Solved Previous Year Papers

- [2024 MidSem Regular Paper - Complete Solutions](papers/2024-midsem-regular-solved.md)
- [2024 MidSem Makeup Paper - Detailed Solutions](papers/2024-midsem-makeup-solved.md)
- [2023 MidSem Regular Paper - Step-by-Step Solutions](papers/2023-midsem-regular-solved.md)
- [2022 MidSem Paper - Comprehensive Solutions](papers/2022-midsem-solved.md)

## üìù Assignments

- [Assignment 1 - Linear Systems & Inner Products](assignments/assignment1-solved.md)

## üéØ MidSem Important Topics

### Expected Question Types

1. **REF/RREF (Easy to Score)**
   - Transform matrices to Row Echelon Form
   - Transform matrices to Reduced Row Echelon Form
   - Use Gaussian elimination step-by-step

2. **Linear Dependence/Independence**
   - Test if vectors are linearly independent
   - Use REF to find rank
   - Express dependent vectors as linear combinations

3. **Inner/Dot Products or Gram-Schmidt Orthogonalization**
   - Compute inner products with weighted matrices
   - Compute norms from inner products
   - Apply Gram-Schmidt process step-by-step
   - Verify orthonormality

4. **Eigen Decomposition/Diagonalization/SVD Decomposition**
   - Find eigenvalues and eigenvectors
   - Diagonalize matrices
   - Compute SVD (lengthy but easy to score)
   - Use decomposition to solve systems

5. **Taylor's Series (Easy to Score)**
   - **MUST KNOW: Two-variable Taylor series**
   - Expand functions around given points
   - First-order and second-order approximations

6. **Partial Derivatives or Applications**
   - Compute partial derivatives
   - Find gradients
   - Compute Jacobian matrices
   - Compute Hessian matrices
   - Applications in optimization

### Must Solve

- **MFML Practice Problems.pdf** - Essential practice material
- All past papers topic-wise

### Key Formulas

- Matrix multiplication and inversion
- Determinant computation
- Eigenvalue equation: $Av = \lambda v$
- Inner product: $\langle x, y \rangle = x^T M y$
- Norm: $\|x\| = \sqrt{\langle x, x \rangle}$
- Gradient: $\nabla f(x) = \left(\frac{\partial f}{\partial x_1}, \ldots, \frac{\partial f}{\partial x_n}\right)^T$
- Two-variable Taylor: $f(x,y) \approx f(a,b) + f_x(a,b)(x-a) + f_y(a,b)(y-b) + \frac{1}{2}[f_{xx}(a,b)(x-a)^2 + 2f_{xy}(a,b)(x-a)(y-b) + f_{yy}(a,b)(y-b)^2]$

### Study Resources

- Companion docs + Topic explanations: MFML Additional Resources
- Understanding the Gradient
- Finding the Gradient of a Vector Function
- Matrix Calculus Overview
- Detailed Explanation of Linear Independence
- Example Calculation of LU Decomposition
- SVD Problem with Full Explanation
- Eigenvectors and Eigenvalues (Essence of Linear Algebra)
- Powers in Matrix Product
- Past papers topic wise: MFML Past Papers
- Useful cheatsheet: [Linear Algebra Cheat Sheet](https://jiha-kim.github.io/crash-courses/linear-algebra/999-cheat-sheet/)
- Linear algebra Formula sheet: Linear Algebra Formula Sheet.pdf

---

**Course Information:**
- Course No.: AIMLC ZC416 / DSECLZC416
- Course Title: Mathematical Foundations for Machine Language / Mathematical Foundations for Data Science
